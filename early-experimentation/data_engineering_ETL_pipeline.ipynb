{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50201c6",
   "metadata": {},
   "source": [
    "# ETL Pipeline (Extract → Transform → Load)\n",
    "\n",
    "This notebook walks through a full ETL workflow for loading Flowcase style data into PostgreSQL:\n",
    "\n",
    "1. Generate synthetic CV reports  \n",
    "2. Extract raw CSV files  \n",
    "3. Transform data into a clean relational schema  \n",
    "4. Load into a PostgreSQL database  \n",
    "5. Verify the results  \n",
    "\n",
    "Each step is designed to be clear, testable, and reproducible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13bbfdd",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "To get started:\n",
    "\n",
    "1. Create a Python virtual environment  \n",
    "2. Select the `.venv` kernel in Jupyter  \n",
    "3. Install dependencies:  \n",
    "    ```\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "4. Make sure PostgreSQL is running (e.g., via pgAdmin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17b802",
   "metadata": {},
   "source": [
    "## Step 0 — Generate Synthetic Data\n",
    "\n",
    "Generate synthetic Flowcase-style CV Partner reports.  \n",
    "These are stored under the `cv_reports/` folder using timestamped folder names.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d5506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ user_report.csv: 500 rows\n",
      "✔ usage_report.csv: 500 rows\n",
      "✔ project_experiences.csv: 1501 rows\n",
      "✔ certifications.csv: 1006 rows\n",
      "✔ courses.csv: 1446 rows\n",
      "✔ languages.csv: 996 rows\n",
      "✔ technologies.csv: 2220 rows\n",
      "✔ key_qualifications.csv: 485 rows\n",
      "✔ educations.csv: 757 rows\n",
      "✔ work_experiences.csv: 1484 rows\n",
      "✔ positions.csv: 1264 rows\n",
      "✔ blogs.csv: 758 rows\n",
      "✔ cv_roles.csv: 1001 rows\n",
      "✔ sc_clearance.csv: 500 rows\n",
      "✔ availability_report.csv: 30000 rows\n",
      "\n",
      "All files written under: /Users/alanabarrett-frew/Desktop/Module  4/Assignment/ETL Pipeline/ETL_pipeline/early-experimentation/cv_reports/Q42025\n"
     ]
    }
   ],
   "source": [
    "import make_fake_flowcase_reports as make_fake_flowcase_reports\n",
    "\n",
    "make_fake_flowcase_reports.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f28053",
   "metadata": {},
   "source": [
    "## Run all Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1373d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from datetime import date\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514123e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_step(title):\n",
    "    print(f\"\\n{'='*20} {title} {'='*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce0a69",
   "metadata": {},
   "source": [
    "# Step 1 — Extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2036190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_report_folder(base_folder=\"cv_reports\"):\n",
    "    print_step(\"Finding the latest report folder\")\n",
    "\n",
    "    report_folders = [f for f in Path(base_folder).iterdir() if f.is_dir()]\n",
    "    if not report_folders:\n",
    "        raise FileNotFoundError(f\"No report folders found in {base_folder}\")\n",
    "\n",
    "    latest = sorted(report_folders, key=lambda f: f.name)[-1]\n",
    "\n",
    "    print(f\"Found {len(report_folders)} folders.\")\n",
    "    print(f\"Latest folder: {latest.name}\")\n",
    "\n",
    "    return latest\n",
    "\n",
    "\n",
    "def find_latest_quarterly_report_folder(base_folder=\"cv_reports\"):\n",
    "    print_step(\"Finding the latest quarterly report folder\")\n",
    "\n",
    "    pattern = re.compile(r\"Q[1-4]\\d{4}\")\n",
    "    report_folders = [\n",
    "        f for f in Path(base_folder).iterdir()\n",
    "        if f.is_dir() and pattern.match(f.name)\n",
    "    ]\n",
    "    if not report_folders:\n",
    "        raise FileNotFoundError(f\"No quarterly report folders found in {base_folder}.\")\n",
    "\n",
    "    names = sorted([f.name for f in report_folders])\n",
    "    print(\"Quarterly folders found:\", names)\n",
    "\n",
    "    latest_folder = sorted(report_folders, key=lambda folder: folder.name)[-1]\n",
    "    print(\"Using latest quarterly folder:\", latest_folder.name)\n",
    "\n",
    "    return latest_folder\n",
    "\n",
    "\n",
    "def load_csv_files_from_folder(report_folder):\n",
    "    print_step(f\"Loading CSV files from {report_folder}\")\n",
    "\n",
    "    csv_files = list(Path(report_folder).glob(\"*.csv\"))\n",
    "    print(f\"Found {len(csv_files)} CSV files.\")\n",
    "    dataframes = {}\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            dataframes[csv_file.name] = df\n",
    "            print(f\"  Loaded {csv_file.name} -> {df.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️ Failed to read {csv_file.name}: {e}\")\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "def extract(settings):\n",
    "    \"\"\"\n",
    "    Finds the latest quarterly report folder and loads all CSVs as DataFrames.\n",
    "    Returns an object with .data_dir and dict-like data (keyed by filename).\n",
    "    \"\"\"\n",
    "    data_source = settings.get(\"data_source\", \"fake\")\n",
    "\n",
    "    if data_source == \"real\":\n",
    "        print(\"[extract] Real data mode selected, but not implemented.\")\n",
    "        return type(\"ExtractResult\", (), {\"data_dir\": None})()\n",
    "\n",
    "    # Fake data path\n",
    "    base_folder = settings.get(\"base_folder\", \"cv_reports\")\n",
    "    data_dir = find_latest_quarterly_report_folder(base_folder)\n",
    "    data = load_csv_files_from_folder(data_dir)\n",
    "\n",
    "    class ExtractResult(dict):\n",
    "        pass\n",
    "\n",
    "    result = ExtractResult(data)\n",
    "    result.data_dir = data_dir\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad32481",
   "metadata": {},
   "source": [
    "## Step 1.1 — Locate the latest report folder\n",
    "\n",
    "Identify the most recent synthetic export under `cv_reports/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017eba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 1.1: Locate latest report folder ====================\n",
      "\n",
      "==================== Finding the latest report folder ====================\n",
      "Found 1 folders.\n",
      "Latest folder: Q42025\n",
      "✅ Using folder: cv_reports/Q42025\n"
     ]
    }
   ],
   "source": [
    "print_step(\"Step 1.1: Locate latest report folder\")\n",
    "\n",
    "latest_folder = find_latest_report_folder(\"cv_reports\")\n",
    "print(f\"✅ Using folder: {latest_folder}\")\n",
    "\n",
    "# Tiny test: does it actually exist?\n",
    "assert latest_folder.exists(), \"Latest folder path does not exist on disk!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a88e7",
   "metadata": {},
   "source": [
    "## Step 1.2 — Load all CSV files from the latest report\n",
    "\n",
    "Load all CSVs inside the selected folder into pandas DataFrames and perform a sanity check to ensure core files are present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30eb83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 1.2: Load CSV files from latest folder ====================\n",
      "\n",
      "==================== Loading CSV files from cv_reports/Q42025 ====================\n",
      "Found 15 CSV files.\n",
      "  Loaded certifications.csv -> (1006, 22)\n",
      "  Loaded project_experiences.csv -> (1501, 45)\n",
      "  Loaded blogs.csv -> (758, 21)\n",
      "  Loaded availability_report.csv -> (30000, 7)\n",
      "  Loaded cv_roles.csv -> (1001, 19)\n",
      "  Loaded work_experiences.csv -> (1484, 26)\n",
      "  Loaded educations.csv -> (757, 27)\n",
      "  Loaded user_report.csv -> (500, 26)\n",
      "  Loaded courses.csv -> (1446, 26)\n",
      "  Loaded key_qualifications.csv -> (485, 21)\n",
      "  Loaded positions.csv -> (1264, 23)\n",
      "  Loaded technologies.csv -> (2220, 20)\n",
      "  Loaded sc_clearance.csv -> (500, 9)\n",
      "  Loaded languages.csv -> (996, 22)\n",
      "  Loaded usage_report.csv -> (500, 51)\n",
      "\n",
      "Summary of loaded files:\n",
      " - certifications.csv             (1006, 22)\n",
      " - project_experiences.csv        (1501, 45)\n",
      " - blogs.csv                      (758, 21)\n",
      " - availability_report.csv        (30000, 7)\n",
      " - cv_roles.csv                   (1001, 19)\n",
      " - work_experiences.csv           (1484, 26)\n",
      " - educations.csv                 (757, 27)\n",
      " - user_report.csv                (500, 26)\n",
      " - courses.csv                    (1446, 26)\n",
      " - key_qualifications.csv         (485, 21)\n",
      " - positions.csv                  (1264, 23)\n",
      " - technologies.csv               (2220, 20)\n",
      " - sc_clearance.csv               (500, 9)\n",
      " - languages.csv                  (996, 22)\n",
      " - usage_report.csv               (500, 51)\n",
      "\n",
      "Expected core files: ['user_report.csv', 'project_experiences.csv', 'work_experiences.csv']\n",
      "Missing: []\n"
     ]
    }
   ],
   "source": [
    "print_step(\"Step 1.2: Load CSV files from latest folder\")\n",
    "\n",
    "raw_frames = load_csv_files_from_folder(latest_folder)\n",
    "\n",
    "print(\"\\nSummary of loaded files:\")\n",
    "for name, df in raw_frames.items():\n",
    "    print(f\" - {name:30} {df.shape}\")\n",
    "\n",
    "# Check: do we have some expected core CSVs?\n",
    "expected_files = [\n",
    "    \"user_report.csv\",\n",
    "    \"project_experiences.csv\",\n",
    "    \"work_experiences.csv\",\n",
    "]\n",
    "missing = [f for f in expected_files if f not in raw_frames]\n",
    "\n",
    "print(\"\\nExpected core files:\", expected_files)\n",
    "print(\"Missing:\", missing)\n",
    "\n",
    "assert not missing, \"One or more expected CSVs are missing!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bae474",
   "metadata": {},
   "source": [
    "# Step 2 — Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db93e221",
   "metadata": {},
   "source": [
    "## Step 2.1 — Transform helpers\n",
    "\n",
    "These helpers normalise multilang fields, dates, and define the `TransformResult`\n",
    "dataclass for returning a clean set of tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5d4ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformResult:\n",
    "    users_df: pd.DataFrame | None = None\n",
    "    cvs_df: pd.DataFrame | None = None\n",
    "    technologies_df: pd.DataFrame | None = None\n",
    "    languages_df: pd.DataFrame | None = None\n",
    "    project_experiences_df: pd.DataFrame | None = None\n",
    "    work_experiences_df: pd.DataFrame | None = None\n",
    "    certifications_df: pd.DataFrame | None = None\n",
    "    courses_df: pd.DataFrame | None = None\n",
    "    educations_df: pd.DataFrame | None = None\n",
    "    positions_df: pd.DataFrame | None = None\n",
    "    blogs_df: pd.DataFrame | None = None\n",
    "    cv_roles_df: pd.DataFrame | None = None\n",
    "    key_qualifications_df: pd.DataFrame | None = None\n",
    "    sc_clearance_df: pd.DataFrame | None = None\n",
    "    availability_df: pd.DataFrame | None = None\n",
    "\n",
    "def parse_multilang(pipe: object) -> dict:\n",
    "    \"\"\"\n",
    "    Convert a single pipe string like 'int:Text|no:Tekst' into a dict.\n",
    "    Anything non-string or blank -> {}.\n",
    "    \"\"\"\n",
    "    if not isinstance(pipe, str) or not pipe.strip():\n",
    "        return {}\n",
    "    out = {}\n",
    "    for part in pipe.split(\"|\"):\n",
    "        if \":\" in part:\n",
    "            k, v = part.split(\":\", 1)\n",
    "            k, v = k.strip(), v.strip()\n",
    "            if k and v:\n",
    "                out[k] = v\n",
    "    return out\n",
    "\n",
    "def to_iso_date(s: object) -> str | None:\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)):\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    # If it looks like ISO (yyyy-mm-dd), parse straight without dayfirst\n",
    "    if \"-\" in s and len(s.split(\"-\")[0]) == 4:\n",
    "        dt = pd.to_datetime(s, errors=\"coerce\")\n",
    "    else:\n",
    "        dt = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
    "    return None if pd.isna(dt) else dt.date().isoformat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba73a74",
   "metadata": {},
   "source": [
    "## Step 2.2 — Core transform logic\n",
    "\n",
    "The `transform()` function builds clean tables for Users, CVs, skills, \n",
    "experiences, and other CV Partner sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f5fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data) -> TransformResult:\n",
    "    # Core extracts\n",
    "    users = data.get(\"user_report.csv\", pd.DataFrame()).copy()\n",
    "    usage = data.get(\"usage_report.csv\", pd.DataFrame()).copy()\n",
    "\n",
    "    # Parse user name as dict\n",
    "    if not users.empty and \"Name (multilang)\" in users.columns:\n",
    "        users[\"Name (multilang)\"] = users[\"Name (multilang)\"].map(parse_multilang)\n",
    "    else:\n",
    "        users[\"Name (multilang)\"] = [{}] * len(users)\n",
    "\n",
    "    # Nationality comes from usage_report: \"Nationality (#{lang})\" is a single pipe string\n",
    "    if not usage.empty and \"Nationality (#{lang})\" in usage.columns:\n",
    "        nat_map = {\n",
    "            str(r[\"CV Partner User ID\"]): parse_multilang(r[\"Nationality (#{lang})\"])\n",
    "            for _, r in usage.iterrows()\n",
    "            if \"CV Partner User ID\" in r and pd.notna(r[\"CV Partner User ID\"])\n",
    "        }\n",
    "        users[\"nationality_multilang\"] = users[\"CV Partner User ID\"].map(\n",
    "            lambda uid: nat_map.get(str(uid), {})\n",
    "        )\n",
    "    else:\n",
    "        users[\"nationality_multilang\"] = [{}] * len(users)\n",
    "\n",
    "    # Build CV rows: user_report already has one row per CV\n",
    "    cvs = users.copy()\n",
    "    if \"Title (#{lang})\" in users.columns:\n",
    "        cvs[\"title_multilang\"] = users[\"Title (#{lang})\"].map(parse_multilang)\n",
    "    else:\n",
    "        cvs[\"title_multilang\"] = [{}] * len(cvs)\n",
    "\n",
    "    # Carry seniority columns from user_report -> cvs_df\n",
    "    def _num(x):\n",
    "        try:\n",
    "            return int(x)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    cvs[\"sfia_level\"] = users.get(\"SFIA Level\", pd.Series([None]*len(users))).map(_num)\n",
    "    cvs[\"cpd_level\"]  = users.get(\"CPD Level\",  pd.Series([None]*len(users))).map(_num)\n",
    "    cvs[\"cpd_band\"]   = users.get(\"CPD Band\",   pd.Series([None]*len(users))).astype(\"string\").where(lambda s: s.notna(), None)\n",
    "    cvs[\"cpd_label\"]  = users.get(\"CPD Label\",  pd.Series([None]*len(users))).astype(\"string\").where(lambda s: s.notna(), None)\n",
    "\n",
    "\n",
    "    # Pass through + light cleanup\n",
    "    sc_clearance = data.get(\"sc_clearance.csv\", pd.DataFrame()).copy()\n",
    "    if not sc_clearance.empty:\n",
    "        for col in (\"Valid From\", \"Valid To\"):\n",
    "            if col in sc_clearance.columns:\n",
    "                sc_clearance[col] = sc_clearance[col].map(to_iso_date)\n",
    "\n",
    "    availability = data.get(\"availability_report.csv\", pd.DataFrame()).copy()\n",
    "    if not availability.empty and \"Date\" in availability.columns:\n",
    "        availability[\"Date\"] = availability[\"Date\"].map(to_iso_date)\n",
    "\n",
    "    return TransformResult(\n",
    "        users_df=users if not users.empty else pd.DataFrame(),\n",
    "        cvs_df=cvs if not cvs.empty else pd.DataFrame(),\n",
    "        technologies_df=data.get(\"technologies.csv\"),\n",
    "        languages_df=data.get(\"languages.csv\"),\n",
    "        project_experiences_df=data.get(\"project_experiences.csv\"),\n",
    "        work_experiences_df=data.get(\"work_experiences.csv\"),\n",
    "        certifications_df=data.get(\"certifications.csv\"),\n",
    "        courses_df=data.get(\"courses.csv\"),\n",
    "        educations_df=data.get(\"educations.csv\"),\n",
    "        positions_df=data.get(\"positions.csv\"),\n",
    "        blogs_df=data.get(\"blogs.csv\"),\n",
    "        cv_roles_df=data.get(\"cv_roles.csv\"),\n",
    "        key_qualifications_df=data.get(\"key_qualifications.csv\"),\n",
    "        sc_clearance_df=sc_clearance if not sc_clearance.empty else pd.DataFrame(),\n",
    "        availability_df=availability if not availability.empty else pd.DataFrame(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55720d32",
   "metadata": {},
   "source": [
    "## Step 2.3 — Run transform and perform tests\n",
    "\n",
    "Execute `transform(raw_data)` and validate:\n",
    "\n",
    "- Row counts  \n",
    "- Key identifiers  \n",
    "- Data integrity (e.g., CV count aligns with user count)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297eed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 2.3: Reload CSVs for transform demo ====================\n",
      "\n",
      "==================== Loading CSV files from cv_reports/Q42025 ====================\n",
      "Found 15 CSV files.\n",
      "  Loaded certifications.csv -> (1006, 22)\n",
      "  Loaded project_experiences.csv -> (1501, 45)\n",
      "  Loaded blogs.csv -> (758, 21)\n",
      "  Loaded availability_report.csv -> (30000, 7)\n",
      "  Loaded cv_roles.csv -> (1001, 19)\n",
      "  Loaded work_experiences.csv -> (1484, 26)\n",
      "  Loaded educations.csv -> (757, 27)\n",
      "  Loaded user_report.csv -> (500, 26)\n",
      "  Loaded courses.csv -> (1446, 26)\n",
      "  Loaded key_qualifications.csv -> (485, 21)\n",
      "  Loaded positions.csv -> (1264, 23)\n",
      "  Loaded technologies.csv -> (2220, 20)\n",
      "  Loaded sc_clearance.csv -> (500, 9)\n",
      "  Loaded languages.csv -> (996, 22)\n",
      "  Loaded usage_report.csv -> (500, 51)\n",
      "\n",
      "==================== Step 2.3a: Run transform() on extracted data ====================\n",
      "\n",
      "Transformed tables (row counts):\n",
      " - users_df                    500 rows\n",
      " - cvs_df                      500 rows\n",
      " - technologies_df            2220 rows\n",
      " - languages_df                996 rows\n",
      " - project_experiences_df     1501 rows\n",
      " - work_experiences_df        1484 rows\n",
      "\n",
      "Sample: users_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Name (multilang)</th>\n",
       "      <th>Title (#{lang})</th>\n",
       "      <th>Email</th>\n",
       "      <th>UPN</th>\n",
       "      <th>External User ID</th>\n",
       "      <th>CV Partner User ID</th>\n",
       "      <th>CV Partner CV ID</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Landline</th>\n",
       "      <th>...</th>\n",
       "      <th>Years since first work experience</th>\n",
       "      <th>Access roles</th>\n",
       "      <th>Has profile image</th>\n",
       "      <th>Owns a reference project</th>\n",
       "      <th>Read and understood privacy notice</th>\n",
       "      <th>SFIA Level</th>\n",
       "      <th>CPD Level</th>\n",
       "      <th>CPD Band</th>\n",
       "      <th>CPD Label</th>\n",
       "      <th>nationality_multilang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danielle Johnson</td>\n",
       "      <td>{'int': 'Danielle Johnson'}</td>\n",
       "      <td>int:Principal C# Developer</td>\n",
       "      <td>danielle.johnson@mail.test</td>\n",
       "      <td>daniellejohnson</td>\n",
       "      <td>ext_5b69cd14</td>\n",
       "      <td>5b69cd14</td>\n",
       "      <td>cv_5b69cd14</td>\n",
       "      <td>958-350-6431</td>\n",
       "      <td>+1-539-500-5329x31839</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Norwegian'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joshua Walker</td>\n",
       "      <td>{'int': 'Joshua Walker'}</td>\n",
       "      <td>int:Principal Data Engineer</td>\n",
       "      <td>joshua.walker@mail.test</td>\n",
       "      <td>joshuawalker</td>\n",
       "      <td>ext_439b63ae</td>\n",
       "      <td>439b63ae</td>\n",
       "      <td>cv_439b63ae</td>\n",
       "      <td>729-504-2284x21020</td>\n",
       "      <td>001-350-324-0268</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>User</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Swedish'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jill Rhodes</td>\n",
       "      <td>{'int': 'Jill Rhodes'}</td>\n",
       "      <td>int:Senior C# Developer</td>\n",
       "      <td>jill.rhodes@example.org</td>\n",
       "      <td>jillrhodes</td>\n",
       "      <td>ext_bc24ae58</td>\n",
       "      <td>bc24ae58</td>\n",
       "      <td>cv_bc24ae58</td>\n",
       "      <td>975.289.1783x9084</td>\n",
       "      <td>7764617711</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>{'int': 'British'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patricia Miller</td>\n",
       "      <td>{'int': 'Patricia Miller'}</td>\n",
       "      <td>int:Principal Analytics Engineer</td>\n",
       "      <td>patricia.miller@mail.test</td>\n",
       "      <td>patriciamiller</td>\n",
       "      <td>ext_711200c6</td>\n",
       "      <td>711200c6</td>\n",
       "      <td>cv_711200c6</td>\n",
       "      <td>624-999-8569</td>\n",
       "      <td>896.311.8367x36576</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>User</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Polish'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robert Johnson</td>\n",
       "      <td>{'int': 'Robert Johnson'}</td>\n",
       "      <td>int:Associate ML Engineer</td>\n",
       "      <td>robert.johnson@mail.test</td>\n",
       "      <td>robertjohnson</td>\n",
       "      <td>ext_a7986c12</td>\n",
       "      <td>a7986c12</td>\n",
       "      <td>cv_a7986c12</td>\n",
       "      <td>465-245-2711x11615</td>\n",
       "      <td>001-688-651-6560</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>Country Manager</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>{'int': 'Danish'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name             Name (multilang)  \\\n",
       "0  Danielle Johnson  {'int': 'Danielle Johnson'}   \n",
       "1     Joshua Walker     {'int': 'Joshua Walker'}   \n",
       "2       Jill Rhodes       {'int': 'Jill Rhodes'}   \n",
       "3   Patricia Miller   {'int': 'Patricia Miller'}   \n",
       "4    Robert Johnson    {'int': 'Robert Johnson'}   \n",
       "\n",
       "                    Title (#{lang})                       Email  \\\n",
       "0        int:Principal C# Developer  danielle.johnson@mail.test   \n",
       "1       int:Principal Data Engineer     joshua.walker@mail.test   \n",
       "2           int:Senior C# Developer     jill.rhodes@example.org   \n",
       "3  int:Principal Analytics Engineer   patricia.miller@mail.test   \n",
       "4         int:Associate ML Engineer    robert.johnson@mail.test   \n",
       "\n",
       "               UPN External User ID CV Partner User ID CV Partner CV ID  \\\n",
       "0  daniellejohnson     ext_5b69cd14           5b69cd14      cv_5b69cd14   \n",
       "1     joshuawalker     ext_439b63ae           439b63ae      cv_439b63ae   \n",
       "2       jillrhodes     ext_bc24ae58           bc24ae58      cv_bc24ae58   \n",
       "3   patriciamiller     ext_711200c6           711200c6      cv_711200c6   \n",
       "4    robertjohnson     ext_a7986c12           a7986c12      cv_a7986c12   \n",
       "\n",
       "         Phone Number               Landline  ...  \\\n",
       "0        958-350-6431  +1-539-500-5329x31839  ...   \n",
       "1  729-504-2284x21020       001-350-324-0268  ...   \n",
       "2   975.289.1783x9084             7764617711  ...   \n",
       "3        624-999-8569     896.311.8367x36576  ...   \n",
       "4  465-245-2711x11615       001-688-651-6560  ...   \n",
       "\n",
       "   Years since first work experience     Access roles Has profile image  \\\n",
       "0                                  5             User              True   \n",
       "1                                 12             User             False   \n",
       "2                                  9             User              True   \n",
       "3                                 18             User             False   \n",
       "4                                 10  Country Manager              True   \n",
       "\n",
       "  Owns a reference project Read and understood privacy notice SFIA Level  \\\n",
       "0                    False                               True          5   \n",
       "1                    False                              False          5   \n",
       "2                    False                               True          4   \n",
       "3                    False                               True          5   \n",
       "4                     True                              False          2   \n",
       "\n",
       "   CPD Level  CPD Band CPD Label  nationality_multilang  \n",
       "0          3         L     CPD3L   {'int': 'Norwegian'}  \n",
       "1          3         L     CPD3L     {'int': 'Swedish'}  \n",
       "2          3         E     CPD3E     {'int': 'British'}  \n",
       "3          3         L     CPD3L      {'int': 'Polish'}  \n",
       "4          1         E     CPD1E      {'int': 'Danish'}  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample: cvs_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Name (multilang)</th>\n",
       "      <th>Title (#{lang})</th>\n",
       "      <th>Email</th>\n",
       "      <th>UPN</th>\n",
       "      <th>External User ID</th>\n",
       "      <th>CV Partner User ID</th>\n",
       "      <th>CV Partner CV ID</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Landline</th>\n",
       "      <th>...</th>\n",
       "      <th>SFIA Level</th>\n",
       "      <th>CPD Level</th>\n",
       "      <th>CPD Band</th>\n",
       "      <th>CPD Label</th>\n",
       "      <th>nationality_multilang</th>\n",
       "      <th>title_multilang</th>\n",
       "      <th>sfia_level</th>\n",
       "      <th>cpd_level</th>\n",
       "      <th>cpd_band</th>\n",
       "      <th>cpd_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danielle Johnson</td>\n",
       "      <td>{'int': 'Danielle Johnson'}</td>\n",
       "      <td>int:Principal C# Developer</td>\n",
       "      <td>danielle.johnson@mail.test</td>\n",
       "      <td>daniellejohnson</td>\n",
       "      <td>ext_5b69cd14</td>\n",
       "      <td>5b69cd14</td>\n",
       "      <td>cv_5b69cd14</td>\n",
       "      <td>958-350-6431</td>\n",
       "      <td>+1-539-500-5329x31839</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Norwegian'}</td>\n",
       "      <td>{'int': 'Principal C# Developer'}</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joshua Walker</td>\n",
       "      <td>{'int': 'Joshua Walker'}</td>\n",
       "      <td>int:Principal Data Engineer</td>\n",
       "      <td>joshua.walker@mail.test</td>\n",
       "      <td>joshuawalker</td>\n",
       "      <td>ext_439b63ae</td>\n",
       "      <td>439b63ae</td>\n",
       "      <td>cv_439b63ae</td>\n",
       "      <td>729-504-2284x21020</td>\n",
       "      <td>001-350-324-0268</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Swedish'}</td>\n",
       "      <td>{'int': 'Principal Data Engineer'}</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jill Rhodes</td>\n",
       "      <td>{'int': 'Jill Rhodes'}</td>\n",
       "      <td>int:Senior C# Developer</td>\n",
       "      <td>jill.rhodes@example.org</td>\n",
       "      <td>jillrhodes</td>\n",
       "      <td>ext_bc24ae58</td>\n",
       "      <td>bc24ae58</td>\n",
       "      <td>cv_bc24ae58</td>\n",
       "      <td>975.289.1783x9084</td>\n",
       "      <td>7764617711</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>{'int': 'British'}</td>\n",
       "      <td>{'int': 'Senior C# Developer'}</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD3E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patricia Miller</td>\n",
       "      <td>{'int': 'Patricia Miller'}</td>\n",
       "      <td>int:Principal Analytics Engineer</td>\n",
       "      <td>patricia.miller@mail.test</td>\n",
       "      <td>patriciamiller</td>\n",
       "      <td>ext_711200c6</td>\n",
       "      <td>711200c6</td>\n",
       "      <td>cv_711200c6</td>\n",
       "      <td>624-999-8569</td>\n",
       "      <td>896.311.8367x36576</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Polish'}</td>\n",
       "      <td>{'int': 'Principal Analytics Engineer'}</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robert Johnson</td>\n",
       "      <td>{'int': 'Robert Johnson'}</td>\n",
       "      <td>int:Associate ML Engineer</td>\n",
       "      <td>robert.johnson@mail.test</td>\n",
       "      <td>robertjohnson</td>\n",
       "      <td>ext_a7986c12</td>\n",
       "      <td>a7986c12</td>\n",
       "      <td>cv_a7986c12</td>\n",
       "      <td>465-245-2711x11615</td>\n",
       "      <td>001-688-651-6560</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>{'int': 'Danish'}</td>\n",
       "      <td>{'int': 'Associate ML Engineer'}</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD1E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name             Name (multilang)  \\\n",
       "0  Danielle Johnson  {'int': 'Danielle Johnson'}   \n",
       "1     Joshua Walker     {'int': 'Joshua Walker'}   \n",
       "2       Jill Rhodes       {'int': 'Jill Rhodes'}   \n",
       "3   Patricia Miller   {'int': 'Patricia Miller'}   \n",
       "4    Robert Johnson    {'int': 'Robert Johnson'}   \n",
       "\n",
       "                    Title (#{lang})                       Email  \\\n",
       "0        int:Principal C# Developer  danielle.johnson@mail.test   \n",
       "1       int:Principal Data Engineer     joshua.walker@mail.test   \n",
       "2           int:Senior C# Developer     jill.rhodes@example.org   \n",
       "3  int:Principal Analytics Engineer   patricia.miller@mail.test   \n",
       "4         int:Associate ML Engineer    robert.johnson@mail.test   \n",
       "\n",
       "               UPN External User ID CV Partner User ID CV Partner CV ID  \\\n",
       "0  daniellejohnson     ext_5b69cd14           5b69cd14      cv_5b69cd14   \n",
       "1     joshuawalker     ext_439b63ae           439b63ae      cv_439b63ae   \n",
       "2       jillrhodes     ext_bc24ae58           bc24ae58      cv_bc24ae58   \n",
       "3   patriciamiller     ext_711200c6           711200c6      cv_711200c6   \n",
       "4    robertjohnson     ext_a7986c12           a7986c12      cv_a7986c12   \n",
       "\n",
       "         Phone Number               Landline  ...  SFIA Level CPD Level  \\\n",
       "0        958-350-6431  +1-539-500-5329x31839  ...           5         3   \n",
       "1  729-504-2284x21020       001-350-324-0268  ...           5         3   \n",
       "2   975.289.1783x9084             7764617711  ...           4         3   \n",
       "3        624-999-8569     896.311.8367x36576  ...           5         3   \n",
       "4  465-245-2711x11615       001-688-651-6560  ...           2         1   \n",
       "\n",
       "  CPD Band CPD Label nationality_multilang  \\\n",
       "0        L     CPD3L  {'int': 'Norwegian'}   \n",
       "1        L     CPD3L    {'int': 'Swedish'}   \n",
       "2        E     CPD3E    {'int': 'British'}   \n",
       "3        L     CPD3L     {'int': 'Polish'}   \n",
       "4        E     CPD1E     {'int': 'Danish'}   \n",
       "\n",
       "                           title_multilang  sfia_level  cpd_level cpd_band  \\\n",
       "0        {'int': 'Principal C# Developer'}           5          3        L   \n",
       "1       {'int': 'Principal Data Engineer'}           5          3        L   \n",
       "2           {'int': 'Senior C# Developer'}           4          3        E   \n",
       "3  {'int': 'Principal Analytics Engineer'}           5          3        L   \n",
       "4         {'int': 'Associate ML Engineer'}           2          1        E   \n",
       "\n",
       "   cpd_label  \n",
       "0      CPD3L  \n",
       "1      CPD3L  \n",
       "2      CPD3E  \n",
       "3      CPD3L  \n",
       "4      CPD1E  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 2.3b: Basic data quality checks on transform output ====================\n",
      "✅ Transform checks passed for users_df and cvs_df.\n"
     ]
    }
   ],
   "source": [
    "print_step(\"Step 2.3: Reload CSVs for transform demo\")\n",
    "\n",
    "raw_data = load_csv_files_from_folder(latest_folder)\n",
    "\n",
    "print_step(\"Step 2.3a: Run transform() on extracted data\")\n",
    "\n",
    "# Use the raw data dict from load_csv_files_from_folder(...)\n",
    "tr = transform(raw_data)\n",
    "\n",
    "print(\"\\nTransformed tables (row counts):\")\n",
    "for name in [\n",
    "    \"users_df\", \"cvs_df\", \"technologies_df\", \"languages_df\",\n",
    "    \"project_experiences_df\", \"work_experiences_df\",\n",
    "]:\n",
    "    df = getattr(tr, name)\n",
    "    if df is not None:\n",
    "        print(f\" - {name:25} {len(df):5d} rows\")\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"\\nSample: users_df\")\n",
    "display(tr.users_df.head())\n",
    "\n",
    "print(\"\\nSample: cvs_df\")\n",
    "display(tr.cvs_df.head())\n",
    "\n",
    "print_step(\"Step 2.3b: Basic data quality checks on transform output\")\n",
    "\n",
    "users_df = tr.users_df\n",
    "cvs_df = tr.cvs_df\n",
    "\n",
    "# 1) Ensure we have users\n",
    "assert not users_df.empty, \"users_df is unexpectedly empty after transform!\"\n",
    "\n",
    "# 2) Key identifier should exist & not be all null\n",
    "assert \"CV Partner User ID\" in users_df.columns, \"Missing CV Partner User ID column in users_df\"\n",
    "assert users_df[\"CV Partner User ID\"].notna().any(), \"All user IDs are null!\"\n",
    "\n",
    "# 3) Same number of rows in users_df and cvs_df\n",
    "assert len(users_df) == len(cvs_df), \"users_df and cvs_df row counts differ!\"\n",
    "\n",
    "print(\"✅ Transform checks passed for users_df and cvs_df.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377b6c6",
   "metadata": {},
   "source": [
    "# Step 3 — Load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae8579",
   "metadata": {},
   "source": [
    "## Step 3.1 — Load helpers\n",
    "\n",
    "These utility functions handle boolean parsing, date conversion, \n",
    "foreign key lookups, and normalisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e14f7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_bool(v):\n",
    "    if v is None or (isinstance(v, float) and pd.isna(v)):\n",
    "        return None\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    s = str(v).strip().lower()\n",
    "    return s in (\"true\", \"1\", \"t\", \"yes\", \"y\")\n",
    "\n",
    "def _clean_str(v, default=\"\"):\n",
    "    # Safely turn any value (including NaN/float) into a stripped string (or default)\n",
    "    if v is None or (isinstance(v, float) and pd.isna(v)):\n",
    "        return default\n",
    "    s = str(v).strip()\n",
    "    return s if s else default\n",
    "\n",
    "def _resolve_user_id(conn, email=None, upn=None, external_id=None):\n",
    "    if email:\n",
    "        uid = conn.execute(text(\"SELECT user_id FROM users WHERE lower(email)=lower(:e)\"), {\"e\": email}).scalar()\n",
    "        if uid: return uid\n",
    "    if upn:\n",
    "        uid = conn.execute(text(\"SELECT user_id FROM users WHERE lower(upn)=lower(:u)\"), {\"u\": upn}).scalar()\n",
    "        if uid: return uid\n",
    "    if external_id:\n",
    "        uid = conn.execute(text(\"SELECT user_id FROM users WHERE external_user_id=:x\"), {\"x\": external_id}).scalar()\n",
    "        if uid: return uid\n",
    "    return None\n",
    "\n",
    "def _to_date(v, default=None):\n",
    "    # Accept strings like \"2024-07-01\", \"01/07/2024\", or excel-ish values\n",
    "    if v is None or (isinstance(v, float) and pd.isna(v)) or str(v).strip() == \"\":\n",
    "        return default\n",
    "    dt = pd.to_datetime(str(v).strip(), dayfirst=True, errors=\"coerce\")\n",
    "    return None if pd.isna(dt) else dt.date()\n",
    "        \n",
    "def _cv_id(conn, cv_partner_cv_id: str):\n",
    "    return conn.execute(\n",
    "        text(\"SELECT cv_id FROM cvs WHERE cv_partner_cv_id=:cid\"),\n",
    "        {\"cid\": str(cv_partner_cv_id)}\n",
    "    ).scalar()\n",
    "\n",
    "def _ensure_dim(conn, table: str, name: str, key: str = \"name\", id_col: str = None):\n",
    "    if not name:\n",
    "        return None\n",
    "    if id_col is None:\n",
    "        id_col = (table[4:] + \"_id\") if table.startswith(\"dim_\") else (table.rstrip(\"s\") + \"_id\")\n",
    "    conn.execute(text(f\"INSERT INTO {table} ({key}) VALUES (:n) ON CONFLICT ({key}) DO NOTHING\"), {\"n\": name})\n",
    "    return conn.execute(text(f\"SELECT {id_col} FROM {table} WHERE {key}=:n\"), {\"n\": name}).scalar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e33021",
   "metadata": {},
   "source": [
    "## Step 3.2 — Core entity upserts (Users and CVs)\n",
    "\n",
    "These upsert functions populate the `users` and `cvs` tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea8a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsert_users(conn, df):\n",
    "    print(f\"Upserting {len(df)} users.\")\n",
    "    sql = text(\"\"\"\n",
    "        INSERT INTO users\n",
    "          (cv_partner_user_id, name_multilang, email, upn, external_user_id,\n",
    "           phone_number, landline, birth_year, department, country,\n",
    "           user_created_at, nationality_multilang)\n",
    "        VALUES\n",
    "          (:cv_partner_user_id, CAST(:name_multilang AS JSONB), :email, :upn, :external_user_id,\n",
    "           :phone_number, :landline, :birth_year, :department, :country,\n",
    "           :user_created_at, CAST(:nationality_multilang AS JSONB))\n",
    "        ON CONFLICT (cv_partner_user_id) DO UPDATE\n",
    "        SET name_multilang = EXCLUDED.name_multilang,\n",
    "            email = EXCLUDED.email,\n",
    "            upn = EXCLUDED.upn,\n",
    "            external_user_id = EXCLUDED.external_user_id,\n",
    "            phone_number = EXCLUDED.phone_number,\n",
    "            landline = EXCLUDED.landline,\n",
    "            birth_year = EXCLUDED.birth_year,\n",
    "            department = EXCLUDED.department,\n",
    "            country = EXCLUDED.country,\n",
    "            user_created_at = EXCLUDED.user_created_at,\n",
    "            nationality_multilang = EXCLUDED.nationality_multilang\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        conn.execute(sql, {\n",
    "            \"cv_partner_user_id\": str(r[\"CV Partner User ID\"]),\n",
    "            \"name_multilang\": json.dumps(r[\"Name (multilang)\"]),  # dict -> JSON\n",
    "            \"email\": r.get(\"Email\"),\n",
    "            \"upn\": r.get(\"UPN\"),\n",
    "            \"external_user_id\": r.get(\"External User ID\"),\n",
    "            \"phone_number\": r.get(\"Phone Number\"),\n",
    "            \"landline\": r.get(\"Landline\"),\n",
    "            \"birth_year\": int(r[\"Birth Year\"]) if pd.notna(r.get(\"Birth Year\")) else None,\n",
    "            \"department\": r.get(\"Department\"),\n",
    "            \"country\": r.get(\"Country\"),\n",
    "            \"user_created_at\": r.get(\"User created at\"),\n",
    "            \"nationality_multilang\": json.dumps(r.get(\"nationality_multilang\", {})),\n",
    "        })\n",
    "\n",
    "def upsert_cvs(conn, df):\n",
    "    print(f\"Upserting {len(df)} CVs...\")\n",
    "    sql = text(\"\"\"\n",
    "        INSERT INTO cvs\n",
    "          (cv_partner_cv_id, user_id, title_multilang, years_of_education,\n",
    "           years_since_first_work_experience, has_profile_image,\n",
    "           owns_reference_project, read_privacy_notice,\n",
    "           cv_last_updated_by_owner, cv_last_updated,\n",
    "           sfia_level, cpd_level, cpd_band, cpd_label)\n",
    "        VALUES\n",
    "          (:cv_partner_cv_id, :user_id, CAST(:title_multilang AS JSONB), :yoe, :ysfwe,\n",
    "           :has_img, :owns_ref, :read_priv, :lu_owner, :lu,\n",
    "           :sfia_level, :cpd_level, :cpd_band, :cpd_label)\n",
    "        ON CONFLICT (cv_partner_cv_id) DO UPDATE\n",
    "        SET title_multilang = EXCLUDED.title_multilang,\n",
    "            years_of_education = EXCLUDED.years_of_education,\n",
    "            years_since_first_work_experience = EXCLUDED.years_since_first_work_experience,\n",
    "            has_profile_image = EXCLUDED.has_profile_image,\n",
    "            owns_reference_project = EXCLUDED.owns_reference_project,\n",
    "            read_privacy_notice = EXCLUDED.read_privacy_notice,\n",
    "            cv_last_updated_by_owner = EXCLUDED.cv_last_updated_by_owner,\n",
    "            cv_last_updated = EXCLUDED.cv_last_updated,\n",
    "            sfia_level = EXCLUDED.sfia_level,\n",
    "            cpd_level  = EXCLUDED.cpd_level,\n",
    "            cpd_band   = EXCLUDED.cpd_band,\n",
    "            cpd_label  = EXCLUDED.cpd_label\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        uid = conn.execute(\n",
    "            text(\"SELECT user_id FROM users WHERE cv_partner_user_id=:uid\"),\n",
    "            {\"uid\": str(r[\"CV Partner User ID\"])}\n",
    "        ).scalar()\n",
    "        if uid is None:\n",
    "            print(f\"  ⚠️ Skipping CV {r['CV Partner CV ID']} (unknown user {r['CV Partner User ID']})\")\n",
    "            continue\n",
    "\n",
    "        conn.execute(sql, {\n",
    "            \"cv_partner_cv_id\": str(r[\"CV Partner CV ID\"]),\n",
    "            \"user_id\": uid,\n",
    "            \"title_multilang\": json.dumps(r[\"title_multilang\"]),\n",
    "            \"yoe\": int(r[\"Years of education\"]) if pd.notna(r[\"Years of education\"]) else None,\n",
    "            \"ysfwe\": int(r[\"Years since first work experience\"]) if pd.notna(r[\"Years since first work experience\"]) else None,\n",
    "            \"has_img\": _to_bool(r[\"Has profile image\"]),\n",
    "            \"owns_ref\": _to_bool(r[\"Owns a reference project\"]),\n",
    "            \"read_priv\": _to_bool(r[\"Read and understood privacy notice\"]),\n",
    "            \"lu_owner\": r[\"CV Last updated by owner\"],\n",
    "            \"lu\": r[\"CV Last updated\"],\n",
    "            \"sfia_level\": r.get(\"sfia_level\"),\n",
    "            \"cpd_level\":  r.get(\"cpd_level\"),\n",
    "            \"cpd_band\":   (None if pd.isna(r.get(\"cpd_band\"))  else str(r.get(\"cpd_band\"))),\n",
    "            \"cpd_label\":  (None if pd.isna(r.get(\"cpd_label\")) else str(r.get(\"cpd_label\"))),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b25529",
   "metadata": {},
   "source": [
    "## Step 3.3 — Skills and languages\n",
    "\n",
    "Upserts for technology skills, languages, and related dimension tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c67306ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_technologies(conn, df):\n",
    "    print(f\"Upserting {len(df)} technologies...\")\n",
    "    for _, r in df.iterrows():\n",
    "        tech_name = r[\"Skill name\"]\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO dim_technology (name)\n",
    "            VALUES (:name)\n",
    "            ON CONFLICT (name) DO NOTHING\n",
    "        \"\"\"), {\"name\": tech_name})\n",
    "\n",
    "        tech_id = conn.execute(\n",
    "            text(\"SELECT technology_id FROM dim_technology WHERE name=:n\"),\n",
    "            {\"n\": tech_name}\n",
    "        ).scalar()\n",
    "        if tech_id is None:\n",
    "            print(f\"  ⚠️ Skipping tech link; cannot resolve technology '{tech_name}'\")\n",
    "            continue\n",
    "\n",
    "        cv_id = conn.execute(\n",
    "            text(\"SELECT cv_id FROM cvs WHERE cv_partner_cv_id=:cid\"),\n",
    "            {\"cid\": str(r[\"CV Partner CV ID\"])}\n",
    "        ).scalar()\n",
    "        if cv_id is None:\n",
    "            print(f\"  ⚠️ Skipping tech link; unknown CV {r['CV Partner CV ID']}\")\n",
    "            continue\n",
    "\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO cv_technology (cv_id, technology_id, years_experience, proficiency, is_official_masterdata)\n",
    "            VALUES (:cv, :tech, :yexp, :prof, CAST(:is_md AS JSONB))\n",
    "            ON CONFLICT (cv_id, technology_id) DO UPDATE\n",
    "            SET years_experience = EXCLUDED.years_experience,\n",
    "                proficiency = EXCLUDED.proficiency,\n",
    "                is_official_masterdata = EXCLUDED.is_official_masterdata\n",
    "        \"\"\"), {\n",
    "            \"cv\": cv_id,\n",
    "            \"tech\": tech_id,\n",
    "            \"yexp\": int(r[\"Year experience\"]) if pd.notna(r[\"Year experience\"]) else None,\n",
    "            \"prof\": int(r[\"Proficiency (0-5)\"]) if pd.notna(r[\"Proficiency (0-5)\"]) else None,\n",
    "            \"is_md\": json.dumps(r[\"Is official masterdata (in #{lang})\"])  # dict -> json\n",
    "        })\n",
    "\n",
    "def upsert_languages(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} languages...\")\n",
    "    sql = text(\"\"\"\n",
    "        INSERT INTO cv_language\n",
    "          (cv_id, language_id, level, highlighted, is_official_masterdata, updated, updated_by_owner)\n",
    "        VALUES\n",
    "          (:cv_id, :lang_id, :level, :highlighted, CAST(:is_md AS JSONB), :updated, :updated_by_owner)\n",
    "        ON CONFLICT (cv_id, language_id) DO UPDATE\n",
    "        SET level = EXCLUDED.level,\n",
    "            highlighted = EXCLUDED.highlighted,\n",
    "            is_official_masterdata = EXCLUDED.is_official_masterdata,\n",
    "            updated = EXCLUDED.updated,\n",
    "            updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        lang_id = _ensure_dim(conn, \"dim_language\", r.get(\"Language\"))\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"lang_id\": lang_id,\n",
    "            \"level\": r.get(\"Level\"),\n",
    "            \"highlighted\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"is_md\": json.dumps(r.get(\"Is official masterdata (in #{lang})\", {})),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff34cc",
   "metadata": {},
   "source": [
    "## Step 3.4 — Project experience, work experience, certifications, courses, education, and positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13e851d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsert_project_experiences(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} project experiences...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO project_experience\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         month_from, year_from, month_to, year_to,\n",
    "         customer_int, customer_multilang,\n",
    "         customer_anon_int, customer_anon_multilang,\n",
    "         description_int, description_multilang,\n",
    "         long_description_int, long_description_multilang,\n",
    "         industry_id, project_type_id,\n",
    "         percent_allocated, extent_individual_hours, extent_hours, extent_total_hours,\n",
    "         extent_unit, extent_currency, extent_total, extent_total_currency,\n",
    "         project_area, project_area_unit,\n",
    "         highlighted, updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id,\n",
    "         :m_from, :y_from, :m_to, :y_to,\n",
    "         :cust_int, CAST(:cust_ml AS JSONB),\n",
    "         :cust_anon_int, CAST(:cust_anon_ml AS JSONB),\n",
    "         :desc_int, CAST(:desc_ml AS JSONB),\n",
    "         :ldesc_int, CAST(:ldesc_ml AS JSONB),\n",
    "         :industry_id, :project_type_id,\n",
    "         :pct_alloc, :indiv_hours, :hours, :total_hours,\n",
    "         :extent_unit, :extent_curr, :extent_total, :extent_total_curr,\n",
    "         :proj_area, :proj_area_unit,\n",
    "         :highlighted, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          month_from = EXCLUDED.month_from, year_from = EXCLUDED.year_from,\n",
    "          month_to = EXCLUDED.month_to, year_to = EXCLUDED.year_to,\n",
    "          customer_int = EXCLUDED.customer_int, customer_multilang = EXCLUDED.customer_multilang,\n",
    "          customer_anon_int = EXCLUDED.customer_anon_int, customer_anon_multilang = EXCLUDED.customer_anon_multilang,\n",
    "          description_int = EXCLUDED.description_int, description_multilang = EXCLUDED.description_multilang,\n",
    "          long_description_int = EXCLUDED.long_description_int, long_description_multilang = EXCLUDED.long_description_multilang,\n",
    "          industry_id = EXCLUDED.industry_id, project_type_id = EXCLUDED.project_type_id,\n",
    "          percent_allocated = EXCLUDED.percent_allocated,\n",
    "          extent_individual_hours = EXCLUDED.extent_individual_hours,\n",
    "          extent_hours = EXCLUDED.extent_hours,\n",
    "          extent_total_hours = EXCLUDED.extent_total_hours,\n",
    "          extent_unit = EXCLUDED.extent_unit,\n",
    "          extent_currency = EXCLUDED.extent_currency,\n",
    "          extent_total = EXCLUDED.extent_total,\n",
    "          extent_total_currency = EXCLUDED.extent_total_currency,\n",
    "          project_area = EXCLUDED.project_area, project_area_unit = EXCLUDED.project_area_unit,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        industry_id = _ensure_dim(conn, \"dim_industry\", r.get(\"Industry (int)\"))\n",
    "        projtype_id = _ensure_dim(conn, \"dim_project_type\", r.get(\"Project type (int)\"))\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"m_from\": r.get(\"Month from\"),\n",
    "            \"y_from\": r.get(\"Year from\"),\n",
    "            \"m_to\": r.get(\"Month to\"),\n",
    "            \"y_to\": r.get(\"Year to\"),\n",
    "            \"cust_int\": r.get(\"Customer (int)\"),\n",
    "            \"cust_ml\": json.dumps(r.get(\"Customer (#{lang})\", {})),\n",
    "            \"cust_anon_int\": r.get(\"Customer Anonymized (int)\"),\n",
    "            \"cust_anon_ml\": json.dumps(r.get(\"Customer Anonymized (#{lang})\", {})),\n",
    "            \"desc_int\": r.get(\"Description (int)\"),\n",
    "            \"desc_ml\": json.dumps(r.get(\"Description (#{lang})\", {})),\n",
    "            \"ldesc_int\": r.get(\"Long description (int)\"),\n",
    "            \"ldesc_ml\": json.dumps(r.get(\"Long description (#{lang})\", {})),\n",
    "            \"industry_id\": industry_id,\n",
    "            \"project_type_id\": projtype_id,\n",
    "            \"pct_alloc\": r.get(\"Percent allocated\"),\n",
    "            \"indiv_hours\": r.get(\"Project extent (individual hours)\"),\n",
    "            \"hours\": r.get(\"Project extent (hours)\"),\n",
    "            \"total_hours\": r.get(\"Project extent total (hours)\"),\n",
    "            \"extent_unit\": r.get(\"Project extent\"),\n",
    "            \"extent_curr\": r.get(\"Project extent (currency)\"),\n",
    "            \"extent_total\": r.get(\"Project extent total\"),\n",
    "            \"extent_total_curr\": r.get(\"Project extent total (currency)\"),\n",
    "            \"proj_area\": r.get(\"Project area\"),\n",
    "            \"proj_area_unit\": r.get(\"Project area (unit)\"),\n",
    "            \"highlighted\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_work_experiences(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} work experiences...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO work_experience\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         month_from, year_from, month_to, year_to,\n",
    "         highlighted, employer, description, long_description,\n",
    "         updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id,\n",
    "         :m_from, :y_from, :m_to, :y_to,\n",
    "         :highlighted, :employer, :desc, :ldesc,\n",
    "         :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          month_from = EXCLUDED.month_from, year_from = EXCLUDED.year_from,\n",
    "          month_to = EXCLUDED.month_to, year_to = EXCLUDED.year_to,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          employer = EXCLUDED.employer,\n",
    "          description = EXCLUDED.description,\n",
    "          long_description = EXCLUDED.long_description,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"m_from\": r.get(\"Month from\"),\n",
    "            \"y_from\": r.get(\"Year from\"),\n",
    "            \"m_to\": r.get(\"Month to\"),\n",
    "            \"y_to\": r.get(\"Year to\"),\n",
    "            \"highlighted\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"employer\": r.get(\"Employer\"),\n",
    "            \"desc\": r.get(\"Description\"),\n",
    "            \"ldesc\": r.get(\"Long Description\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_certifications(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} certifications...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO certification\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         month, year, month_expire, year_expire,\n",
    "         updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id, :m, :y, :mexp, :yexp, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          month = EXCLUDED.month, year = EXCLUDED.year,\n",
    "          month_expire = EXCLUDED.month_expire, year_expire = EXCLUDED.year_expire,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"m\": r.get(\"Month\"),\n",
    "            \"y\": r.get(\"Year\"),\n",
    "            \"mexp\": r.get(\"Month expire\"),\n",
    "            \"yexp\": r.get(\"Year expire\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_courses(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} courses...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO course\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         month, year, name, organiser, long_description, highlighted,\n",
    "         is_official_masterdata, attachments, updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id, :m, :y, :name, :org, :ldesc, :hl,\n",
    "         CAST(:is_md AS JSONB), :att, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          month = EXCLUDED.month, year = EXCLUDED.year,\n",
    "          name = EXCLUDED.name, organiser = EXCLUDED.organiser,\n",
    "          long_description = EXCLUDED.long_description,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          is_official_masterdata = EXCLUDED.is_official_masterdata,\n",
    "          attachments = EXCLUDED.attachments,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"m\": r.get(\"Month\"),\n",
    "            \"y\": r.get(\"Year\"),\n",
    "            \"name\": r.get(\"Name\"),\n",
    "            \"org\": r.get(\"Organiser\"),\n",
    "            \"ldesc\": r.get(\"Long description\"),\n",
    "            \"hl\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"is_md\": json.dumps(r.get(\"Is official masterdata (in #{lang})\", {})),\n",
    "            \"att\": r.get(\"Attachments\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_educations(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} educations...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO education\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         month_from, year_from, month_to, year_to,\n",
    "         highlighted, attachments, place_of_study, degree, description,\n",
    "         updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id,\n",
    "         :m_from, :y_from, :m_to, :y_to,\n",
    "         :hl, :att, :place, :deg, :desc,\n",
    "         :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          month_from = EXCLUDED.month_from, year_from = EXCLUDED.year_from,\n",
    "          month_to = EXCLUDED.month_to, year_to = EXCLUDED.year_to,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          attachments = EXCLUDED.attachments,\n",
    "          place_of_study = EXCLUDED.place_of_study,\n",
    "          degree = EXCLUDED.degree,\n",
    "          description = EXCLUDED.description,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"m_from\": r.get(\"Month from\"),\n",
    "            \"y_from\": r.get(\"Year from\"),\n",
    "            \"m_to\": r.get(\"Month to\"),\n",
    "            \"y_to\": r.get(\"Year to\"),\n",
    "            \"hl\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"att\": r.get(\"Attachments\"),\n",
    "            \"place\": r.get(\"Place of study\"),\n",
    "            \"deg\": r.get(\"Degree\"),\n",
    "            \"desc\": r.get(\"Description\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_positions(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} positions...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO position\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         year_from, year_to, highlighted, name, description,\n",
    "         updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id, :y_from, :y_to, :hl, :name, :desc, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          year_from = EXCLUDED.year_from, year_to = EXCLUDED.year_to,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          name = EXCLUDED.name, description = EXCLUDED.description,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"y_from\": r.get(\"Year from\"),\n",
    "            \"y_to\": r.get(\"Year to\"),\n",
    "            \"hl\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"name\": r.get(\"Name\"),\n",
    "            \"desc\": r.get(\"Description\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_blogs(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} blogs/publications...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO blog_publication\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         name, description, highlighted, updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id, :name, :desc, :hl, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          name = EXCLUDED.name, description = EXCLUDED.description,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"name\": r.get(\"Name\"),\n",
    "            \"desc\": r.get(\"Description\"),\n",
    "            \"hl\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_cv_roles(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} cv roles...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO cv_role\n",
    "        (cv_id, name, description, highlighted, updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :name, :desc, :hl, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, name) DO UPDATE\n",
    "      SET description = EXCLUDED.description,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"name\": r.get(\"Name\"),\n",
    "            \"desc\": r.get(\"Description\"),\n",
    "            \"hl\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_key_qualifications(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} key qualifications...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO key_qualification\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         label, summary, short_description, updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id, :label, :summary, :short_desc, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          label = EXCLUDED.label, summary = EXCLUDED.summary,\n",
    "          short_description = EXCLUDED.short_description,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"label\": r.get(\"Label\"),\n",
    "            \"summary\": r.get(\"Summary of Qualifications\"),\n",
    "            \"short_desc\": r.get(\"Short description\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac67bad",
   "metadata": {},
   "source": [
    "## Step 3.5 — Security clearance and availability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d092d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_sc_clearance(conn, df: pd.DataFrame):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    for _, r in df.iterrows():\n",
    "        uid = _resolve_user_id(conn, r.get(\"Email\"), r.get(\"UPN\"), r.get(\"External User ID\"))\n",
    "        if not uid:\n",
    "            continue\n",
    "\n",
    "        clr = _clean_str(r.get(\"Clearance\"), \"None\") or \"None\"\n",
    "        conn.execute(text(\"INSERT INTO dim_clearance(name) VALUES (:n) ON CONFLICT(name) DO NOTHING\"),\n",
    "                     {\"n\": clr})\n",
    "        clr_id = conn.execute(text(\"SELECT clearance_id FROM dim_clearance WHERE name=:n\"),\n",
    "                              {\"n\": clr}).scalar()\n",
    "\n",
    "        # Default valid_from if missing so we never violate NOT NULL\n",
    "        vf = _to_date(r.get(\"Valid From\"), default=date(1900, 1, 1))\n",
    "        vt = _to_date(r.get(\"Valid To\"))\n",
    "        vb = _clean_str(r.get(\"Verified By\"), None) or None\n",
    "        no = _clean_str(r.get(\"Notes\"), None) or None\n",
    "\n",
    "        # If both present and vt < vf (bad data), drop vt\n",
    "        if vt and vf and vt < vf:\n",
    "            vt = None\n",
    "\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO user_clearance(user_id, clearance_id, valid_from, valid_to, verified_by, notes)\n",
    "            VALUES (:u, :c, :vf, :vt, :vb, :no)\n",
    "            ON CONFLICT (user_id, clearance_id, valid_from) DO UPDATE\n",
    "            SET valid_to    = EXCLUDED.valid_to,\n",
    "                verified_by = EXCLUDED.verified_by,\n",
    "                notes       = EXCLUDED.notes\n",
    "        \"\"\"), {\"u\": uid, \"c\": clr_id, \"vf\": vf, \"vt\": vt, \"vb\": vb, \"no\": no})\n",
    "\n",
    "\n",
    "\n",
    "def upsert_availability(conn, df: pd.DataFrame):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    sql = text(\"\"\"\n",
    "        INSERT INTO user_availability(user_id, date, percent_available, source)\n",
    "        VALUES (:u, :d, :p, :s)\n",
    "        ON CONFLICT (user_id, date) DO UPDATE\n",
    "        SET percent_available = EXCLUDED.percent_available,\n",
    "            source            = EXCLUDED.source,\n",
    "            updated_at        = NOW()\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        uid = _resolve_user_id(conn, r.get(\"Email\"), r.get(\"UPN\"), r.get(\"External User ID\"))\n",
    "        if not uid:\n",
    "            continue\n",
    "        # percent can come as float/NaN — clamp to [0,100]\n",
    "        raw = r.get(\"Percent Available\")\n",
    "        p = 0 if (raw is None or (isinstance(raw, float) and pd.isna(raw))) else int(float(raw))\n",
    "        p = max(0, min(100, p))\n",
    "        conn.execute(sql, {\n",
    "            \"u\": uid,\n",
    "            \"d\": _clean_str(r.get(\"Date\"), None) or None,\n",
    "            \"p\": p,\n",
    "            \"s\": _clean_str(r.get(\"Source\"), \"Fake generator\"),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d26263",
   "metadata": {},
   "source": [
    "## Step 3.6 — Load orchestrator\n",
    "\n",
    "The `load()` function runs all upserts in the correct sequence inside a \n",
    "single database transaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95b8135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(clean_data, engine):\n",
    "    \"\"\"\n",
    "    Loads each cleaned DataFrame into the database using upsert logic.\n",
    "    \"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        if getattr(clean_data, 'users_df', None) is not None:\n",
    "            upsert_users(conn, clean_data.users_df)\n",
    "        if getattr(clean_data, 'cvs_df', None) is not None:\n",
    "            upsert_cvs(conn, clean_data.cvs_df)\n",
    "        if getattr(clean_data, 'technologies_df', None) is not None:\n",
    "            upsert_technologies(conn, clean_data.technologies_df)\n",
    "        if getattr(clean_data, 'languages_df', None) is not None:\n",
    "            upsert_languages(conn, clean_data.languages_df)\n",
    "        if getattr(clean_data, 'project_experiences_df', None) is not None:\n",
    "            upsert_project_experiences(conn, clean_data.project_experiences_df)\n",
    "        if getattr(clean_data, 'work_experiences_df', None) is not None:\n",
    "            upsert_work_experiences(conn, clean_data.work_experiences_df)\n",
    "        if getattr(clean_data, 'certifications_df', None) is not None:\n",
    "            upsert_certifications(conn, clean_data.certifications_df)\n",
    "        if getattr(clean_data, 'courses_df', None) is not None:\n",
    "            upsert_courses(conn, clean_data.courses_df)\n",
    "        if getattr(clean_data, 'educations_df', None) is not None:\n",
    "            upsert_educations(conn, clean_data.educations_df)\n",
    "        if getattr(clean_data, 'positions_df', None) is not None:\n",
    "            upsert_positions(conn, clean_data.positions_df)\n",
    "        if getattr(clean_data, 'blogs_df', None) is not None:\n",
    "            upsert_blogs(conn, clean_data.blogs_df)\n",
    "        if getattr(clean_data, 'cv_roles_df', None) is not None:\n",
    "            upsert_cv_roles(conn, clean_data.cv_roles_df)\n",
    "        if getattr(clean_data, 'key_qualifications_df', None) is not None:\n",
    "            upsert_key_qualifications(conn, clean_data.key_qualifications_df)\n",
    "        if getattr(clean_data, 'sc_clearance_df', None) is not None:\n",
    "            upsert_sc_clearance(conn, clean_data.sc_clearance_df)\n",
    "        if getattr(clean_data, 'availability_df', None) is not None:\n",
    "            upsert_availability(conn, clean_data.availability_df)\n",
    "    print(\"✅ Load complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c025fc2e",
   "metadata": {},
   "source": [
    "# Step 4 — Database Setup\n",
    "\n",
    "These steps configure PostgreSQL connection settings, create the database if \n",
    "missing, and apply schema files from `sql/*.sql`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8be3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_db_config_txt(path=\"db_config.txt\"):\n",
    "    db = {}\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if \"=\" in line:\n",
    "                    k, v = line.strip().split(\"=\", 1)\n",
    "                    db[k.strip()] = v.strip()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return db\n",
    "\n",
    "def compose_settings():\n",
    "    # precedence: ENV > db_config.txt > defaults\n",
    "    defaults = dict(host=\"localhost\", port=5432, database=\"flowcase_demo\",\n",
    "                    user=\"postgres\", password=\"postgres\")\n",
    "    file_cfg = read_db_config_txt()\n",
    "\n",
    "    env_cfg = dict(\n",
    "        host=os.getenv(\"PGHOST\"),\n",
    "        port=os.getenv(\"PGPORT\"),\n",
    "        database=os.getenv(\"PGDATABASE\"),\n",
    "        user=os.getenv(\"PGUSER\"),\n",
    "        password=os.getenv(\"PGPASSWORD\"),\n",
    "    )\n",
    "    # drop Nones\n",
    "    env_cfg = {k:v for k,v in env_cfg.items() if v is not None}\n",
    "    # coerce port\n",
    "    if \"port\" in env_cfg:\n",
    "        try: env_cfg[\"port\"] = int(env_cfg[\"port\"])\n",
    "        except: env_cfg.pop(\"port\", None)\n",
    "\n",
    "    db = {**defaults, **file_cfg, **env_cfg}\n",
    "\n",
    "    settings = {\n",
    "        \"data_source\": \"fake\",\n",
    "        \"base_folder\": \"cv_reports\",\n",
    "        \"db\": db,\n",
    "        # let utils apply ALL sql/*.sql automatically\n",
    "        \"schema\": {\"apply_all_sql_in_sql_folder\": True, \"folder\": \"sql\"}\n",
    "    }\n",
    "    return settings\n",
    "\n",
    "def ensure_database_exists(db):\n",
    "    try:\n",
    "        conn = psycopg2.connect(dbname=\"postgres\",\n",
    "                                user=db[\"user\"], password=db[\"password\"],\n",
    "                                host=db[\"host\"], port=db[\"port\"])\n",
    "        conn.autocommit = True\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT 1 FROM pg_database WHERE datname = %s\", (db[\"database\"],))\n",
    "        if not cur.fetchone():\n",
    "            print(f\"Database '{db['database']}' does not exist. Creating...\")\n",
    "            cur.execute(f\"CREATE DATABASE {db['database']};\")\n",
    "        cur.close(); conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not check/create database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0673d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database_engine(db_settings: dict):\n",
    "    url = (\n",
    "        \"postgresql+psycopg2://\"\n",
    "        f\"{db_settings['user']}:{db_settings['password']}\"\n",
    "        f\"@{db_settings['host']}:{db_settings['port']}/{db_settings['database']}\"\n",
    "    )\n",
    "    return create_engine(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc7c76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def setup_database_schema_if_needed(engine, settings: dict):\n",
    "    schema_cfg = settings.get(\"schema\", {})\n",
    "    if not schema_cfg.get(\"apply_all_sql_in_sql_folder\"):\n",
    "        return\n",
    "\n",
    "    sql_folder = Path(schema_cfg.get(\"folder\", \"sql\"))\n",
    "    if not sql_folder.exists():\n",
    "        print(f\"Schema folder {sql_folder} does not exist. Skipping schema setup.\")\n",
    "        return\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        for path in sorted(sql_folder.glob(\"*.sql\")):\n",
    "            print(f\"Applying schema from {path.name}...\")\n",
    "            conn.execute(text(path.read_text()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a489cd8",
   "metadata": {},
   "source": [
    "# Step 5 — Run Full ETL Pipeline\n",
    "\n",
    "This executes:\n",
    "\n",
    "1. Extract  \n",
    "2. Transform  \n",
    "3. Load  \n",
    "\n",
    "And confirms everything worked end-to-end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b91cda42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying schema from 01_schema.sql...\n",
      "Applying schema from 02_cv_search_profile_mv.sql...\n",
      "\n",
      "==================== Finding the latest quarterly report folder ====================\n",
      "Quarterly folders found: ['Q42025']\n",
      "Using latest quarterly folder: Q42025\n",
      "\n",
      "==================== Loading CSV files from cv_reports/Q42025 ====================\n",
      "Found 15 CSV files.\n",
      "  Loaded certifications.csv -> (1006, 22)\n",
      "  Loaded project_experiences.csv -> (1501, 45)\n",
      "  Loaded blogs.csv -> (758, 21)\n",
      "  Loaded availability_report.csv -> (30000, 7)\n",
      "  Loaded cv_roles.csv -> (1001, 19)\n",
      "  Loaded work_experiences.csv -> (1484, 26)\n",
      "  Loaded educations.csv -> (757, 27)\n",
      "  Loaded user_report.csv -> (500, 26)\n",
      "  Loaded courses.csv -> (1446, 26)\n",
      "  Loaded key_qualifications.csv -> (485, 21)\n",
      "  Loaded positions.csv -> (1264, 23)\n",
      "  Loaded technologies.csv -> (2220, 20)\n",
      "  Loaded sc_clearance.csv -> (500, 9)\n",
      "  Loaded languages.csv -> (996, 22)\n",
      "  Loaded usage_report.csv -> (500, 51)\n",
      "Using data folder: cv_reports/Q42025\n",
      "Upserting 500 users.\n",
      "Upserting 500 CVs...\n",
      "Upserting 2220 technologies...\n",
      "Upserting 996 languages...\n",
      "Upserting 1501 project experiences...\n",
      "Upserting 1484 work experiences...\n",
      "Upserting 1006 certifications...\n",
      "Upserting 1446 courses...\n",
      "Upserting 757 educations...\n",
      "Upserting 1264 positions...\n",
      "Upserting 758 blogs/publications...\n",
      "Upserting 1001 cv roles...\n",
      "Upserting 485 key qualifications...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3p/rr2nrbcj6j79v6mwqtwtdzbw0000gn/T/ipykernel_82427/3417465587.py:32: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  dt = pd.to_datetime(str(v).strip(), dayfirst=True, errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Load complete.\n",
      "✅ Flowcase ETL (manual fake) complete.\n"
     ]
    }
   ],
   "source": [
    "settings = compose_settings()\n",
    "db_settings = settings[\"db\"]\n",
    "\n",
    "ensure_database_exists(db_settings)\n",
    "engine = create_database_engine(db_settings)\n",
    "\n",
    "setup_database_schema_if_needed(engine, settings)\n",
    "\n",
    "ex = extract(settings)\n",
    "print(f\"Using data folder: {getattr(ex, 'data_dir', 'unknown')}\")\n",
    "tr = transform(ex)\n",
    "\n",
    "load(tr, engine)\n",
    "print(\"✅ Flowcase ETL (manual fake) complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b25f8",
   "metadata": {},
   "source": [
    "## Step 5.1 — Basic database verification\n",
    "\n",
    "After running the full ETL, we check that key tables contain data as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac85034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users in DB: 500\n",
      "CVs in DB: 500\n",
      "CV–technology links in DB: 2220\n",
      "✅ Basic load checks passed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with engine.connect() as conn:\n",
    "    users_count = conn.execute(text(\"SELECT COUNT(*) FROM users\")).scalar()\n",
    "    cvs_count = conn.execute(text(\"SELECT COUNT(*) FROM cvs\")).scalar()\n",
    "    tech_links = conn.execute(text(\"SELECT COUNT(*) FROM cv_technology\")).scalar()\n",
    "\n",
    "print(f\"Users in DB: {users_count}\")\n",
    "print(f\"CVs in DB: {cvs_count}\")\n",
    "print(f\"CV–technology links in DB: {tech_links}\")\n",
    "\n",
    "assert users_count > 0, \"No users loaded!\"\n",
    "assert cvs_count > 0, \"No CVs loaded!\"\n",
    "print(\"✅ Basic load checks passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3dc2a",
   "metadata": {},
   "source": [
    "# Step 6 - materialised search view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1626084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 6 — Refresh materialised search view ====================\n",
      "\n",
      "Sample rows from cv_search_profile_mv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cv_partner_user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>cv_id</th>\n",
       "      <th>cv_title</th>\n",
       "      <th>sfia_level</th>\n",
       "      <th>cpd_label</th>\n",
       "      <th>technologies</th>\n",
       "      <th>max_years_experience</th>\n",
       "      <th>clearance</th>\n",
       "      <th>latest_availability_date</th>\n",
       "      <th>latest_percent_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5b69cd14</td>\n",
       "      <td>Danielle Johnson</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal C# Developer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>.NET, Azure, Kubernetes, Python, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>439b63ae</td>\n",
       "      <td>Joshua Walker</td>\n",
       "      <td>2</td>\n",
       "      <td>Principal Data Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>C#, Kafka, Node.js, Snowflake, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bc24ae58</td>\n",
       "      <td>Jill Rhodes</td>\n",
       "      <td>3</td>\n",
       "      <td>Senior C# Developer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>.NET, Node.js, React, Snowflake, TypeScript, dbt</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>711200c6</td>\n",
       "      <td>Patricia Miller</td>\n",
       "      <td>4</td>\n",
       "      <td>Principal Analytics Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>Airflow, C#, JavaScript, Kafka, Spark, Terraform</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a7986c12</td>\n",
       "      <td>Robert Johnson</td>\n",
       "      <td>5</td>\n",
       "      <td>Associate ML Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>Airflow, Node.js, Python, Spark</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>aea2bd5b</td>\n",
       "      <td>Jeffery Wagner</td>\n",
       "      <td>6</td>\n",
       "      <td>Consultant Data Platform Engineer</td>\n",
       "      <td>3</td>\n",
       "      <td>CPD2L</td>\n",
       "      <td>Airflow, JavaScript, Power BI, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>f3e19f78</td>\n",
       "      <td>Anthony Gonzalez</td>\n",
       "      <td>7</td>\n",
       "      <td>Principal Azure Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>C#, Databricks, SQL, Snowflake, Terraform</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2ced75ad</td>\n",
       "      <td>Debra Gardner</td>\n",
       "      <td>8</td>\n",
       "      <td>Senior AI Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Airflow, JavaScript, Oracle, Power BI, SQL, Te...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4ba9d1b6</td>\n",
       "      <td>Jeffrey Lawrence</td>\n",
       "      <td>9</td>\n",
       "      <td>Associate Backend Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>AWS, Azure, C#, Oracle, Power BI, TypeScript</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>6e32ee35</td>\n",
       "      <td>Lisa Smith</td>\n",
       "      <td>10</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>.NET, Airflow, Azure, React, Snowflake</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id cv_partner_user_id         user_name  cv_id  \\\n",
       "0        1           5b69cd14  Danielle Johnson      1   \n",
       "1        2           439b63ae     Joshua Walker      2   \n",
       "2        3           bc24ae58       Jill Rhodes      3   \n",
       "3        4           711200c6   Patricia Miller      4   \n",
       "4        5           a7986c12    Robert Johnson      5   \n",
       "5        6           aea2bd5b    Jeffery Wagner      6   \n",
       "6        7           f3e19f78  Anthony Gonzalez      7   \n",
       "7        8           2ced75ad     Debra Gardner      8   \n",
       "8        9           4ba9d1b6  Jeffrey Lawrence      9   \n",
       "9       10           6e32ee35        Lisa Smith     10   \n",
       "\n",
       "                            cv_title  sfia_level cpd_label  \\\n",
       "0             Principal C# Developer           5     CPD3L   \n",
       "1            Principal Data Engineer           5     CPD3L   \n",
       "2                Senior C# Developer           4     CPD3E   \n",
       "3       Principal Analytics Engineer           5     CPD3L   \n",
       "4              Associate ML Engineer           2     CPD1E   \n",
       "5  Consultant Data Platform Engineer           3     CPD2L   \n",
       "6           Principal Azure Engineer           5     CPD3L   \n",
       "7                 Senior AI Engineer           4     CPD3E   \n",
       "8         Associate Backend Engineer           2     CPD1E   \n",
       "9           Associate Data Scientist           2     CPD1E   \n",
       "\n",
       "                                        technologies  max_years_experience  \\\n",
       "0               .NET, Azure, Kubernetes, Python, dbt                    15   \n",
       "1                 C#, Kafka, Node.js, Snowflake, dbt                    15   \n",
       "2   .NET, Node.js, React, Snowflake, TypeScript, dbt                     9   \n",
       "3   Airflow, C#, JavaScript, Kafka, Spark, Terraform                    15   \n",
       "4                    Airflow, Node.js, Python, Spark                    15   \n",
       "5                 Airflow, JavaScript, Power BI, dbt                    15   \n",
       "6          C#, Databricks, SQL, Snowflake, Terraform                    15   \n",
       "7  Airflow, JavaScript, Oracle, Power BI, SQL, Te...                    12   \n",
       "8       AWS, Azure, C#, Oracle, Power BI, TypeScript                    15   \n",
       "9             .NET, Airflow, Azure, React, Snowflake                    15   \n",
       "\n",
       "  clearance latest_availability_date  latest_percent_available  \n",
       "0      None               2026-01-26                        23  \n",
       "1      None               2026-01-26                        74  \n",
       "2      None               2026-01-26                        64  \n",
       "3        SC               2026-01-26                        66  \n",
       "4        SC               2026-01-26                        91  \n",
       "5        SC               2026-01-26                         0  \n",
       "6      None               2026-01-26                        37  \n",
       "7      None               2026-01-26                        20  \n",
       "8      None               2026-01-26                        21  \n",
       "9      None               2026-01-26                        57  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_step(\"Step 6 — Refresh materialised search view\")\n",
    "\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"REFRESH MATERIALIZED VIEW cv_search_profile_mv;\"))\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    mv_sample = pd.read_sql(\n",
    "        \"SELECT * FROM cv_search_profile_mv ORDER BY user_id LIMIT 10;\",\n",
    "        conn,\n",
    "    )\n",
    "\n",
    "print(\"\\nSample rows from cv_search_profile_mv:\")\n",
    "display(mv_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d34e6",
   "metadata": {},
   "source": [
    "## Step 6.1 - Example queries against cv_search_profile_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89c9ed76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Example queries against cv_search_profile_mv ====================\n",
      "\n",
      "Available SC (or above) candidates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cv_partner_user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>cv_id</th>\n",
       "      <th>cv_title</th>\n",
       "      <th>sfia_level</th>\n",
       "      <th>cpd_label</th>\n",
       "      <th>technologies</th>\n",
       "      <th>max_years_experience</th>\n",
       "      <th>clearance</th>\n",
       "      <th>latest_availability_date</th>\n",
       "      <th>latest_percent_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>df5d3f82</td>\n",
       "      <td>Leslie Walton</td>\n",
       "      <td>126</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>C#, JavaScript, React</td>\n",
       "      <td>11</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>293</td>\n",
       "      <td>f8f4ef54</td>\n",
       "      <td>Nicole Sanchez</td>\n",
       "      <td>293</td>\n",
       "      <td>Senior DevOps Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Docker, Node.js, Oracle, React, Terraform</td>\n",
       "      <td>12</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462</td>\n",
       "      <td>79b08fa6</td>\n",
       "      <td>Courtney Berger</td>\n",
       "      <td>462</td>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Azure, Kafka, Power BI, Terraform, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>930ca7b5</td>\n",
       "      <td>Kimberly Moreno</td>\n",
       "      <td>62</td>\n",
       "      <td>Senior Data Architect</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>JavaScript, Kafka, Kubernetes, Oracle, Spark, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>294</td>\n",
       "      <td>3f9be908</td>\n",
       "      <td>Steven Bishop</td>\n",
       "      <td>294</td>\n",
       "      <td>Principal Data Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>Databricks, Kafka, dbt</td>\n",
       "      <td>9</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>173</td>\n",
       "      <td>718baf55</td>\n",
       "      <td>Mark Lin</td>\n",
       "      <td>173</td>\n",
       "      <td>Principal AWS Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>.NET, Airflow, Python, SQL</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>487</td>\n",
       "      <td>5712f033</td>\n",
       "      <td>Madison Blankenship</td>\n",
       "      <td>487</td>\n",
       "      <td>Senior Azure Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Kubernetes, Node.js, Snowflake, Terraform</td>\n",
       "      <td>11</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>499</td>\n",
       "      <td>3e9c87fe</td>\n",
       "      <td>Mitchell Ramos</td>\n",
       "      <td>499</td>\n",
       "      <td>Lead Cloud Architect</td>\n",
       "      <td>6</td>\n",
       "      <td>CPD4E</td>\n",
       "      <td>Airflow, Docker, SQL, Terraform, TypeScript</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>80cdaa13</td>\n",
       "      <td>Christopher Davis</td>\n",
       "      <td>14</td>\n",
       "      <td>Principal Solution Architect</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>Databricks, Kafka, Python, Snowflake, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>198</td>\n",
       "      <td>d93e4efd</td>\n",
       "      <td>Aaron Mitchell</td>\n",
       "      <td>198</td>\n",
       "      <td>Lead Data Platform Engineer</td>\n",
       "      <td>6</td>\n",
       "      <td>CPD4E</td>\n",
       "      <td>C#, Power BI, Python, TypeScript</td>\n",
       "      <td>12</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500</td>\n",
       "      <td>5cd17635</td>\n",
       "      <td>Stephanie Foley</td>\n",
       "      <td>500</td>\n",
       "      <td>Senior Databricks Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Node.js, Oracle, Power BI</td>\n",
       "      <td>12</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>466</td>\n",
       "      <td>b2e9128f</td>\n",
       "      <td>Kenneth Burgess</td>\n",
       "      <td>466</td>\n",
       "      <td>Principal Azure Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>C#, GCP, SQL</td>\n",
       "      <td>10</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>125</td>\n",
       "      <td>14e651fc</td>\n",
       "      <td>Emily Evans</td>\n",
       "      <td>125</td>\n",
       "      <td>Principal .NET Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>.NET, AWS, Kubernetes, React, Spark, dbt</td>\n",
       "      <td>10</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25</td>\n",
       "      <td>4022937f</td>\n",
       "      <td>Cynthia Diaz</td>\n",
       "      <td>25</td>\n",
       "      <td>Lead Enterprise Architect</td>\n",
       "      <td>6</td>\n",
       "      <td>CPD4E</td>\n",
       "      <td>JavaScript, Kafka, Oracle, Spark, Terraform</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>c40873c0</td>\n",
       "      <td>Chelsea Hernandez</td>\n",
       "      <td>60</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>AWS, C#, Kafka, SQL, Snowflake</td>\n",
       "      <td>12</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79</td>\n",
       "      <td>dfccd9c7</td>\n",
       "      <td>Matthew Chapman</td>\n",
       "      <td>79</td>\n",
       "      <td>Principal Frontend Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>AWS, C#, React, Spark, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>261</td>\n",
       "      <td>06dc916f</td>\n",
       "      <td>Zoe Bell</td>\n",
       "      <td>261</td>\n",
       "      <td>Principal Databricks Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>Airflow, Databricks, Spark</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>217</td>\n",
       "      <td>a42602dc</td>\n",
       "      <td>Gregory Rubio</td>\n",
       "      <td>217</td>\n",
       "      <td>Senior Data Platform Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>AWS, Airflow, JavaScript</td>\n",
       "      <td>10</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>324</td>\n",
       "      <td>6dabf9df</td>\n",
       "      <td>Monique Andrews</td>\n",
       "      <td>324</td>\n",
       "      <td>Senior Data Platform Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Airflow, React, Spark</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>389</td>\n",
       "      <td>117e53e7</td>\n",
       "      <td>Victoria Durham</td>\n",
       "      <td>389</td>\n",
       "      <td>Principal .NET Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>.NET, GCP, Kubernetes, Snowflake, TypeScript</td>\n",
       "      <td>10</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id cv_partner_user_id            user_name  cv_id  \\\n",
       "0       126           df5d3f82        Leslie Walton    126   \n",
       "1       293           f8f4ef54       Nicole Sanchez    293   \n",
       "2       462           79b08fa6      Courtney Berger    462   \n",
       "3        62           930ca7b5      Kimberly Moreno     62   \n",
       "4       294           3f9be908        Steven Bishop    294   \n",
       "5       173           718baf55             Mark Lin    173   \n",
       "6       487           5712f033  Madison Blankenship    487   \n",
       "7       499           3e9c87fe       Mitchell Ramos    499   \n",
       "8        14           80cdaa13    Christopher Davis     14   \n",
       "9       198           d93e4efd       Aaron Mitchell    198   \n",
       "10      500           5cd17635      Stephanie Foley    500   \n",
       "11      466           b2e9128f      Kenneth Burgess    466   \n",
       "12      125           14e651fc          Emily Evans    125   \n",
       "13       25           4022937f         Cynthia Diaz     25   \n",
       "14       60           c40873c0    Chelsea Hernandez     60   \n",
       "15       79           dfccd9c7      Matthew Chapman     79   \n",
       "16      261           06dc916f             Zoe Bell    261   \n",
       "17      217           a42602dc        Gregory Rubio    217   \n",
       "18      324           6dabf9df      Monique Andrews    324   \n",
       "19      389           117e53e7      Victoria Durham    389   \n",
       "\n",
       "                         cv_title  sfia_level cpd_label  \\\n",
       "0            Senior Data Engineer           4     CPD3E   \n",
       "1          Senior DevOps Engineer           4     CPD3E   \n",
       "2         Senior Python Developer           4     CPD3E   \n",
       "3           Senior Data Architect           4     CPD3E   \n",
       "4         Principal Data Engineer           5     CPD3L   \n",
       "5          Principal AWS Engineer           5     CPD3L   \n",
       "6           Senior Azure Engineer           4     CPD3E   \n",
       "7            Lead Cloud Architect           6     CPD4E   \n",
       "8    Principal Solution Architect           5     CPD3L   \n",
       "9     Lead Data Platform Engineer           6     CPD4E   \n",
       "10     Senior Databricks Engineer           4     CPD3E   \n",
       "11       Principal Azure Engineer           5     CPD3L   \n",
       "12        Principal .NET Engineer           5     CPD3L   \n",
       "13      Lead Enterprise Architect           6     CPD4E   \n",
       "14           Senior Data Engineer           4     CPD3E   \n",
       "15    Principal Frontend Engineer           5     CPD3L   \n",
       "16  Principal Databricks Engineer           5     CPD3L   \n",
       "17  Senior Data Platform Engineer           4     CPD3E   \n",
       "18  Senior Data Platform Engineer           4     CPD3E   \n",
       "19        Principal .NET Engineer           5     CPD3L   \n",
       "\n",
       "                                         technologies  max_years_experience  \\\n",
       "0                               C#, JavaScript, React                    11   \n",
       "1           Docker, Node.js, Oracle, React, Terraform                    12   \n",
       "2              Azure, Kafka, Power BI, Terraform, dbt                    15   \n",
       "3   JavaScript, Kafka, Kubernetes, Oracle, Spark, ...                    14   \n",
       "4                              Databricks, Kafka, dbt                     9   \n",
       "5                          .NET, Airflow, Python, SQL                    14   \n",
       "6           Kubernetes, Node.js, Snowflake, Terraform                    11   \n",
       "7         Airflow, Docker, SQL, Terraform, TypeScript                    14   \n",
       "8           Databricks, Kafka, Python, Snowflake, dbt                    15   \n",
       "9                    C#, Power BI, Python, TypeScript                    12   \n",
       "10                          Node.js, Oracle, Power BI                    12   \n",
       "11                                       C#, GCP, SQL                    10   \n",
       "12           .NET, AWS, Kubernetes, React, Spark, dbt                    10   \n",
       "13        JavaScript, Kafka, Oracle, Spark, Terraform                    14   \n",
       "14                     AWS, C#, Kafka, SQL, Snowflake                    12   \n",
       "15                         AWS, C#, React, Spark, dbt                    15   \n",
       "16                         Airflow, Databricks, Spark                    14   \n",
       "17                           AWS, Airflow, JavaScript                    10   \n",
       "18                              Airflow, React, Spark                    15   \n",
       "19       .NET, GCP, Kubernetes, Snowflake, TypeScript                    10   \n",
       "\n",
       "   clearance latest_availability_date  latest_percent_available  \n",
       "0         SC               2026-01-26                        93  \n",
       "1         SC               2026-01-26                        92  \n",
       "2         SC               2026-01-26                        91  \n",
       "3         SC               2026-01-26                        89  \n",
       "4         SC               2026-01-26                        84  \n",
       "5         SC               2026-01-26                        83  \n",
       "6         SC               2026-01-26                        83  \n",
       "7         SC               2026-01-26                        81  \n",
       "8         SC               2026-01-26                        81  \n",
       "9         SC               2026-01-26                        80  \n",
       "10        SC               2026-01-26                        79  \n",
       "11        SC               2026-01-26                        78  \n",
       "12        SC               2026-01-26                        77  \n",
       "13        SC               2026-01-26                        74  \n",
       "14        SC               2026-01-26                        74  \n",
       "15        SC               2026-01-26                        73  \n",
       "16        SC               2026-01-26                        73  \n",
       "17        SC               2026-01-26                        71  \n",
       "18        SC               2026-01-26                        69  \n",
       "19        SC               2026-01-26                        68  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_step(\"Example queries against cv_search_profile_mv\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    sc_available = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT *\n",
    "        FROM cv_search_profile_mv\n",
    "        WHERE\n",
    "            (clearance = 'SC' OR clearance IS NULL) AND\n",
    "            sfia_level >= 4 AND\n",
    "            latest_percent_available >= 50\n",
    "        ORDER BY latest_percent_available DESC, sfia_level DESC\n",
    "        LIMIT 20;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "    )\n",
    "\n",
    "print(\"\\nAvailable SC (or above) candidates:\")\n",
    "display(sc_available)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c43c5",
   "metadata": {},
   "source": [
    "# Step 7 — Explore Validations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d8e635",
   "metadata": {},
   "source": [
    "## 7.1 Pick a random user + CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ae51c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 7.1 — Pick one random user + CV ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cv_partner_user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>department</th>\n",
       "      <th>country</th>\n",
       "      <th>cv_id</th>\n",
       "      <th>cv_partner_cv_id</th>\n",
       "      <th>cv_title</th>\n",
       "      <th>sfia_level</th>\n",
       "      <th>cpd_level</th>\n",
       "      <th>cpd_band</th>\n",
       "      <th>cpd_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>86d64648</td>\n",
       "      <td>Alejandro Vaughan</td>\n",
       "      <td>alejandro.vaughan@mail.test</td>\n",
       "      <td>Cloud Engineering</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>300</td>\n",
       "      <td>cv_86d64648</td>\n",
       "      <td>Senior Azure Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD3E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id cv_partner_user_id               name                        email  \\\n",
       "0      300           86d64648  Alejandro Vaughan  alejandro.vaughan@mail.test   \n",
       "\n",
       "          department  country  cv_id cv_partner_cv_id               cv_title  \\\n",
       "0  Cloud Engineering  Ireland    300      cv_86d64648  Senior Azure Engineer   \n",
       "\n",
       "   sfia_level  cpd_level cpd_band cpd_label  \n",
       "0           4          3        E     CPD3E  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chosen user_id=300, cv_id=300\n"
     ]
    }
   ],
   "source": [
    "print_step(\"Step 7.1 — Pick one random user + CV\")\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    person_df = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            u.user_id,\n",
    "            u.cv_partner_user_id,\n",
    "            (u.name_multilang->>'int') AS name,\n",
    "            u.email,\n",
    "            u.department,\n",
    "            u.country,\n",
    "            c.cv_id,\n",
    "            c.cv_partner_cv_id,\n",
    "            (c.title_multilang->>'int') AS cv_title,\n",
    "            c.sfia_level,\n",
    "            c.cpd_level,\n",
    "            c.cpd_band,\n",
    "            c.cpd_label\n",
    "        FROM users u\n",
    "        JOIN cvs c ON c.user_id = u.user_id\n",
    "        ORDER BY random()\n",
    "        LIMIT 1;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "    )\n",
    "\n",
    "display(person_df)\n",
    "\n",
    "user_id = int(person_df.loc[0, \"user_id\"])\n",
    "cv_id = int(person_df.loc[0, \"cv_id\"])\n",
    "\n",
    "print(f\"\\nChosen user_id={user_id}, cv_id={cv_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8347d40c",
   "metadata": {},
   "source": [
    "## 7.2 Pull all related sections for that CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95506d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 7.2 — Load all sections for this CV ====================\n",
      "\n",
      "Technologies:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>technology</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>proficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Databricks</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terraform</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dbt</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   technology  years_experience  proficiency\n",
       "0  Databricks                 3            4\n",
       "1  JavaScript                13            3\n",
       "2   Terraform                14            2\n",
       "3         dbt                 2            5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Languages:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>level</th>\n",
       "      <th>highlighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polish</td>\n",
       "      <td>Fluent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language   level  highlighted\n",
       "0  English  Fluent         True\n",
       "1   Danish  Fluent        False\n",
       "2   Polish  Fluent        False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project experience:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_from</th>\n",
       "      <th>year_to</th>\n",
       "      <th>description</th>\n",
       "      <th>industry</th>\n",
       "      <th>project_type</th>\n",
       "      <th>percent_allocated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>2023</td>\n",
       "      <td>None</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Implementation</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>None</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Advisory</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_from  year_to description industry    project_type  percent_allocated\n",
       "0       2022     2023        None  Finance  Implementation                 32\n",
       "1       2021     2021        None  Finance        Advisory                 78"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Work experience:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_from</th>\n",
       "      <th>year_to</th>\n",
       "      <th>employer</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>2023</td>\n",
       "      <td>RetailCo</td>\n",
       "      <td>Worked on data platforms, software delivery an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>2018</td>\n",
       "      <td>RetailCo</td>\n",
       "      <td>Worked on data platforms, software delivery an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>ConsultCo</td>\n",
       "      <td>Worked on data platforms, software delivery an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2015</td>\n",
       "      <td>ConsultCo</td>\n",
       "      <td>Worked on data platforms, software delivery an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_from  year_to   employer  \\\n",
       "0       2019     2023   RetailCo   \n",
       "1       2016     2018   RetailCo   \n",
       "2       2014     2015  ConsultCo   \n",
       "3       2013     2015  ConsultCo   \n",
       "\n",
       "                                         description  \n",
       "0  Worked on data platforms, software delivery an...  \n",
       "1  Worked on data platforms, software delivery an...  \n",
       "2  Worked on data platforms, software delivery an...  \n",
       "3  Worked on data platforms, software delivery an...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Education:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_from</th>\n",
       "      <th>year_to</th>\n",
       "      <th>place_of_study</th>\n",
       "      <th>degree</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year_from, year_to, place_of_study, degree, description]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Courses:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>organiser</th>\n",
       "      <th>highlighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>Azure Fundamentals</td>\n",
       "      <td>Databricks</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>Power BI</td>\n",
       "      <td>Udemy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>SQL Advanced</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>Azure Fundamentals</td>\n",
       "      <td>AWS</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                name   organiser  highlighted\n",
       "0  2024  Azure Fundamentals  Databricks         True\n",
       "1  2022            Power BI       Udemy         True\n",
       "2  2021        SQL Advanced    Coursera         True\n",
       "3  2018  Azure Fundamentals         AWS         True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Certifications:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>month_expire</th>\n",
       "      <th>year_expire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  month_expire  year_expire\n",
       "0  2020      7            10         2023\n",
       "1  2020      5            11         2022"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_from</th>\n",
       "      <th>year_to</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>highlighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>2024</td>\n",
       "      <td>Senior Azure Engineer</td>\n",
       "      <td>Progression based on delivery impact.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>2023</td>\n",
       "      <td>Consultant Azure Engineer</td>\n",
       "      <td>Progression based on delivery impact.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>2022</td>\n",
       "      <td>Associate Azure Engineer</td>\n",
       "      <td>Progression based on delivery impact.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_from  year_to                       name  \\\n",
       "0       2023     2024      Senior Azure Engineer   \n",
       "1       2022     2023  Consultant Azure Engineer   \n",
       "2       2021     2022   Associate Azure Engineer   \n",
       "\n",
       "                             description  highlighted  \n",
       "0  Progression based on delivery impact.        False  \n",
       "1  Progression based on delivery impact.         True  \n",
       "2  Progression based on delivery impact.         True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blogs / publications:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>highlighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azure Fabric Basics</td>\n",
       "      <td>Conference talk / blog summary.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optimising PySpark</td>\n",
       "      <td>Conference talk / blog summary.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                      description  highlighted\n",
       "0  Azure Fabric Basics  Conference talk / blog summary.         True\n",
       "1   Optimising PySpark  Conference talk / blog summary.         True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV roles:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>highlighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Developer</td>\n",
       "      <td>High-level role on multiple projects.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                            description  highlighted\n",
       "0  Developer  High-level role on multiple projects.         True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key qualifications:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>summary</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Key Strengths</td>\n",
       "      <td>Experienced in cloud, data engineering and ana...</td>\n",
       "      <td>Focus on Python, Azure/AWS, Databricks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                            summary  \\\n",
       "0  Key Strengths  Experienced in cloud, data engineering and ana...   \n",
       "\n",
       "                         short_description  \n",
       "0  Focus on Python, Azure/AWS, Databricks.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_step(\"Step 7.2 — Load all sections for this CV\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    techs = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          dt.name AS technology,\n",
    "          ct.years_experience,\n",
    "          ct.proficiency\n",
    "        FROM cv_technology ct\n",
    "        JOIN dim_technology dt ON dt.technology_id = ct.technology_id\n",
    "        WHERE ct.cv_id = %(cv_id)s\n",
    "        ORDER BY dt.name;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    langs = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          dl.name AS language,\n",
    "          cl.level,\n",
    "          cl.highlighted\n",
    "        FROM cv_language cl\n",
    "        JOIN dim_language dl ON dl.language_id = cl.language_id\n",
    "        WHERE cl.cv_id = %(cv_id)s\n",
    "        ORDER BY cl.highlighted DESC, dl.name;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    projects = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          pe.year_from, pe.year_to,\n",
    "          (pe.description_multilang->>'int') AS description,\n",
    "          di.name AS industry,\n",
    "          dpt.name AS project_type,\n",
    "          pe.percent_allocated\n",
    "        FROM project_experience pe\n",
    "        LEFT JOIN dim_industry di ON di.industry_id = pe.industry_id\n",
    "        LEFT JOIN dim_project_type dpt ON dpt.project_type_id = pe.project_type_id\n",
    "        WHERE pe.cv_id = %(cv_id)s\n",
    "        ORDER BY pe.year_from DESC, pe.month_from DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    work = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          year_from, year_to,\n",
    "          employer,\n",
    "          description\n",
    "        FROM work_experience\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY year_from DESC, month_from DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    edu = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          year_from, year_to,\n",
    "          place_of_study,\n",
    "          degree,\n",
    "          description\n",
    "        FROM education\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY year_from DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    courses = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          year,\n",
    "          name,\n",
    "          organiser,\n",
    "          highlighted\n",
    "        FROM course\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY year DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    certs = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          year,\n",
    "          month,\n",
    "          month_expire,\n",
    "          year_expire\n",
    "        FROM certification\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY year DESC, month DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    positions = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          year_from, year_to,\n",
    "          name,\n",
    "          description,\n",
    "          highlighted\n",
    "        FROM position\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY year_from DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    blogs = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          name,\n",
    "          description,\n",
    "          highlighted\n",
    "        FROM blog_publication\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY highlighted DESC, updated DESC NULLS LAST;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    roles = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          name,\n",
    "          description,\n",
    "          highlighted\n",
    "        FROM cv_role\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY highlighted DESC, name;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    key_quals = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          label,\n",
    "          summary,\n",
    "          short_description\n",
    "        FROM key_qualification\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY label;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "print(\"\\nTechnologies:\")\n",
    "display(techs.head())\n",
    "\n",
    "print(\"\\nLanguages:\")\n",
    "display(langs.head())\n",
    "\n",
    "print(\"\\nProject experience:\")\n",
    "display(projects.head())\n",
    "\n",
    "print(\"\\nWork experience:\")\n",
    "display(work.head())\n",
    "\n",
    "print(\"\\nEducation:\")\n",
    "display(edu.head())\n",
    "\n",
    "print(\"\\nCourses:\")\n",
    "display(courses.head())\n",
    "\n",
    "print(\"\\nCertifications:\")\n",
    "display(certs.head())\n",
    "\n",
    "print(\"\\nPositions:\")\n",
    "display(positions.head())\n",
    "\n",
    "print(\"\\nBlogs / publications:\")\n",
    "display(blogs.head())\n",
    "\n",
    "print(\"\\nCV roles:\")\n",
    "display(roles.head())\n",
    "\n",
    "print(\"\\nKey qualifications:\")\n",
    "display(key_quals.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572e634",
   "metadata": {},
   "source": [
    "## 7.3 Clearance + availability for that user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1e1bd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 7.3 — Clearance and availability for this user ====================\n",
      "\n",
      "Security clearance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clearance</th>\n",
       "      <th>valid_from</th>\n",
       "      <th>valid_to</th>\n",
       "      <th>verified_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clearance  valid_from valid_to verified_by\n",
       "0      None  1900-01-01     None          HR"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Upcoming availability (sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>percent_available</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>27</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>47</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>18</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>57</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-29</td>\n",
       "      <td>100</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>100</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>79</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-12-02</td>\n",
       "      <td>74</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-12-03</td>\n",
       "      <td>73</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>47</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  percent_available          source\n",
       "0  2025-11-25                 27  Fake generator\n",
       "1  2025-11-26                 47  Fake generator\n",
       "2  2025-11-27                 18  Fake generator\n",
       "3  2025-11-28                 57  Fake generator\n",
       "4  2025-11-29                100  Fake generator\n",
       "5  2025-11-30                100  Fake generator\n",
       "6  2025-12-01                 79  Fake generator\n",
       "7  2025-12-02                 74  Fake generator\n",
       "8  2025-12-03                 73  Fake generator\n",
       "9  2025-12-04                 47  Fake generator"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_step(\"Step 7.3 — Clearance and availability for this user\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    clearance = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          dc.name AS clearance,\n",
    "          uc.valid_from,\n",
    "          uc.valid_to,\n",
    "          uc.verified_by\n",
    "        FROM user_clearance uc\n",
    "        JOIN dim_clearance dc ON dc.clearance_id = uc.clearance_id\n",
    "        WHERE uc.user_id = %(user_id)s\n",
    "        ORDER BY uc.valid_from DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"user_id\": user_id},\n",
    "    )\n",
    "\n",
    "    availability = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          date,\n",
    "          percent_available,\n",
    "          source\n",
    "        FROM user_availability\n",
    "        WHERE user_id = %(user_id)s\n",
    "        ORDER BY date\n",
    "        LIMIT 30;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"user_id\": user_id},\n",
    "    )\n",
    "\n",
    "print(\"\\nSecurity clearance:\")\n",
    "display(clearance)\n",
    "\n",
    "print(\"\\nUpcoming availability (sample):\")\n",
    "display(availability.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c5ba883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Example table use ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-row-per-person profile table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cv_partner_user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>cv_id</th>\n",
       "      <th>cv_title</th>\n",
       "      <th>sfia_level</th>\n",
       "      <th>cpd_label</th>\n",
       "      <th>technologies</th>\n",
       "      <th>max_years_experience</th>\n",
       "      <th>clearance</th>\n",
       "      <th>latest_availability_date</th>\n",
       "      <th>latest_percent_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5b69cd14</td>\n",
       "      <td>Danielle Johnson</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal C# Developer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>.NET, Azure, Kubernetes, Python, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>439b63ae</td>\n",
       "      <td>Joshua Walker</td>\n",
       "      <td>2</td>\n",
       "      <td>Principal Data Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>C#, Kafka, Node.js, Snowflake, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bc24ae58</td>\n",
       "      <td>Jill Rhodes</td>\n",
       "      <td>3</td>\n",
       "      <td>Senior C# Developer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>.NET, Node.js, React, Snowflake, TypeScript, dbt</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>711200c6</td>\n",
       "      <td>Patricia Miller</td>\n",
       "      <td>4</td>\n",
       "      <td>Principal Analytics Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>Airflow, C#, JavaScript, Kafka, Spark, Terraform</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a7986c12</td>\n",
       "      <td>Robert Johnson</td>\n",
       "      <td>5</td>\n",
       "      <td>Associate ML Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>Airflow, Node.js, Python, Spark</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>aea2bd5b</td>\n",
       "      <td>Jeffery Wagner</td>\n",
       "      <td>6</td>\n",
       "      <td>Consultant Data Platform Engineer</td>\n",
       "      <td>3</td>\n",
       "      <td>CPD2L</td>\n",
       "      <td>Airflow, JavaScript, Power BI, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>f3e19f78</td>\n",
       "      <td>Anthony Gonzalez</td>\n",
       "      <td>7</td>\n",
       "      <td>Principal Azure Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>C#, Databricks, SQL, Snowflake, Terraform</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2ced75ad</td>\n",
       "      <td>Debra Gardner</td>\n",
       "      <td>8</td>\n",
       "      <td>Senior AI Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Airflow, JavaScript, Oracle, Power BI, SQL, Te...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4ba9d1b6</td>\n",
       "      <td>Jeffrey Lawrence</td>\n",
       "      <td>9</td>\n",
       "      <td>Associate Backend Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>AWS, Azure, C#, Oracle, Power BI, TypeScript</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>6e32ee35</td>\n",
       "      <td>Lisa Smith</td>\n",
       "      <td>10</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>.NET, Airflow, Azure, React, Snowflake</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id cv_partner_user_id              name  cv_id  \\\n",
       "0        1           5b69cd14  Danielle Johnson      1   \n",
       "1        2           439b63ae     Joshua Walker      2   \n",
       "2        3           bc24ae58       Jill Rhodes      3   \n",
       "3        4           711200c6   Patricia Miller      4   \n",
       "4        5           a7986c12    Robert Johnson      5   \n",
       "5        6           aea2bd5b    Jeffery Wagner      6   \n",
       "6        7           f3e19f78  Anthony Gonzalez      7   \n",
       "7        8           2ced75ad     Debra Gardner      8   \n",
       "8        9           4ba9d1b6  Jeffrey Lawrence      9   \n",
       "9       10           6e32ee35        Lisa Smith     10   \n",
       "\n",
       "                            cv_title  sfia_level cpd_label  \\\n",
       "0             Principal C# Developer           5     CPD3L   \n",
       "1            Principal Data Engineer           5     CPD3L   \n",
       "2                Senior C# Developer           4     CPD3E   \n",
       "3       Principal Analytics Engineer           5     CPD3L   \n",
       "4              Associate ML Engineer           2     CPD1E   \n",
       "5  Consultant Data Platform Engineer           3     CPD2L   \n",
       "6           Principal Azure Engineer           5     CPD3L   \n",
       "7                 Senior AI Engineer           4     CPD3E   \n",
       "8         Associate Backend Engineer           2     CPD1E   \n",
       "9           Associate Data Scientist           2     CPD1E   \n",
       "\n",
       "                                        technologies  max_years_experience  \\\n",
       "0               .NET, Azure, Kubernetes, Python, dbt                    15   \n",
       "1                 C#, Kafka, Node.js, Snowflake, dbt                    15   \n",
       "2   .NET, Node.js, React, Snowflake, TypeScript, dbt                     9   \n",
       "3   Airflow, C#, JavaScript, Kafka, Spark, Terraform                    15   \n",
       "4                    Airflow, Node.js, Python, Spark                    15   \n",
       "5                 Airflow, JavaScript, Power BI, dbt                    15   \n",
       "6          C#, Databricks, SQL, Snowflake, Terraform                    15   \n",
       "7  Airflow, JavaScript, Oracle, Power BI, SQL, Te...                    12   \n",
       "8       AWS, Azure, C#, Oracle, Power BI, TypeScript                    15   \n",
       "9             .NET, Airflow, Azure, React, Snowflake                    15   \n",
       "\n",
       "  clearance latest_availability_date  latest_percent_available  \n",
       "0      None               2026-01-26                       100  \n",
       "1      None               2026-01-26                       100  \n",
       "2      None               2026-01-26                       100  \n",
       "3        SC               2026-01-26                       100  \n",
       "4        SC               2026-01-26                       100  \n",
       "5        SC               2026-01-26                       100  \n",
       "6      None               2026-01-26                       100  \n",
       "7      None               2026-01-26                       100  \n",
       "8      None               2026-01-26                       100  \n",
       "9      None               2026-01-26                       100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_step(\"Example table use\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    basic = pd.read_sql(\"\"\"\n",
    "        SELECT\n",
    "            u.user_id,\n",
    "            u.cv_partner_user_id,\n",
    "            (u.name_multilang->>'int') AS name,\n",
    "            c.cv_id,\n",
    "            (c.title_multilang->>'int') AS cv_title,\n",
    "            c.sfia_level,\n",
    "            c.cpd_label,\n",
    "            dt.name AS technology,\n",
    "            ct.years_experience,\n",
    "            cr.name AS clearance,\n",
    "            ua.percent_available, \n",
    "            ua.date AS availability_date\n",
    "        FROM users u\n",
    "        JOIN cvs c\n",
    "            ON c.user_id = u.user_id\n",
    "        LEFT JOIN cv_technology ct  ON ct.cv_id = c.cv_id\n",
    "        LEFT JOIN dim_technology dt ON dt.technology_id = ct.technology_id\n",
    "        LEFT JOIN user_clearance uc ON uc.user_id = u.user_id\n",
    "        LEFT JOIN dim_clearance cr  ON cr.clearance_id = uc.clearance_id\n",
    "        LEFT JOIN user_availability ua ON ua.user_id = u.user_id\n",
    "\n",
    "    \"\"\", conn)\n",
    "\n",
    "basic_clean = (\n",
    "    basic.sort_values(\n",
    "        by=[\"user_id\", \"cv_id\", \"technology\", \"availability_date\", \"clearance\"],\n",
    "        ascending=[True, True, True, True, False]\n",
    "    )\n",
    "    .drop_duplicates(\n",
    "        subset=[\"user_id\", \"cv_id\", \"technology\", \"availability_date\"],\n",
    "        keep=\"first\"\n",
    "    )\n",
    ")\n",
    "\n",
    "profile = (\n",
    "    basic_clean\n",
    "    .groupby(\n",
    "        [\n",
    "            \"user_id\",\n",
    "            \"cv_partner_user_id\",\n",
    "            \"name\",\n",
    "            \"cv_id\",\n",
    "            \"cv_title\",\n",
    "            \"sfia_level\",\n",
    "            \"cpd_label\",\n",
    "        ],\n",
    "        dropna=False,\n",
    "    )\n",
    "    .agg(\n",
    "        technologies=(\"technology\", lambda s: \", \".join(sorted(set(s.dropna())))),\n",
    "        max_years_experience=(\"years_experience\", \"max\"),\n",
    "        clearance=(\"clearance\", lambda s: s.dropna().iloc[0] if s.dropna().any() else None),\n",
    "        latest_availability_date=(\"availability_date\", \"max\"),\n",
    "        latest_percent_available=(\"percent_available\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\nOne-row-per-person profile table:\")\n",
    "display(profile.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
