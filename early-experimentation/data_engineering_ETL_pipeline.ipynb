{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50201c6",
   "metadata": {},
   "source": [
    "# ETL Pipeline (Extract → Transform → Load)\n",
    "\n",
    "This notebook walks through a full ETL workflow for loading Flowcase style data into PostgreSQL:\n",
    "\n",
    "1. Generate synthetic CV reports  \n",
    "2. Extract raw CSV files  \n",
    "3. Transform data into a clean relational schema  \n",
    "4. Load into a PostgreSQL database  \n",
    "5. Verify the results  \n",
    "\n",
    "Each step is designed to be clear, testable, and reproducible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13bbfdd",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "To get started:\n",
    "\n",
    "1. Create a Python virtual environment  \n",
    "2. Select the `.venv` kernel in Jupyter  \n",
    "3. Install dependencies:  \n",
    "    ```\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "4. Make sure PostgreSQL is running (e.g., via pgAdmin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17b802",
   "metadata": {},
   "source": [
    "## Step 0 — Generate Synthetic Data\n",
    "\n",
    "Generate synthetic Flowcase-style CV Partner reports.  \n",
    "These are stored under the `cv_reports/` folder using timestamped folder names.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d5506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ user_report.csv: 500 rows\n",
      "✔ usage_report.csv: 500 rows\n",
      "✔ project_experiences.csv: 1501 rows\n",
      "✔ certifications.csv: 1006 rows\n",
      "✔ courses.csv: 1446 rows\n",
      "✔ languages.csv: 996 rows\n",
      "✔ technologies.csv: 2220 rows\n",
      "✔ key_qualifications.csv: 485 rows\n",
      "✔ educations.csv: 757 rows\n",
      "✔ work_experiences.csv: 1484 rows\n",
      "✔ positions.csv: 1264 rows\n",
      "✔ blogs.csv: 758 rows\n",
      "✔ cv_roles.csv: 1001 rows\n",
      "✔ sc_clearance.csv: 500 rows\n",
      "✔ availability_report.csv: 30000 rows\n",
      "\n",
      "All files written under: /Users/alanabarrett-frew/Desktop/Module  4/Assignment/ETL Pipeline/preprocessing/ETL_pipeline/early-experimentation/cv_reports/Q42025\n"
     ]
    }
   ],
   "source": [
    "import make_fake_flowcase_reports as make_fake_flowcase_reports\n",
    "\n",
    "make_fake_flowcase_reports.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f28053",
   "metadata": {},
   "source": [
    "## Run all Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1373d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from datetime import date\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514123e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_step(title):\n",
    "    print(f\"\\n{'='*20} {title} {'='*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce0a69",
   "metadata": {},
   "source": [
    "# Step 1 — Extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2036190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_report_folder(base_folder=\"cv_reports\"):\n",
    "    print_step(\"Finding the latest report folder\")\n",
    "\n",
    "    report_folders = [f for f in Path(base_folder).iterdir() if f.is_dir()]\n",
    "    if not report_folders:\n",
    "        raise FileNotFoundError(f\"No report folders found in {base_folder}\")\n",
    "\n",
    "    latest = sorted(report_folders, key=lambda f: f.name)[-1]\n",
    "\n",
    "    print(f\"Found {len(report_folders)} folders.\")\n",
    "    print(f\"Latest folder: {latest.name}\")\n",
    "\n",
    "    return latest\n",
    "\n",
    "\n",
    "def find_latest_quarterly_report_folder(base_folder=\"cv_reports\"):\n",
    "    print_step(\"Finding the latest quarterly report folder\")\n",
    "\n",
    "    pattern = re.compile(r\"Q[1-4]\\d{4}\")\n",
    "    report_folders = [\n",
    "        f for f in Path(base_folder).iterdir()\n",
    "        if f.is_dir() and pattern.match(f.name)\n",
    "    ]\n",
    "    if not report_folders:\n",
    "        raise FileNotFoundError(f\"No quarterly report folders found in {base_folder}.\")\n",
    "\n",
    "    names = sorted([f.name for f in report_folders])\n",
    "    print(\"Quarterly folders found:\", names)\n",
    "\n",
    "    latest_folder = sorted(report_folders, key=lambda folder: folder.name)[-1]\n",
    "    print(\"Using latest quarterly folder:\", latest_folder.name)\n",
    "\n",
    "    return latest_folder\n",
    "\n",
    "\n",
    "def load_csv_files_from_folder(report_folder):\n",
    "    print_step(f\"Loading CSV files from {report_folder}\")\n",
    "\n",
    "    csv_files = list(Path(report_folder).glob(\"*.csv\"))\n",
    "    print(f\"Found {len(csv_files)} CSV files.\")\n",
    "    dataframes = {}\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            dataframes[csv_file.name] = df\n",
    "            print(f\"  Loaded {csv_file.name} -> {df.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️ Failed to read {csv_file.name}: {e}\")\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "def extract(settings):\n",
    "    \"\"\"\n",
    "    Finds the latest quarterly report folder and loads all CSVs as DataFrames.\n",
    "    Returns an object with .data_dir and dict-like data (keyed by filename).\n",
    "    \"\"\"\n",
    "    data_source = settings.get(\"data_source\", \"fake\")\n",
    "\n",
    "    if data_source == \"real\":\n",
    "        print(\"[extract] Real data mode selected, but not implemented.\")\n",
    "        return type(\"ExtractResult\", (), {\"data_dir\": None})()\n",
    "\n",
    "    # Fake data path\n",
    "    base_folder = settings.get(\"base_folder\", \"cv_reports\")\n",
    "    data_dir = find_latest_quarterly_report_folder(base_folder)\n",
    "    data = load_csv_files_from_folder(data_dir)\n",
    "\n",
    "    class ExtractResult(dict):\n",
    "        pass\n",
    "\n",
    "    result = ExtractResult(data)\n",
    "    result.data_dir = data_dir\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad32481",
   "metadata": {},
   "source": [
    "## Step 1.1 — Locate the latest report folder\n",
    "\n",
    "Identify the most recent synthetic export under `cv_reports/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017eba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 1.1: Locate latest report folder ====================\n",
      "\n",
      "==================== Finding the latest report folder ====================\n",
      "Found 1 folders.\n",
      "Latest folder: Q42025\n",
      "✅ Using folder: cv_reports/Q42025\n"
     ]
    }
   ],
   "source": [
    "print_step(\"Step 1.1: Locate latest report folder\")\n",
    "\n",
    "latest_folder = find_latest_report_folder(\"cv_reports\")\n",
    "print(f\"✅ Using folder: {latest_folder}\")\n",
    "\n",
    "# Tiny test: does it actually exist?\n",
    "assert latest_folder.exists(), \"Latest folder path does not exist on disk!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a88e7",
   "metadata": {},
   "source": [
    "## Step 1.2 — Load all CSV files from the latest report\n",
    "\n",
    "Load all CSVs inside the selected folder into pandas DataFrames and perform a sanity check to ensure core files are present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30eb83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 1.2: Load CSV files from latest folder ====================\n",
      "\n",
      "==================== Loading CSV files from cv_reports/Q42025 ====================\n",
      "Found 15 CSV files.\n",
      "  Loaded certifications.csv -> (1006, 22)\n",
      "  Loaded project_experiences.csv -> (1501, 45)\n",
      "  Loaded blogs.csv -> (758, 21)\n",
      "  Loaded availability_report.csv -> (30000, 7)\n",
      "  Loaded cv_roles.csv -> (1001, 19)\n",
      "  Loaded work_experiences.csv -> (1484, 26)\n",
      "  Loaded educations.csv -> (757, 27)\n",
      "  Loaded user_report.csv -> (500, 26)\n",
      "  Loaded courses.csv -> (1446, 26)\n",
      "  Loaded key_qualifications.csv -> (485, 21)\n",
      "  Loaded positions.csv -> (1264, 23)\n",
      "  Loaded technologies.csv -> (2220, 20)\n",
      "  Loaded sc_clearance.csv -> (500, 9)\n",
      "  Loaded languages.csv -> (996, 22)\n",
      "  Loaded usage_report.csv -> (500, 51)\n",
      "\n",
      "Summary of loaded files:\n",
      " - certifications.csv             (1006, 22)\n",
      " - project_experiences.csv        (1501, 45)\n",
      " - blogs.csv                      (758, 21)\n",
      " - availability_report.csv        (30000, 7)\n",
      " - cv_roles.csv                   (1001, 19)\n",
      " - work_experiences.csv           (1484, 26)\n",
      " - educations.csv                 (757, 27)\n",
      " - user_report.csv                (500, 26)\n",
      " - courses.csv                    (1446, 26)\n",
      " - key_qualifications.csv         (485, 21)\n",
      " - positions.csv                  (1264, 23)\n",
      " - technologies.csv               (2220, 20)\n",
      " - sc_clearance.csv               (500, 9)\n",
      " - languages.csv                  (996, 22)\n",
      " - usage_report.csv               (500, 51)\n",
      "\n",
      "Expected core files: ['user_report.csv', 'project_experiences.csv', 'work_experiences.csv']\n",
      "Missing: []\n"
     ]
    }
   ],
   "source": [
    "print_step(\"Step 1.2: Load CSV files from latest folder\")\n",
    "\n",
    "raw_frames = load_csv_files_from_folder(latest_folder)\n",
    "\n",
    "print(\"\\nSummary of loaded files:\")\n",
    "for name, df in raw_frames.items():\n",
    "    print(f\" - {name:30} {df.shape}\")\n",
    "\n",
    "# Check: do we have some expected core CSVs?\n",
    "expected_files = [\n",
    "    \"user_report.csv\",\n",
    "    \"project_experiences.csv\",\n",
    "    \"work_experiences.csv\",\n",
    "]\n",
    "missing = [f for f in expected_files if f not in raw_frames]\n",
    "\n",
    "print(\"\\nExpected core files:\", expected_files)\n",
    "print(\"Missing:\", missing)\n",
    "\n",
    "assert not missing, \"One or more expected CSVs are missing!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bae474",
   "metadata": {},
   "source": [
    "# Step 2 — Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db93e221",
   "metadata": {},
   "source": [
    "## Step 2.1 — Transform helpers\n",
    "\n",
    "These helpers normalise multilang fields, dates, and define the `TransformResult`\n",
    "dataclass for returning a clean set of tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5d4ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformResult:\n",
    "    users_df: pd.DataFrame | None = None\n",
    "    cvs_df: pd.DataFrame | None = None\n",
    "    technologies_df: pd.DataFrame | None = None\n",
    "    languages_df: pd.DataFrame | None = None\n",
    "    project_experiences_df: pd.DataFrame | None = None\n",
    "    work_experiences_df: pd.DataFrame | None = None\n",
    "    certifications_df: pd.DataFrame | None = None\n",
    "    courses_df: pd.DataFrame | None = None\n",
    "    educations_df: pd.DataFrame | None = None\n",
    "    positions_df: pd.DataFrame | None = None\n",
    "    blogs_df: pd.DataFrame | None = None\n",
    "    cv_roles_df: pd.DataFrame | None = None\n",
    "    key_qualifications_df: pd.DataFrame | None = None\n",
    "    sc_clearance_df: pd.DataFrame | None = None\n",
    "    availability_df: pd.DataFrame | None = None\n",
    "\n",
    "def parse_multilang(pipe: object) -> dict:\n",
    "    \"\"\"\n",
    "    Convert a single pipe string like 'int:Text|no:Tekst' into a dict.\n",
    "    Anything non-string or blank -> {}.\n",
    "    \"\"\"\n",
    "    if not isinstance(pipe, str) or not pipe.strip():\n",
    "        return {}\n",
    "    out = {}\n",
    "    for part in pipe.split(\"|\"):\n",
    "        if \":\" in part:\n",
    "            k, v = part.split(\":\", 1)\n",
    "            k, v = k.strip(), v.strip()\n",
    "            if k and v:\n",
    "                out[k] = v\n",
    "    return out\n",
    "\n",
    "def to_iso_date(s: object) -> str | None:\n",
    "    if s is None or (isinstance(s, float) and pd.isna(s)):\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    # If it looks like ISO (yyyy-mm-dd), parse straight without dayfirst\n",
    "    if \"-\" in s and len(s.split(\"-\")[0]) == 4:\n",
    "        dt = pd.to_datetime(s, errors=\"coerce\")\n",
    "    else:\n",
    "        dt = pd.to_datetime(s, dayfirst=True, errors=\"coerce\")\n",
    "    return None if pd.isna(dt) else dt.date().isoformat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba73a74",
   "metadata": {},
   "source": [
    "## Step 2.2 — Core transform logic\n",
    "\n",
    "The `transform()` function builds clean tables for Users, CVs, skills, \n",
    "experiences, and other CV Partner sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f5fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data) -> TransformResult:\n",
    "    # Core extracts\n",
    "    users = data.get(\"user_report.csv\", pd.DataFrame()).copy()\n",
    "    usage = data.get(\"usage_report.csv\", pd.DataFrame()).copy()\n",
    "\n",
    "    # Parse user name as dict\n",
    "    if not users.empty and \"Name (multilang)\" in users.columns:\n",
    "        users[\"Name (multilang)\"] = users[\"Name (multilang)\"].map(parse_multilang)\n",
    "    else:\n",
    "        users[\"Name (multilang)\"] = [{}] * len(users)\n",
    "\n",
    "    # Nationality comes from usage_report: \"Nationality (#{lang})\" is a single pipe string\n",
    "    if not usage.empty and \"Nationality (#{lang})\" in usage.columns:\n",
    "        nat_map = {\n",
    "            str(r[\"CV Partner User ID\"]): parse_multilang(r[\"Nationality (#{lang})\"])\n",
    "            for _, r in usage.iterrows()\n",
    "            if \"CV Partner User ID\" in r and pd.notna(r[\"CV Partner User ID\"])\n",
    "        }\n",
    "        users[\"nationality_multilang\"] = users[\"CV Partner User ID\"].map(\n",
    "            lambda uid: nat_map.get(str(uid), {})\n",
    "        )\n",
    "    else:\n",
    "        users[\"nationality_multilang\"] = [{}] * len(users)\n",
    "\n",
    "    # Build CV rows: user_report already has one row per CV\n",
    "    cvs = users.copy()\n",
    "    if \"Title (#{lang})\" in users.columns:\n",
    "        cvs[\"title_multilang\"] = users[\"Title (#{lang})\"].map(parse_multilang)\n",
    "    else:\n",
    "        cvs[\"title_multilang\"] = [{}] * len(cvs)\n",
    "\n",
    "    # Carry seniority columns from user_report -> cvs_df\n",
    "    def _num(x):\n",
    "        try:\n",
    "            return int(x)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    cvs[\"sfia_level\"] = users.get(\"SFIA Level\", pd.Series([None]*len(users))).map(_num)\n",
    "    cvs[\"cpd_level\"]  = users.get(\"CPD Level\",  pd.Series([None]*len(users))).map(_num)\n",
    "    cvs[\"cpd_band\"]   = users.get(\"CPD Band\",   pd.Series([None]*len(users))).astype(\"string\").where(lambda s: s.notna(), None)\n",
    "    cvs[\"cpd_label\"]  = users.get(\"CPD Label\",  pd.Series([None]*len(users))).astype(\"string\").where(lambda s: s.notna(), None)\n",
    "\n",
    "\n",
    "    # Pass through + light cleanup\n",
    "    sc_clearance = data.get(\"sc_clearance.csv\", pd.DataFrame()).copy()\n",
    "    if not sc_clearance.empty:\n",
    "        for col in (\"Valid From\", \"Valid To\"):\n",
    "            if col in sc_clearance.columns:\n",
    "                sc_clearance[col] = sc_clearance[col].map(to_iso_date)\n",
    "\n",
    "    availability = data.get(\"availability_report.csv\", pd.DataFrame()).copy()\n",
    "    if not availability.empty and \"Date\" in availability.columns:\n",
    "        availability[\"Date\"] = availability[\"Date\"].map(to_iso_date)\n",
    "\n",
    "    return TransformResult(\n",
    "        users_df=users if not users.empty else pd.DataFrame(),\n",
    "        cvs_df=cvs if not cvs.empty else pd.DataFrame(),\n",
    "        technologies_df=data.get(\"technologies.csv\"),\n",
    "        languages_df=data.get(\"languages.csv\"),\n",
    "        project_experiences_df=data.get(\"project_experiences.csv\"),\n",
    "        work_experiences_df=data.get(\"work_experiences.csv\"),\n",
    "        certifications_df=data.get(\"certifications.csv\"),\n",
    "        courses_df=data.get(\"courses.csv\"),\n",
    "        educations_df=data.get(\"educations.csv\"),\n",
    "        positions_df=data.get(\"positions.csv\"),\n",
    "        blogs_df=data.get(\"blogs.csv\"),\n",
    "        cv_roles_df=data.get(\"cv_roles.csv\"),\n",
    "        key_qualifications_df=data.get(\"key_qualifications.csv\"),\n",
    "        sc_clearance_df=sc_clearance if not sc_clearance.empty else pd.DataFrame(),\n",
    "        availability_df=availability if not availability.empty else pd.DataFrame(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55720d32",
   "metadata": {},
   "source": [
    "## Step 2.3 — Run transform and perform tests\n",
    "\n",
    "Execute `transform(raw_data)` and validate:\n",
    "\n",
    "- Row counts  \n",
    "- Key identifiers  \n",
    "- Data integrity (e.g., CV count aligns with user count)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297eed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 2.3: Reload CSVs for transform demo ====================\n",
      "\n",
      "==================== Loading CSV files from cv_reports/Q42025 ====================\n",
      "Found 15 CSV files.\n",
      "  Loaded certifications.csv -> (1006, 22)\n",
      "  Loaded project_experiences.csv -> (1501, 45)\n",
      "  Loaded blogs.csv -> (758, 21)\n",
      "  Loaded availability_report.csv -> (30000, 7)\n",
      "  Loaded cv_roles.csv -> (1001, 19)\n",
      "  Loaded work_experiences.csv -> (1484, 26)\n",
      "  Loaded educations.csv -> (757, 27)\n",
      "  Loaded user_report.csv -> (500, 26)\n",
      "  Loaded courses.csv -> (1446, 26)\n",
      "  Loaded key_qualifications.csv -> (485, 21)\n",
      "  Loaded positions.csv -> (1264, 23)\n",
      "  Loaded technologies.csv -> (2220, 20)\n",
      "  Loaded sc_clearance.csv -> (500, 9)\n",
      "  Loaded languages.csv -> (996, 22)\n",
      "  Loaded usage_report.csv -> (500, 51)\n",
      "\n",
      "==================== Step 2.3a: Run transform() on extracted data ====================\n",
      "\n",
      "Transformed tables (row counts):\n",
      " - users_df                    500 rows\n",
      " - cvs_df                      500 rows\n",
      " - technologies_df            2220 rows\n",
      " - languages_df                996 rows\n",
      " - project_experiences_df     1501 rows\n",
      " - work_experiences_df        1484 rows\n",
      "\n",
      "Sample: users_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Name (multilang)</th>\n",
       "      <th>Title (#{lang})</th>\n",
       "      <th>Email</th>\n",
       "      <th>UPN</th>\n",
       "      <th>External User ID</th>\n",
       "      <th>CV Partner User ID</th>\n",
       "      <th>CV Partner CV ID</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Landline</th>\n",
       "      <th>...</th>\n",
       "      <th>Years since first work experience</th>\n",
       "      <th>Access roles</th>\n",
       "      <th>Has profile image</th>\n",
       "      <th>Owns a reference project</th>\n",
       "      <th>Read and understood privacy notice</th>\n",
       "      <th>SFIA Level</th>\n",
       "      <th>CPD Level</th>\n",
       "      <th>CPD Band</th>\n",
       "      <th>CPD Label</th>\n",
       "      <th>nationality_multilang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danielle Johnson</td>\n",
       "      <td>{'int': 'Danielle Johnson'}</td>\n",
       "      <td>int:Principal C# Developer</td>\n",
       "      <td>danielle.johnson@mail.test</td>\n",
       "      <td>daniellejohnson</td>\n",
       "      <td>ext_f543201a</td>\n",
       "      <td>f543201a</td>\n",
       "      <td>cv_f543201a</td>\n",
       "      <td>958-350-6431</td>\n",
       "      <td>+1-539-500-5329x31839</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Norwegian'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joshua Walker</td>\n",
       "      <td>{'int': 'Joshua Walker'}</td>\n",
       "      <td>int:Principal Data Engineer</td>\n",
       "      <td>joshua.walker@mail.test</td>\n",
       "      <td>joshuawalker</td>\n",
       "      <td>ext_9cf199d1</td>\n",
       "      <td>9cf199d1</td>\n",
       "      <td>cv_9cf199d1</td>\n",
       "      <td>729-504-2284x21020</td>\n",
       "      <td>001-350-324-0268</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>User</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Swedish'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jill Rhodes</td>\n",
       "      <td>{'int': 'Jill Rhodes'}</td>\n",
       "      <td>int:Senior C# Developer</td>\n",
       "      <td>jill.rhodes@example.org</td>\n",
       "      <td>jillrhodes</td>\n",
       "      <td>ext_90dbd3f5</td>\n",
       "      <td>90dbd3f5</td>\n",
       "      <td>cv_90dbd3f5</td>\n",
       "      <td>975.289.1783x9084</td>\n",
       "      <td>7764617711</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>{'int': 'British'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patricia Miller</td>\n",
       "      <td>{'int': 'Patricia Miller'}</td>\n",
       "      <td>int:Principal Analytics Engineer</td>\n",
       "      <td>patricia.miller@mail.test</td>\n",
       "      <td>patriciamiller</td>\n",
       "      <td>ext_34ecdd86</td>\n",
       "      <td>34ecdd86</td>\n",
       "      <td>cv_34ecdd86</td>\n",
       "      <td>624-999-8569</td>\n",
       "      <td>896.311.8367x36576</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>User</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Polish'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robert Johnson</td>\n",
       "      <td>{'int': 'Robert Johnson'}</td>\n",
       "      <td>int:Associate ML Engineer</td>\n",
       "      <td>robert.johnson@mail.test</td>\n",
       "      <td>robertjohnson</td>\n",
       "      <td>ext_460e91df</td>\n",
       "      <td>460e91df</td>\n",
       "      <td>cv_460e91df</td>\n",
       "      <td>465-245-2711x11615</td>\n",
       "      <td>001-688-651-6560</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>Country Manager</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>{'int': 'Danish'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name             Name (multilang)  \\\n",
       "0  Danielle Johnson  {'int': 'Danielle Johnson'}   \n",
       "1     Joshua Walker     {'int': 'Joshua Walker'}   \n",
       "2       Jill Rhodes       {'int': 'Jill Rhodes'}   \n",
       "3   Patricia Miller   {'int': 'Patricia Miller'}   \n",
       "4    Robert Johnson    {'int': 'Robert Johnson'}   \n",
       "\n",
       "                    Title (#{lang})                       Email  \\\n",
       "0        int:Principal C# Developer  danielle.johnson@mail.test   \n",
       "1       int:Principal Data Engineer     joshua.walker@mail.test   \n",
       "2           int:Senior C# Developer     jill.rhodes@example.org   \n",
       "3  int:Principal Analytics Engineer   patricia.miller@mail.test   \n",
       "4         int:Associate ML Engineer    robert.johnson@mail.test   \n",
       "\n",
       "               UPN External User ID CV Partner User ID CV Partner CV ID  \\\n",
       "0  daniellejohnson     ext_f543201a           f543201a      cv_f543201a   \n",
       "1     joshuawalker     ext_9cf199d1           9cf199d1      cv_9cf199d1   \n",
       "2       jillrhodes     ext_90dbd3f5           90dbd3f5      cv_90dbd3f5   \n",
       "3   patriciamiller     ext_34ecdd86           34ecdd86      cv_34ecdd86   \n",
       "4    robertjohnson     ext_460e91df           460e91df      cv_460e91df   \n",
       "\n",
       "         Phone Number               Landline  ...  \\\n",
       "0        958-350-6431  +1-539-500-5329x31839  ...   \n",
       "1  729-504-2284x21020       001-350-324-0268  ...   \n",
       "2   975.289.1783x9084             7764617711  ...   \n",
       "3        624-999-8569     896.311.8367x36576  ...   \n",
       "4  465-245-2711x11615       001-688-651-6560  ...   \n",
       "\n",
       "   Years since first work experience     Access roles Has profile image  \\\n",
       "0                                  5             User              True   \n",
       "1                                 12             User             False   \n",
       "2                                  9             User              True   \n",
       "3                                 18             User             False   \n",
       "4                                 10  Country Manager              True   \n",
       "\n",
       "  Owns a reference project Read and understood privacy notice SFIA Level  \\\n",
       "0                    False                               True          5   \n",
       "1                    False                              False          5   \n",
       "2                    False                               True          4   \n",
       "3                    False                               True          5   \n",
       "4                     True                              False          2   \n",
       "\n",
       "   CPD Level  CPD Band CPD Label  nationality_multilang  \n",
       "0          3         L     CPD3L   {'int': 'Norwegian'}  \n",
       "1          3         L     CPD3L     {'int': 'Swedish'}  \n",
       "2          3         E     CPD3E     {'int': 'British'}  \n",
       "3          3         L     CPD3L      {'int': 'Polish'}  \n",
       "4          1         E     CPD1E      {'int': 'Danish'}  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample: cvs_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Name (multilang)</th>\n",
       "      <th>Title (#{lang})</th>\n",
       "      <th>Email</th>\n",
       "      <th>UPN</th>\n",
       "      <th>External User ID</th>\n",
       "      <th>CV Partner User ID</th>\n",
       "      <th>CV Partner CV ID</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Landline</th>\n",
       "      <th>...</th>\n",
       "      <th>SFIA Level</th>\n",
       "      <th>CPD Level</th>\n",
       "      <th>CPD Band</th>\n",
       "      <th>CPD Label</th>\n",
       "      <th>nationality_multilang</th>\n",
       "      <th>title_multilang</th>\n",
       "      <th>sfia_level</th>\n",
       "      <th>cpd_level</th>\n",
       "      <th>cpd_band</th>\n",
       "      <th>cpd_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danielle Johnson</td>\n",
       "      <td>{'int': 'Danielle Johnson'}</td>\n",
       "      <td>int:Principal C# Developer</td>\n",
       "      <td>danielle.johnson@mail.test</td>\n",
       "      <td>daniellejohnson</td>\n",
       "      <td>ext_f543201a</td>\n",
       "      <td>f543201a</td>\n",
       "      <td>cv_f543201a</td>\n",
       "      <td>958-350-6431</td>\n",
       "      <td>+1-539-500-5329x31839</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Norwegian'}</td>\n",
       "      <td>{'int': 'Principal C# Developer'}</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joshua Walker</td>\n",
       "      <td>{'int': 'Joshua Walker'}</td>\n",
       "      <td>int:Principal Data Engineer</td>\n",
       "      <td>joshua.walker@mail.test</td>\n",
       "      <td>joshuawalker</td>\n",
       "      <td>ext_9cf199d1</td>\n",
       "      <td>9cf199d1</td>\n",
       "      <td>cv_9cf199d1</td>\n",
       "      <td>729-504-2284x21020</td>\n",
       "      <td>001-350-324-0268</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Swedish'}</td>\n",
       "      <td>{'int': 'Principal Data Engineer'}</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jill Rhodes</td>\n",
       "      <td>{'int': 'Jill Rhodes'}</td>\n",
       "      <td>int:Senior C# Developer</td>\n",
       "      <td>jill.rhodes@example.org</td>\n",
       "      <td>jillrhodes</td>\n",
       "      <td>ext_90dbd3f5</td>\n",
       "      <td>90dbd3f5</td>\n",
       "      <td>cv_90dbd3f5</td>\n",
       "      <td>975.289.1783x9084</td>\n",
       "      <td>7764617711</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>{'int': 'British'}</td>\n",
       "      <td>{'int': 'Senior C# Developer'}</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD3E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patricia Miller</td>\n",
       "      <td>{'int': 'Patricia Miller'}</td>\n",
       "      <td>int:Principal Analytics Engineer</td>\n",
       "      <td>patricia.miller@mail.test</td>\n",
       "      <td>patriciamiller</td>\n",
       "      <td>ext_34ecdd86</td>\n",
       "      <td>34ecdd86</td>\n",
       "      <td>cv_34ecdd86</td>\n",
       "      <td>624-999-8569</td>\n",
       "      <td>896.311.8367x36576</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>{'int': 'Polish'}</td>\n",
       "      <td>{'int': 'Principal Analytics Engineer'}</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>CPD3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robert Johnson</td>\n",
       "      <td>{'int': 'Robert Johnson'}</td>\n",
       "      <td>int:Associate ML Engineer</td>\n",
       "      <td>robert.johnson@mail.test</td>\n",
       "      <td>robertjohnson</td>\n",
       "      <td>ext_460e91df</td>\n",
       "      <td>460e91df</td>\n",
       "      <td>cv_460e91df</td>\n",
       "      <td>465-245-2711x11615</td>\n",
       "      <td>001-688-651-6560</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>{'int': 'Danish'}</td>\n",
       "      <td>{'int': 'Associate ML Engineer'}</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD1E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name             Name (multilang)  \\\n",
       "0  Danielle Johnson  {'int': 'Danielle Johnson'}   \n",
       "1     Joshua Walker     {'int': 'Joshua Walker'}   \n",
       "2       Jill Rhodes       {'int': 'Jill Rhodes'}   \n",
       "3   Patricia Miller   {'int': 'Patricia Miller'}   \n",
       "4    Robert Johnson    {'int': 'Robert Johnson'}   \n",
       "\n",
       "                    Title (#{lang})                       Email  \\\n",
       "0        int:Principal C# Developer  danielle.johnson@mail.test   \n",
       "1       int:Principal Data Engineer     joshua.walker@mail.test   \n",
       "2           int:Senior C# Developer     jill.rhodes@example.org   \n",
       "3  int:Principal Analytics Engineer   patricia.miller@mail.test   \n",
       "4         int:Associate ML Engineer    robert.johnson@mail.test   \n",
       "\n",
       "               UPN External User ID CV Partner User ID CV Partner CV ID  \\\n",
       "0  daniellejohnson     ext_f543201a           f543201a      cv_f543201a   \n",
       "1     joshuawalker     ext_9cf199d1           9cf199d1      cv_9cf199d1   \n",
       "2       jillrhodes     ext_90dbd3f5           90dbd3f5      cv_90dbd3f5   \n",
       "3   patriciamiller     ext_34ecdd86           34ecdd86      cv_34ecdd86   \n",
       "4    robertjohnson     ext_460e91df           460e91df      cv_460e91df   \n",
       "\n",
       "         Phone Number               Landline  ...  SFIA Level CPD Level  \\\n",
       "0        958-350-6431  +1-539-500-5329x31839  ...           5         3   \n",
       "1  729-504-2284x21020       001-350-324-0268  ...           5         3   \n",
       "2   975.289.1783x9084             7764617711  ...           4         3   \n",
       "3        624-999-8569     896.311.8367x36576  ...           5         3   \n",
       "4  465-245-2711x11615       001-688-651-6560  ...           2         1   \n",
       "\n",
       "  CPD Band CPD Label nationality_multilang  \\\n",
       "0        L     CPD3L  {'int': 'Norwegian'}   \n",
       "1        L     CPD3L    {'int': 'Swedish'}   \n",
       "2        E     CPD3E    {'int': 'British'}   \n",
       "3        L     CPD3L     {'int': 'Polish'}   \n",
       "4        E     CPD1E     {'int': 'Danish'}   \n",
       "\n",
       "                           title_multilang  sfia_level  cpd_level cpd_band  \\\n",
       "0        {'int': 'Principal C# Developer'}           5          3        L   \n",
       "1       {'int': 'Principal Data Engineer'}           5          3        L   \n",
       "2           {'int': 'Senior C# Developer'}           4          3        E   \n",
       "3  {'int': 'Principal Analytics Engineer'}           5          3        L   \n",
       "4         {'int': 'Associate ML Engineer'}           2          1        E   \n",
       "\n",
       "   cpd_label  \n",
       "0      CPD3L  \n",
       "1      CPD3L  \n",
       "2      CPD3E  \n",
       "3      CPD3L  \n",
       "4      CPD1E  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 2.3b: Basic data quality checks on transform output ====================\n",
      "✅ Transform checks passed for users_df and cvs_df.\n"
     ]
    }
   ],
   "source": [
    "print_step(\"Step 2.3: Reload CSVs for transform demo\")\n",
    "\n",
    "raw_data = load_csv_files_from_folder(latest_folder)\n",
    "\n",
    "print_step(\"Step 2.3a: Run transform() on extracted data\")\n",
    "\n",
    "# Use the raw data dict from load_csv_files_from_folder(...)\n",
    "tr = transform(raw_data)\n",
    "\n",
    "print(\"\\nTransformed tables (row counts):\")\n",
    "for name in [\n",
    "    \"users_df\", \"cvs_df\", \"technologies_df\", \"languages_df\",\n",
    "    \"project_experiences_df\", \"work_experiences_df\",\n",
    "]:\n",
    "    df = getattr(tr, name)\n",
    "    if df is not None:\n",
    "        print(f\" - {name:25} {len(df):5d} rows\")\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"\\nSample: users_df\")\n",
    "display(tr.users_df.head())\n",
    "\n",
    "print(\"\\nSample: cvs_df\")\n",
    "display(tr.cvs_df.head())\n",
    "\n",
    "print_step(\"Step 2.3b: Basic data quality checks on transform output\")\n",
    "\n",
    "users_df = tr.users_df\n",
    "cvs_df = tr.cvs_df\n",
    "\n",
    "# 1) Ensure we have users\n",
    "assert not users_df.empty, \"users_df is unexpectedly empty after transform!\"\n",
    "\n",
    "# 2) Key identifier should exist & not be all null\n",
    "assert \"CV Partner User ID\" in users_df.columns, \"Missing CV Partner User ID column in users_df\"\n",
    "assert users_df[\"CV Partner User ID\"].notna().any(), \"All user IDs are null!\"\n",
    "\n",
    "# 3) Same number of rows in users_df and cvs_df\n",
    "assert len(users_df) == len(cvs_df), \"users_df and cvs_df row counts differ!\"\n",
    "\n",
    "print(\"✅ Transform checks passed for users_df and cvs_df.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377b6c6",
   "metadata": {},
   "source": [
    "# Step 3 — Load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae8579",
   "metadata": {},
   "source": [
    "## Step 3.1 — Load helpers\n",
    "\n",
    "These utility functions handle boolean parsing, date conversion, \n",
    "foreign key lookups, and normalisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e14f7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_bool(v):\n",
    "    if v is None or (isinstance(v, float) and pd.isna(v)):\n",
    "        return None\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    s = str(v).strip().lower()\n",
    "    return s in (\"true\", \"1\", \"t\", \"yes\", \"y\")\n",
    "\n",
    "def _clean_str(v, default=\"\"):\n",
    "    # Safely turn any value (including NaN/float) into a stripped string (or default)\n",
    "    if v is None or (isinstance(v, float) and pd.isna(v)):\n",
    "        return default\n",
    "    s = str(v).strip()\n",
    "    return s if s else default\n",
    "\n",
    "def _resolve_user_id(conn, email=None, upn=None, external_id=None):\n",
    "    if email:\n",
    "        uid = conn.execute(text(\"SELECT user_id FROM users WHERE lower(email)=lower(:e)\"), {\"e\": email}).scalar()\n",
    "        if uid: return uid\n",
    "    if upn:\n",
    "        uid = conn.execute(text(\"SELECT user_id FROM users WHERE lower(upn)=lower(:u)\"), {\"u\": upn}).scalar()\n",
    "        if uid: return uid\n",
    "    if external_id:\n",
    "        uid = conn.execute(text(\"SELECT user_id FROM users WHERE external_user_id=:x\"), {\"x\": external_id}).scalar()\n",
    "        if uid: return uid\n",
    "    return None\n",
    "\n",
    "def _to_date(v, default=None):\n",
    "    # Accept strings like \"2024-07-01\", \"01/07/2024\", or excel-ish values\n",
    "    if v is None or (isinstance(v, float) and pd.isna(v)) or str(v).strip() == \"\":\n",
    "        return default\n",
    "    dt = pd.to_datetime(str(v).strip(), dayfirst=True, errors=\"coerce\")\n",
    "    return None if pd.isna(dt) else dt.date()\n",
    "        \n",
    "def _cv_id(conn, cv_partner_cv_id: str):\n",
    "    return conn.execute(\n",
    "        text(\"SELECT cv_id FROM cvs WHERE cv_partner_cv_id=:cid\"),\n",
    "        {\"cid\": str(cv_partner_cv_id)}\n",
    "    ).scalar()\n",
    "\n",
    "def _ensure_dim(conn, table: str, name: str, key: str = \"name\", id_col: str = None):\n",
    "    if not name:\n",
    "        return None\n",
    "    if id_col is None:\n",
    "        id_col = (table[4:] + \"_id\") if table.startswith(\"dim_\") else (table.rstrip(\"s\") + \"_id\")\n",
    "    conn.execute(text(f\"INSERT INTO {table} ({key}) VALUES (:n) ON CONFLICT ({key}) DO NOTHING\"), {\"n\": name})\n",
    "    return conn.execute(text(f\"SELECT {id_col} FROM {table} WHERE {key}=:n\"), {\"n\": name}).scalar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e33021",
   "metadata": {},
   "source": [
    "## Step 3.2 — Core entity upserts (Users and CVs)\n",
    "\n",
    "These upsert functions populate the `users` and `cvs` tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea8a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsert_users(conn, df):\n",
    "    print(f\"Upserting {len(df)} users.\")\n",
    "    sql = text(\"\"\"\n",
    "        INSERT INTO users\n",
    "          (cv_partner_user_id, name_multilang, email, upn, external_user_id,\n",
    "           phone_number, landline, birth_year, department, country,\n",
    "           user_created_at, nationality_multilang)\n",
    "        VALUES\n",
    "          (:cv_partner_user_id, CAST(:name_multilang AS JSONB), :email, :upn, :external_user_id,\n",
    "           :phone_number, :landline, :birth_year, :department, :country,\n",
    "           :user_created_at, CAST(:nationality_multilang AS JSONB))\n",
    "        ON CONFLICT (cv_partner_user_id) DO UPDATE\n",
    "        SET name_multilang = EXCLUDED.name_multilang,\n",
    "            email = EXCLUDED.email,\n",
    "            upn = EXCLUDED.upn,\n",
    "            external_user_id = EXCLUDED.external_user_id,\n",
    "            phone_number = EXCLUDED.phone_number,\n",
    "            landline = EXCLUDED.landline,\n",
    "            birth_year = EXCLUDED.birth_year,\n",
    "            department = EXCLUDED.department,\n",
    "            country = EXCLUDED.country,\n",
    "            user_created_at = EXCLUDED.user_created_at,\n",
    "            nationality_multilang = EXCLUDED.nationality_multilang\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        conn.execute(sql, {\n",
    "            \"cv_partner_user_id\": str(r[\"CV Partner User ID\"]),\n",
    "            \"name_multilang\": json.dumps(r[\"Name (multilang)\"]),  # dict -> JSON\n",
    "            \"email\": r.get(\"Email\"),\n",
    "            \"upn\": r.get(\"UPN\"),\n",
    "            \"external_user_id\": r.get(\"External User ID\"),\n",
    "            \"phone_number\": r.get(\"Phone Number\"),\n",
    "            \"landline\": r.get(\"Landline\"),\n",
    "            \"birth_year\": int(r[\"Birth Year\"]) if pd.notna(r.get(\"Birth Year\")) else None,\n",
    "            \"department\": r.get(\"Department\"),\n",
    "            \"country\": r.get(\"Country\"),\n",
    "            \"user_created_at\": r.get(\"User created at\"),\n",
    "            \"nationality_multilang\": json.dumps(r.get(\"nationality_multilang\", {})),\n",
    "        })\n",
    "\n",
    "def upsert_cvs(conn, df):\n",
    "    print(f\"Upserting {len(df)} CVs...\")\n",
    "    sql = text(\"\"\"\n",
    "        INSERT INTO cvs\n",
    "          (cv_partner_cv_id, user_id, title_multilang, years_of_education,\n",
    "           years_since_first_work_experience, has_profile_image,\n",
    "           owns_reference_project, read_privacy_notice,\n",
    "           cv_last_updated_by_owner, cv_last_updated,\n",
    "           sfia_level, cpd_level, cpd_band, cpd_label)\n",
    "        VALUES\n",
    "          (:cv_partner_cv_id, :user_id, CAST(:title_multilang AS JSONB), :yoe, :ysfwe,\n",
    "           :has_img, :owns_ref, :read_priv, :lu_owner, :lu,\n",
    "           :sfia_level, :cpd_level, :cpd_band, :cpd_label)\n",
    "        ON CONFLICT (cv_partner_cv_id) DO UPDATE\n",
    "        SET title_multilang = EXCLUDED.title_multilang,\n",
    "            years_of_education = EXCLUDED.years_of_education,\n",
    "            years_since_first_work_experience = EXCLUDED.years_since_first_work_experience,\n",
    "            has_profile_image = EXCLUDED.has_profile_image,\n",
    "            owns_reference_project = EXCLUDED.owns_reference_project,\n",
    "            read_privacy_notice = EXCLUDED.read_privacy_notice,\n",
    "            cv_last_updated_by_owner = EXCLUDED.cv_last_updated_by_owner,\n",
    "            cv_last_updated = EXCLUDED.cv_last_updated,\n",
    "            sfia_level = EXCLUDED.sfia_level,\n",
    "            cpd_level  = EXCLUDED.cpd_level,\n",
    "            cpd_band   = EXCLUDED.cpd_band,\n",
    "            cpd_label  = EXCLUDED.cpd_label\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        uid = conn.execute(\n",
    "            text(\"SELECT user_id FROM users WHERE cv_partner_user_id=:uid\"),\n",
    "            {\"uid\": str(r[\"CV Partner User ID\"])}\n",
    "        ).scalar()\n",
    "        if uid is None:\n",
    "            print(f\"  ⚠️ Skipping CV {r['CV Partner CV ID']} (unknown user {r['CV Partner User ID']})\")\n",
    "            continue\n",
    "\n",
    "        conn.execute(sql, {\n",
    "            \"cv_partner_cv_id\": str(r[\"CV Partner CV ID\"]),\n",
    "            \"user_id\": uid,\n",
    "            \"title_multilang\": json.dumps(r[\"title_multilang\"]),\n",
    "            \"yoe\": int(r[\"Years of education\"]) if pd.notna(r[\"Years of education\"]) else None,\n",
    "            \"ysfwe\": int(r[\"Years since first work experience\"]) if pd.notna(r[\"Years since first work experience\"]) else None,\n",
    "            \"has_img\": _to_bool(r[\"Has profile image\"]),\n",
    "            \"owns_ref\": _to_bool(r[\"Owns a reference project\"]),\n",
    "            \"read_priv\": _to_bool(r[\"Read and understood privacy notice\"]),\n",
    "            \"lu_owner\": r[\"CV Last updated by owner\"],\n",
    "            \"lu\": r[\"CV Last updated\"],\n",
    "            \"sfia_level\": r.get(\"sfia_level\"),\n",
    "            \"cpd_level\":  r.get(\"cpd_level\"),\n",
    "            \"cpd_band\":   (None if pd.isna(r.get(\"cpd_band\"))  else str(r.get(\"cpd_band\"))),\n",
    "            \"cpd_label\":  (None if pd.isna(r.get(\"cpd_label\")) else str(r.get(\"cpd_label\"))),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b25529",
   "metadata": {},
   "source": [
    "## Step 3.3 — Skills and languages\n",
    "\n",
    "Upserts for technology skills, languages, and related dimension tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c67306ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_technologies(conn, df):\n",
    "    print(f\"Upserting {len(df)} technologies...\")\n",
    "    for _, r in df.iterrows():\n",
    "        tech_name = r[\"Skill name\"]\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO dim_technology (name)\n",
    "            VALUES (:name)\n",
    "            ON CONFLICT (name) DO NOTHING\n",
    "        \"\"\"), {\"name\": tech_name})\n",
    "\n",
    "        tech_id = conn.execute(\n",
    "            text(\"SELECT technology_id FROM dim_technology WHERE name=:n\"),\n",
    "            {\"n\": tech_name}\n",
    "        ).scalar()\n",
    "        if tech_id is None:\n",
    "            print(f\"  ⚠️ Skipping tech link; cannot resolve technology '{tech_name}'\")\n",
    "            continue\n",
    "\n",
    "        cv_id = conn.execute(\n",
    "            text(\"SELECT cv_id FROM cvs WHERE cv_partner_cv_id=:cid\"),\n",
    "            {\"cid\": str(r[\"CV Partner CV ID\"])}\n",
    "        ).scalar()\n",
    "        if cv_id is None:\n",
    "            print(f\"  ⚠️ Skipping tech link; unknown CV {r['CV Partner CV ID']}\")\n",
    "            continue\n",
    "\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO cv_technology (cv_id, technology_id, years_experience, proficiency, is_official_masterdata)\n",
    "            VALUES (:cv, :tech, :yexp, :prof, CAST(:is_md AS JSONB))\n",
    "            ON CONFLICT (cv_id, technology_id) DO UPDATE\n",
    "            SET years_experience = EXCLUDED.years_experience,\n",
    "                proficiency = EXCLUDED.proficiency,\n",
    "                is_official_masterdata = EXCLUDED.is_official_masterdata\n",
    "        \"\"\"), {\n",
    "            \"cv\": cv_id,\n",
    "            \"tech\": tech_id,\n",
    "            \"yexp\": int(r[\"Year experience\"]) if pd.notna(r[\"Year experience\"]) else None,\n",
    "            \"prof\": int(r[\"Proficiency (0-5)\"]) if pd.notna(r[\"Proficiency (0-5)\"]) else None,\n",
    "            \"is_md\": json.dumps(r[\"Is official masterdata (in #{lang})\"])  # dict -> json\n",
    "        })\n",
    "\n",
    "def upsert_languages(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} languages...\")\n",
    "    sql = text(\"\"\"\n",
    "        INSERT INTO cv_language\n",
    "          (cv_id, language_id, level, highlighted, is_official_masterdata, updated, updated_by_owner)\n",
    "        VALUES\n",
    "          (:cv_id, :lang_id, :level, :highlighted, CAST(:is_md AS JSONB), :updated, :updated_by_owner)\n",
    "        ON CONFLICT (cv_id, language_id) DO UPDATE\n",
    "        SET level = EXCLUDED.level,\n",
    "            highlighted = EXCLUDED.highlighted,\n",
    "            is_official_masterdata = EXCLUDED.is_official_masterdata,\n",
    "            updated = EXCLUDED.updated,\n",
    "            updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        lang_id = _ensure_dim(conn, \"dim_language\", r.get(\"Language\"))\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"lang_id\": lang_id,\n",
    "            \"level\": r.get(\"Level\"),\n",
    "            \"highlighted\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"is_md\": json.dumps(r.get(\"Is official masterdata (in #{lang})\", {})),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff34cc",
   "metadata": {},
   "source": [
    "## Step 3.4 — Project experience, work experience, certifications, courses, education, and positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13e851d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsert_project_experiences(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} project experiences...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO project_experience\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         month_from, year_from, month_to, year_to,\n",
    "         customer_int, customer_multilang,\n",
    "         customer_anon_int, customer_anon_multilang,\n",
    "         description_int, description_multilang,\n",
    "         long_description_int, long_description_multilang,\n",
    "         industry_id, project_type_id,\n",
    "         percent_allocated, extent_individual_hours, extent_hours, extent_total_hours,\n",
    "         extent_unit, extent_currency, extent_total, extent_total_currency,\n",
    "         project_area, project_area_unit,\n",
    "         highlighted, updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id,\n",
    "         :m_from, :y_from, :m_to, :y_to,\n",
    "         :cust_int, CAST(:cust_ml AS JSONB),\n",
    "         :cust_anon_int, CAST(:cust_anon_ml AS JSONB),\n",
    "         :desc_int, CAST(:desc_ml AS JSONB),\n",
    "         :ldesc_int, CAST(:ldesc_ml AS JSONB),\n",
    "         :industry_id, :project_type_id,\n",
    "         :pct_alloc, :indiv_hours, :hours, :total_hours,\n",
    "         :extent_unit, :extent_curr, :extent_total, :extent_total_curr,\n",
    "         :proj_area, :proj_area_unit,\n",
    "         :highlighted, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          month_from = EXCLUDED.month_from, year_from = EXCLUDED.year_from,\n",
    "          month_to = EXCLUDED.month_to, year_to = EXCLUDED.year_to,\n",
    "          customer_int = EXCLUDED.customer_int, customer_multilang = EXCLUDED.customer_multilang,\n",
    "          customer_anon_int = EXCLUDED.customer_anon_int, customer_anon_multilang = EXCLUDED.customer_anon_multilang,\n",
    "          description_int = EXCLUDED.description_int, description_multilang = EXCLUDED.description_multilang,\n",
    "          long_description_int = EXCLUDED.long_description_int, long_description_multilang = EXCLUDED.long_description_multilang,\n",
    "          industry_id = EXCLUDED.industry_id, project_type_id = EXCLUDED.project_type_id,\n",
    "          percent_allocated = EXCLUDED.percent_allocated,\n",
    "          extent_individual_hours = EXCLUDED.extent_individual_hours,\n",
    "          extent_hours = EXCLUDED.extent_hours,\n",
    "          extent_total_hours = EXCLUDED.extent_total_hours,\n",
    "          extent_unit = EXCLUDED.extent_unit,\n",
    "          extent_currency = EXCLUDED.extent_currency,\n",
    "          extent_total = EXCLUDED.extent_total,\n",
    "          extent_total_currency = EXCLUDED.extent_total_currency,\n",
    "          project_area = EXCLUDED.project_area, project_area_unit = EXCLUDED.project_area_unit,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        industry_id = _ensure_dim(conn, \"dim_industry\", r.get(\"Industry (int)\"))\n",
    "        projtype_id = _ensure_dim(conn, \"dim_project_type\", r.get(\"Project type (int)\"))\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"m_from\": r.get(\"Month from\"),\n",
    "            \"y_from\": r.get(\"Year from\"),\n",
    "            \"m_to\": r.get(\"Month to\"),\n",
    "            \"y_to\": r.get(\"Year to\"),\n",
    "            \"cust_int\": r.get(\"Customer (int)\"),\n",
    "            \"cust_ml\": json.dumps(r.get(\"Customer (#{lang})\", {})),\n",
    "            \"cust_anon_int\": r.get(\"Customer Anonymized (int)\"),\n",
    "            \"cust_anon_ml\": json.dumps(r.get(\"Customer Anonymized (#{lang})\", {})),\n",
    "            \"desc_int\": r.get(\"Description (int)\"),\n",
    "            \"desc_ml\": json.dumps(r.get(\"Description (#{lang})\", {})),\n",
    "            \"ldesc_int\": r.get(\"Long description (int)\"),\n",
    "            \"ldesc_ml\": json.dumps(r.get(\"Long description (#{lang})\", {})),\n",
    "            \"industry_id\": industry_id,\n",
    "            \"project_type_id\": projtype_id,\n",
    "            \"pct_alloc\": r.get(\"Percent allocated\"),\n",
    "            \"indiv_hours\": r.get(\"Project extent (individual hours)\"),\n",
    "            \"hours\": r.get(\"Project extent (hours)\"),\n",
    "            \"total_hours\": r.get(\"Project extent total (hours)\"),\n",
    "            \"extent_unit\": r.get(\"Project extent\"),\n",
    "            \"extent_curr\": r.get(\"Project extent (currency)\"),\n",
    "            \"extent_total\": r.get(\"Project extent total\"),\n",
    "            \"extent_total_curr\": r.get(\"Project extent total (currency)\"),\n",
    "            \"proj_area\": r.get(\"Project area\"),\n",
    "            \"proj_area_unit\": r.get(\"Project area (unit)\"),\n",
    "            \"highlighted\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_work_experiences(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} work experiences...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO work_experience\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         month_from, year_from, month_to, year_to,\n",
    "         highlighted, employer, description, long_description,\n",
    "         updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id,\n",
    "         :m_from, :y_from, :m_to, :y_to,\n",
    "         :highlighted, :employer, :desc, :ldesc,\n",
    "         :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          month_from = EXCLUDED.month_from, year_from = EXCLUDED.year_from,\n",
    "          month_to = EXCLUDED.month_to, year_to = EXCLUDED.year_to,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          employer = EXCLUDED.employer,\n",
    "          description = EXCLUDED.description,\n",
    "          long_description = EXCLUDED.long_description,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"m_from\": r.get(\"Month from\"),\n",
    "            \"y_from\": r.get(\"Year from\"),\n",
    "            \"m_to\": r.get(\"Month to\"),\n",
    "            \"y_to\": r.get(\"Year to\"),\n",
    "            \"highlighted\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"employer\": r.get(\"Employer\"),\n",
    "            \"desc\": r.get(\"Description\"),\n",
    "            \"ldesc\": r.get(\"Long Description\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_certifications(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} certifications...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO certification\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         month, year, month_expire, year_expire,\n",
    "         updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id, :m, :y, :mexp, :yexp, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          month = EXCLUDED.month, year = EXCLUDED.year,\n",
    "          month_expire = EXCLUDED.month_expire, year_expire = EXCLUDED.year_expire,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"m\": r.get(\"Month\"),\n",
    "            \"y\": r.get(\"Year\"),\n",
    "            \"mexp\": r.get(\"Month expire\"),\n",
    "            \"yexp\": r.get(\"Year expire\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_courses(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} courses...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO course\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         month, year, name, organiser, long_description, highlighted,\n",
    "         is_official_masterdata, attachments, updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id, :m, :y, :name, :org, :ldesc, :hl,\n",
    "         CAST(:is_md AS JSONB), :att, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          month = EXCLUDED.month, year = EXCLUDED.year,\n",
    "          name = EXCLUDED.name, organiser = EXCLUDED.organiser,\n",
    "          long_description = EXCLUDED.long_description,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          is_official_masterdata = EXCLUDED.is_official_masterdata,\n",
    "          attachments = EXCLUDED.attachments,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"m\": r.get(\"Month\"),\n",
    "            \"y\": r.get(\"Year\"),\n",
    "            \"name\": r.get(\"Name\"),\n",
    "            \"org\": r.get(\"Organiser\"),\n",
    "            \"ldesc\": r.get(\"Long description\"),\n",
    "            \"hl\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"is_md\": json.dumps(r.get(\"Is official masterdata (in #{lang})\", {})),\n",
    "            \"att\": r.get(\"Attachments\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_educations(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} educations...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO education\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         month_from, year_from, month_to, year_to,\n",
    "         highlighted, attachments, place_of_study, degree, description,\n",
    "         updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id,\n",
    "         :m_from, :y_from, :m_to, :y_to,\n",
    "         :hl, :att, :place, :deg, :desc,\n",
    "         :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          month_from = EXCLUDED.month_from, year_from = EXCLUDED.year_from,\n",
    "          month_to = EXCLUDED.month_to, year_to = EXCLUDED.year_to,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          attachments = EXCLUDED.attachments,\n",
    "          place_of_study = EXCLUDED.place_of_study,\n",
    "          degree = EXCLUDED.degree,\n",
    "          description = EXCLUDED.description,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"m_from\": r.get(\"Month from\"),\n",
    "            \"y_from\": r.get(\"Year from\"),\n",
    "            \"m_to\": r.get(\"Month to\"),\n",
    "            \"y_to\": r.get(\"Year to\"),\n",
    "            \"hl\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"att\": r.get(\"Attachments\"),\n",
    "            \"place\": r.get(\"Place of study\"),\n",
    "            \"deg\": r.get(\"Degree\"),\n",
    "            \"desc\": r.get(\"Description\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_positions(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} positions...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO position\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         year_from, year_to, highlighted, name, description,\n",
    "         updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id, :y_from, :y_to, :hl, :name, :desc, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          year_from = EXCLUDED.year_from, year_to = EXCLUDED.year_to,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          name = EXCLUDED.name, description = EXCLUDED.description,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"y_from\": r.get(\"Year from\"),\n",
    "            \"y_to\": r.get(\"Year to\"),\n",
    "            \"hl\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"name\": r.get(\"Name\"),\n",
    "            \"desc\": r.get(\"Description\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_blogs(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} blogs/publications...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO blog_publication\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         name, description, highlighted, updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id, :name, :desc, :hl, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          name = EXCLUDED.name, description = EXCLUDED.description,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"name\": r.get(\"Name\"),\n",
    "            \"desc\": r.get(\"Description\"),\n",
    "            \"hl\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_cv_roles(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} cv roles...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO cv_role\n",
    "        (cv_id, name, description, highlighted, updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :name, :desc, :hl, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, name) DO UPDATE\n",
    "      SET description = EXCLUDED.description,\n",
    "          highlighted = EXCLUDED.highlighted,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"name\": r.get(\"Name\"),\n",
    "            \"desc\": r.get(\"Description\"),\n",
    "            \"hl\": _to_bool(r.get(\"Highlighted\")),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })\n",
    "\n",
    "def upsert_key_qualifications(conn, df):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    print(f\"Upserting {len(df)} key qualifications...\")\n",
    "    sql = text(\"\"\"\n",
    "      INSERT INTO key_qualification\n",
    "        (cv_id, cv_partner_section_id, external_unique_id,\n",
    "         label, summary, short_description, updated, updated_by_owner)\n",
    "      VALUES\n",
    "        (:cv_id, :sid, :ext_id, :label, :summary, :short_desc, :updated, :updated_by_owner)\n",
    "      ON CONFLICT (cv_id, cv_partner_section_id) DO UPDATE\n",
    "      SET external_unique_id = EXCLUDED.external_unique_id,\n",
    "          label = EXCLUDED.label, summary = EXCLUDED.summary,\n",
    "          short_description = EXCLUDED.short_description,\n",
    "          updated = EXCLUDED.updated, updated_by_owner = EXCLUDED.updated_by_owner\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        cv_id = _cv_id(conn, r[\"CV Partner CV ID\"])\n",
    "        if not cv_id:\n",
    "            continue\n",
    "        conn.execute(sql, {\n",
    "            \"cv_id\": cv_id,\n",
    "            \"sid\": r.get(\"CV Partner section ID\"),\n",
    "            \"ext_id\": r.get(\"External unique ID\"),\n",
    "            \"label\": r.get(\"Label\"),\n",
    "            \"summary\": r.get(\"Summary of Qualifications\"),\n",
    "            \"short_desc\": r.get(\"Short description\"),\n",
    "            \"updated\": r.get(\"Updated\"),\n",
    "            \"updated_by_owner\": r.get(\"Updated by owner\"),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac67bad",
   "metadata": {},
   "source": [
    "## Step 3.5 — Security clearance and availability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d092d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_sc_clearance(conn, df: pd.DataFrame):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    for _, r in df.iterrows():\n",
    "        uid = _resolve_user_id(conn, r.get(\"Email\"), r.get(\"UPN\"), r.get(\"External User ID\"))\n",
    "        if not uid:\n",
    "            continue\n",
    "\n",
    "        clr = _clean_str(r.get(\"Clearance\"), \"None\") or \"None\"\n",
    "        conn.execute(text(\"INSERT INTO dim_clearance(name) VALUES (:n) ON CONFLICT(name) DO NOTHING\"),\n",
    "                     {\"n\": clr})\n",
    "        clr_id = conn.execute(text(\"SELECT clearance_id FROM dim_clearance WHERE name=:n\"),\n",
    "                              {\"n\": clr}).scalar()\n",
    "\n",
    "        # Default valid_from if missing so we never violate NOT NULL\n",
    "        vf = _to_date(r.get(\"Valid From\"), default=date(1900, 1, 1))\n",
    "        vt = _to_date(r.get(\"Valid To\"))\n",
    "        vb = _clean_str(r.get(\"Verified By\"), None) or None\n",
    "        no = _clean_str(r.get(\"Notes\"), None) or None\n",
    "\n",
    "        # If both present and vt < vf (bad data), drop vt\n",
    "        if vt and vf and vt < vf:\n",
    "            vt = None\n",
    "\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO user_clearance(user_id, clearance_id, valid_from, valid_to, verified_by, notes)\n",
    "            VALUES (:u, :c, :vf, :vt, :vb, :no)\n",
    "            ON CONFLICT (user_id, clearance_id, valid_from) DO UPDATE\n",
    "            SET valid_to    = EXCLUDED.valid_to,\n",
    "                verified_by = EXCLUDED.verified_by,\n",
    "                notes       = EXCLUDED.notes\n",
    "        \"\"\"), {\"u\": uid, \"c\": clr_id, \"vf\": vf, \"vt\": vt, \"vb\": vb, \"no\": no})\n",
    "\n",
    "\n",
    "\n",
    "def upsert_availability(conn, df: pd.DataFrame):\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    sql = text(\"\"\"\n",
    "        INSERT INTO user_availability(user_id, date, percent_available, source)\n",
    "        VALUES (:u, :d, :p, :s)\n",
    "        ON CONFLICT (user_id, date) DO UPDATE\n",
    "        SET percent_available = EXCLUDED.percent_available,\n",
    "            source            = EXCLUDED.source,\n",
    "            updated_at        = NOW()\n",
    "    \"\"\")\n",
    "    for _, r in df.iterrows():\n",
    "        uid = _resolve_user_id(conn, r.get(\"Email\"), r.get(\"UPN\"), r.get(\"External User ID\"))\n",
    "        if not uid:\n",
    "            continue\n",
    "        # percent can come as float/NaN — clamp to [0,100]\n",
    "        raw = r.get(\"Percent Available\")\n",
    "        p = 0 if (raw is None or (isinstance(raw, float) and pd.isna(raw))) else int(float(raw))\n",
    "        p = max(0, min(100, p))\n",
    "        conn.execute(sql, {\n",
    "            \"u\": uid,\n",
    "            \"d\": _clean_str(r.get(\"Date\"), None) or None,\n",
    "            \"p\": p,\n",
    "            \"s\": _clean_str(r.get(\"Source\"), \"Fake generator\"),\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d26263",
   "metadata": {},
   "source": [
    "## Step 3.6 — Load orchestrator\n",
    "\n",
    "The `load()` function runs all upserts in the correct sequence inside a \n",
    "single database transaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95b8135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(clean_data, engine):\n",
    "    \"\"\"\n",
    "    Loads each cleaned DataFrame into the database using upsert logic.\n",
    "    \"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        if getattr(clean_data, 'users_df', None) is not None:\n",
    "            upsert_users(conn, clean_data.users_df)\n",
    "        if getattr(clean_data, 'cvs_df', None) is not None:\n",
    "            upsert_cvs(conn, clean_data.cvs_df)\n",
    "        if getattr(clean_data, 'technologies_df', None) is not None:\n",
    "            upsert_technologies(conn, clean_data.technologies_df)\n",
    "        if getattr(clean_data, 'languages_df', None) is not None:\n",
    "            upsert_languages(conn, clean_data.languages_df)\n",
    "        if getattr(clean_data, 'project_experiences_df', None) is not None:\n",
    "            upsert_project_experiences(conn, clean_data.project_experiences_df)\n",
    "        if getattr(clean_data, 'work_experiences_df', None) is not None:\n",
    "            upsert_work_experiences(conn, clean_data.work_experiences_df)\n",
    "        if getattr(clean_data, 'certifications_df', None) is not None:\n",
    "            upsert_certifications(conn, clean_data.certifications_df)\n",
    "        if getattr(clean_data, 'courses_df', None) is not None:\n",
    "            upsert_courses(conn, clean_data.courses_df)\n",
    "        if getattr(clean_data, 'educations_df', None) is not None:\n",
    "            upsert_educations(conn, clean_data.educations_df)\n",
    "        if getattr(clean_data, 'positions_df', None) is not None:\n",
    "            upsert_positions(conn, clean_data.positions_df)\n",
    "        if getattr(clean_data, 'blogs_df', None) is not None:\n",
    "            upsert_blogs(conn, clean_data.blogs_df)\n",
    "        if getattr(clean_data, 'cv_roles_df', None) is not None:\n",
    "            upsert_cv_roles(conn, clean_data.cv_roles_df)\n",
    "        if getattr(clean_data, 'key_qualifications_df', None) is not None:\n",
    "            upsert_key_qualifications(conn, clean_data.key_qualifications_df)\n",
    "        if getattr(clean_data, 'sc_clearance_df', None) is not None:\n",
    "            upsert_sc_clearance(conn, clean_data.sc_clearance_df)\n",
    "        if getattr(clean_data, 'availability_df', None) is not None:\n",
    "            upsert_availability(conn, clean_data.availability_df)\n",
    "    print(\"✅ Load complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c025fc2e",
   "metadata": {},
   "source": [
    "# Step 4 — Database Setup\n",
    "\n",
    "These steps configure PostgreSQL connection settings, create the database if \n",
    "missing, and apply schema files from `sql/*.sql`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8be3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_db_config_txt(path=\"db_config.txt\"):\n",
    "    db = {}\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if \"=\" in line:\n",
    "                    k, v = line.strip().split(\"=\", 1)\n",
    "                    db[k.strip()] = v.strip()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return db\n",
    "\n",
    "def compose_settings():\n",
    "    # precedence: ENV > db_config.txt > defaults\n",
    "    defaults = dict(host=\"localhost\", port=5432, database=\"flowcase_demo\",\n",
    "                    user=\"postgres\", password=\"postgres\")\n",
    "    file_cfg = read_db_config_txt()\n",
    "\n",
    "    env_cfg = dict(\n",
    "        host=os.getenv(\"PGHOST\"),\n",
    "        port=os.getenv(\"PGPORT\"),\n",
    "        database=os.getenv(\"PGDATABASE\"),\n",
    "        user=os.getenv(\"PGUSER\"),\n",
    "        password=os.getenv(\"PGPASSWORD\"),\n",
    "    )\n",
    "    # drop Nones\n",
    "    env_cfg = {k:v for k,v in env_cfg.items() if v is not None}\n",
    "    # coerce port\n",
    "    if \"port\" in env_cfg:\n",
    "        try: env_cfg[\"port\"] = int(env_cfg[\"port\"])\n",
    "        except: env_cfg.pop(\"port\", None)\n",
    "\n",
    "    db = {**defaults, **file_cfg, **env_cfg}\n",
    "\n",
    "    settings = {\n",
    "        \"data_source\": \"fake\",\n",
    "        \"base_folder\": \"cv_reports\",\n",
    "        \"db\": db,\n",
    "        # let utils apply ALL sql/*.sql automatically\n",
    "        \"schema\": {\"apply_all_sql_in_sql_folder\": True, \"folder\": \"sql\"}\n",
    "    }\n",
    "    return settings\n",
    "\n",
    "def ensure_database_exists(db):\n",
    "    try:\n",
    "        conn = psycopg2.connect(dbname=\"postgres\",\n",
    "                                user=db[\"user\"], password=db[\"password\"],\n",
    "                                host=db[\"host\"], port=db[\"port\"])\n",
    "        conn.autocommit = True\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT 1 FROM pg_database WHERE datname = %s\", (db[\"database\"],))\n",
    "        if not cur.fetchone():\n",
    "            print(f\"Database '{db['database']}' does not exist. Creating...\")\n",
    "            cur.execute(f\"CREATE DATABASE {db['database']};\")\n",
    "        cur.close(); conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not check/create database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0673d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database_engine(db_settings: dict):\n",
    "    url = (\n",
    "        \"postgresql+psycopg2://\"\n",
    "        f\"{db_settings['user']}:{db_settings['password']}\"\n",
    "        f\"@{db_settings['host']}:{db_settings['port']}/{db_settings['database']}\"\n",
    "    )\n",
    "    return create_engine(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc7c76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def setup_database_schema_if_needed(engine, settings: dict):\n",
    "    schema_cfg = settings.get(\"schema\", {})\n",
    "    if not schema_cfg.get(\"apply_all_sql_in_sql_folder\"):\n",
    "        return\n",
    "\n",
    "    sql_folder = Path(schema_cfg.get(\"folder\", \"sql\"))\n",
    "    if not sql_folder.exists():\n",
    "        print(f\"Schema folder {sql_folder} does not exist. Skipping schema setup.\")\n",
    "        return\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        for path in sorted(sql_folder.glob(\"*.sql\")):\n",
    "            print(f\"Applying schema from {path.name}...\")\n",
    "            conn.execute(text(path.read_text()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a489cd8",
   "metadata": {},
   "source": [
    "# Step 5 — Run Full ETL Pipeline\n",
    "\n",
    "This executes:\n",
    "\n",
    "1. Extract  \n",
    "2. Transform  \n",
    "3. Load  \n",
    "\n",
    "And confirms everything worked end-to-end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b91cda42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying schema from 01_schema.sql...\n",
      "Applying schema from 02_cv_search_profile_mv.sql...\n",
      "\n",
      "==================== Finding the latest quarterly report folder ====================\n",
      "Quarterly folders found: ['Q42025']\n",
      "Using latest quarterly folder: Q42025\n",
      "\n",
      "==================== Loading CSV files from cv_reports/Q42025 ====================\n",
      "Found 15 CSV files.\n",
      "  Loaded certifications.csv -> (1006, 22)\n",
      "  Loaded project_experiences.csv -> (1501, 45)\n",
      "  Loaded blogs.csv -> (758, 21)\n",
      "  Loaded availability_report.csv -> (30000, 7)\n",
      "  Loaded cv_roles.csv -> (1001, 19)\n",
      "  Loaded work_experiences.csv -> (1484, 26)\n",
      "  Loaded educations.csv -> (757, 27)\n",
      "  Loaded user_report.csv -> (500, 26)\n",
      "  Loaded courses.csv -> (1446, 26)\n",
      "  Loaded key_qualifications.csv -> (485, 21)\n",
      "  Loaded positions.csv -> (1264, 23)\n",
      "  Loaded technologies.csv -> (2220, 20)\n",
      "  Loaded sc_clearance.csv -> (500, 9)\n",
      "  Loaded languages.csv -> (996, 22)\n",
      "  Loaded usage_report.csv -> (500, 51)\n",
      "Using data folder: cv_reports/Q42025\n",
      "Upserting 500 users.\n",
      "Upserting 500 CVs...\n",
      "Upserting 2220 technologies...\n",
      "Upserting 996 languages...\n",
      "Upserting 1501 project experiences...\n",
      "Upserting 1484 work experiences...\n",
      "Upserting 1006 certifications...\n",
      "Upserting 1446 courses...\n",
      "Upserting 757 educations...\n",
      "Upserting 1264 positions...\n",
      "Upserting 758 blogs/publications...\n",
      "Upserting 1001 cv roles...\n",
      "Upserting 485 key qualifications...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3p/rr2nrbcj6j79v6mwqtwtdzbw0000gn/T/ipykernel_93648/3417465587.py:32: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  dt = pd.to_datetime(str(v).strip(), dayfirst=True, errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Load complete.\n",
      "✅ Flowcase ETL (manual fake) complete.\n"
     ]
    }
   ],
   "source": [
    "settings = compose_settings()\n",
    "db_settings = settings[\"db\"]\n",
    "\n",
    "ensure_database_exists(db_settings)\n",
    "engine = create_database_engine(db_settings)\n",
    "\n",
    "setup_database_schema_if_needed(engine, settings)\n",
    "\n",
    "ex = extract(settings)\n",
    "print(f\"Using data folder: {getattr(ex, 'data_dir', 'unknown')}\")\n",
    "tr = transform(ex)\n",
    "\n",
    "load(tr, engine)\n",
    "print(\"✅ Flowcase ETL (manual fake) complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b25f8",
   "metadata": {},
   "source": [
    "## Step 5.1 — Basic database verification\n",
    "\n",
    "After running the full ETL, we check that key tables contain data as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac85034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users in DB: 500\n",
      "CVs in DB: 500\n",
      "CV–technology links in DB: 2220\n",
      "✅ Basic load checks passed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with engine.connect() as conn:\n",
    "    users_count = conn.execute(text(\"SELECT COUNT(*) FROM users\")).scalar()\n",
    "    cvs_count = conn.execute(text(\"SELECT COUNT(*) FROM cvs\")).scalar()\n",
    "    tech_links = conn.execute(text(\"SELECT COUNT(*) FROM cv_technology\")).scalar()\n",
    "\n",
    "print(f\"Users in DB: {users_count}\")\n",
    "print(f\"CVs in DB: {cvs_count}\")\n",
    "print(f\"CV–technology links in DB: {tech_links}\")\n",
    "\n",
    "assert users_count > 0, \"No users loaded!\"\n",
    "assert cvs_count > 0, \"No CVs loaded!\"\n",
    "print(\"✅ Basic load checks passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3dc2a",
   "metadata": {},
   "source": [
    "# Step 6 - materialised search view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1626084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 6 — Refresh materialised search view ====================\n",
      "\n",
      "Sample rows from cv_search_profile_mv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cv_partner_user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>cv_id</th>\n",
       "      <th>cv_title</th>\n",
       "      <th>sfia_level</th>\n",
       "      <th>cpd_label</th>\n",
       "      <th>technologies</th>\n",
       "      <th>max_years_experience</th>\n",
       "      <th>clearance</th>\n",
       "      <th>latest_availability_date</th>\n",
       "      <th>latest_percent_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>f543201a</td>\n",
       "      <td>Danielle Johnson</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal C# Developer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>.NET, Azure, Kubernetes, Python, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9cf199d1</td>\n",
       "      <td>Joshua Walker</td>\n",
       "      <td>2</td>\n",
       "      <td>Principal Data Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>C#, Kafka, Node.js, Snowflake, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90dbd3f5</td>\n",
       "      <td>Jill Rhodes</td>\n",
       "      <td>3</td>\n",
       "      <td>Senior C# Developer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>.NET, Node.js, React, Snowflake, TypeScript, dbt</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>34ecdd86</td>\n",
       "      <td>Patricia Miller</td>\n",
       "      <td>4</td>\n",
       "      <td>Principal Analytics Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>Airflow, C#, JavaScript, Kafka, Spark, Terraform</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>460e91df</td>\n",
       "      <td>Robert Johnson</td>\n",
       "      <td>5</td>\n",
       "      <td>Associate ML Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>Airflow, Node.js, Python, Spark</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>95832f08</td>\n",
       "      <td>Jeffery Wagner</td>\n",
       "      <td>6</td>\n",
       "      <td>Consultant Data Platform Engineer</td>\n",
       "      <td>3</td>\n",
       "      <td>CPD2L</td>\n",
       "      <td>Airflow, JavaScript, Power BI, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>e999fc16</td>\n",
       "      <td>Anthony Gonzalez</td>\n",
       "      <td>7</td>\n",
       "      <td>Principal Azure Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>C#, Databricks, SQL, Snowflake, Terraform</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5ebb9296</td>\n",
       "      <td>Debra Gardner</td>\n",
       "      <td>8</td>\n",
       "      <td>Senior AI Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Airflow, JavaScript, Oracle, Power BI, SQL, Te...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ef0cf63e</td>\n",
       "      <td>Jeffrey Lawrence</td>\n",
       "      <td>9</td>\n",
       "      <td>Associate Backend Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>AWS, Azure, C#, Oracle, Power BI, TypeScript</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>506472dd</td>\n",
       "      <td>Lisa Smith</td>\n",
       "      <td>10</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>.NET, Airflow, Azure, React, Snowflake</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id cv_partner_user_id         user_name  cv_id  \\\n",
       "0        1           f543201a  Danielle Johnson      1   \n",
       "1        2           9cf199d1     Joshua Walker      2   \n",
       "2        3           90dbd3f5       Jill Rhodes      3   \n",
       "3        4           34ecdd86   Patricia Miller      4   \n",
       "4        5           460e91df    Robert Johnson      5   \n",
       "5        6           95832f08    Jeffery Wagner      6   \n",
       "6        7           e999fc16  Anthony Gonzalez      7   \n",
       "7        8           5ebb9296     Debra Gardner      8   \n",
       "8        9           ef0cf63e  Jeffrey Lawrence      9   \n",
       "9       10           506472dd        Lisa Smith     10   \n",
       "\n",
       "                            cv_title  sfia_level cpd_label  \\\n",
       "0             Principal C# Developer           5     CPD3L   \n",
       "1            Principal Data Engineer           5     CPD3L   \n",
       "2                Senior C# Developer           4     CPD3E   \n",
       "3       Principal Analytics Engineer           5     CPD3L   \n",
       "4              Associate ML Engineer           2     CPD1E   \n",
       "5  Consultant Data Platform Engineer           3     CPD2L   \n",
       "6           Principal Azure Engineer           5     CPD3L   \n",
       "7                 Senior AI Engineer           4     CPD3E   \n",
       "8         Associate Backend Engineer           2     CPD1E   \n",
       "9           Associate Data Scientist           2     CPD1E   \n",
       "\n",
       "                                        technologies  max_years_experience  \\\n",
       "0               .NET, Azure, Kubernetes, Python, dbt                    15   \n",
       "1                 C#, Kafka, Node.js, Snowflake, dbt                    15   \n",
       "2   .NET, Node.js, React, Snowflake, TypeScript, dbt                     9   \n",
       "3   Airflow, C#, JavaScript, Kafka, Spark, Terraform                    15   \n",
       "4                    Airflow, Node.js, Python, Spark                    15   \n",
       "5                 Airflow, JavaScript, Power BI, dbt                    15   \n",
       "6          C#, Databricks, SQL, Snowflake, Terraform                    15   \n",
       "7  Airflow, JavaScript, Oracle, Power BI, SQL, Te...                    12   \n",
       "8       AWS, Azure, C#, Oracle, Power BI, TypeScript                    15   \n",
       "9             .NET, Airflow, Azure, React, Snowflake                    15   \n",
       "\n",
       "  clearance latest_availability_date  latest_percent_available  \n",
       "0      None               2026-01-23                        40  \n",
       "1      None               2026-01-23                        78  \n",
       "2      None               2026-01-23                        33  \n",
       "3        SC               2026-01-23                        48  \n",
       "4        SC               2026-01-23                         0  \n",
       "5        SC               2026-01-23                        35  \n",
       "6      None               2026-01-23                        52  \n",
       "7      None               2026-01-23                        83  \n",
       "8      None               2026-01-23                        23  \n",
       "9      None               2026-01-23                        24  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_step(\"Step 6 — Refresh materialised search view\")\n",
    "\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"REFRESH MATERIALIZED VIEW cv_search_profile_mv;\"))\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    mv_sample = pd.read_sql(\n",
    "        \"SELECT * FROM cv_search_profile_mv ORDER BY user_id LIMIT 10;\",\n",
    "        conn,\n",
    "    )\n",
    "\n",
    "print(\"\\nSample rows from cv_search_profile_mv:\")\n",
    "display(mv_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d34e6",
   "metadata": {},
   "source": [
    "## Step 6.1 - Example queries against cv_search_profile_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89c9ed76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Example queries against cv_search_profile_mv ====================\n",
      "\n",
      "Available SC (or above) candidates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cv_partner_user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>cv_id</th>\n",
       "      <th>cv_title</th>\n",
       "      <th>sfia_level</th>\n",
       "      <th>cpd_label</th>\n",
       "      <th>technologies</th>\n",
       "      <th>max_years_experience</th>\n",
       "      <th>clearance</th>\n",
       "      <th>latest_availability_date</th>\n",
       "      <th>latest_percent_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>73c0e22b</td>\n",
       "      <td>Jasmine Brown</td>\n",
       "      <td>235</td>\n",
       "      <td>Principal Data Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>AWS, C#, Oracle</td>\n",
       "      <td>11</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119</td>\n",
       "      <td>852ff95e</td>\n",
       "      <td>Pamela Sanchez</td>\n",
       "      <td>119</td>\n",
       "      <td>Senior AI Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>.NET, Databricks, Power BI, Snowflake, dbt</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>f35cc880</td>\n",
       "      <td>Jason Murphy</td>\n",
       "      <td>256</td>\n",
       "      <td>Principal Full-stack Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>.NET, Azure, Kafka, Python, SQL</td>\n",
       "      <td>13</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234</td>\n",
       "      <td>4fd5dcd0</td>\n",
       "      <td>Jesse Benson</td>\n",
       "      <td>234</td>\n",
       "      <td>Principal Solution Architect</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>Azure, JavaScript, Power BI, SQL, Terraform</td>\n",
       "      <td>11</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>231</td>\n",
       "      <td>130a3350</td>\n",
       "      <td>Chris Mitchell</td>\n",
       "      <td>231</td>\n",
       "      <td>Lead Data Platform Engineer</td>\n",
       "      <td>6</td>\n",
       "      <td>CPD4E</td>\n",
       "      <td>AWS, Azure, GCP, Kafka, TypeScript</td>\n",
       "      <td>12</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>398</td>\n",
       "      <td>249570fb</td>\n",
       "      <td>Joshua Tyler</td>\n",
       "      <td>398</td>\n",
       "      <td>Senior Kubernetes Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>.NET, Airflow, Azure, React, Spark</td>\n",
       "      <td>11</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>f43ac997</td>\n",
       "      <td>Cynthia Diaz</td>\n",
       "      <td>25</td>\n",
       "      <td>Lead Enterprise Architect</td>\n",
       "      <td>6</td>\n",
       "      <td>CPD4E</td>\n",
       "      <td>JavaScript, Kafka, Oracle, Spark, Terraform</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>467</td>\n",
       "      <td>0df60a11</td>\n",
       "      <td>Gregory Anderson</td>\n",
       "      <td>467</td>\n",
       "      <td>Senior Analytics Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Kafka, Kubernetes, Node.js, SQL</td>\n",
       "      <td>10</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>371</td>\n",
       "      <td>eb6d0b93</td>\n",
       "      <td>Elizabeth Hodge</td>\n",
       "      <td>371</td>\n",
       "      <td>Senior Analytics Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>.NET, AWS, Databricks, Power BI, dbt</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>155</td>\n",
       "      <td>0f3b546c</td>\n",
       "      <td>Laura Valencia</td>\n",
       "      <td>155</td>\n",
       "      <td>Principal Frontend Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>AWS, JavaScript, Node.js, Python, React, Terra...</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>397</td>\n",
       "      <td>067fc535</td>\n",
       "      <td>Natasha Shields</td>\n",
       "      <td>397</td>\n",
       "      <td>Principal Backend Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>Airflow, C#, Power BI, Spark, TypeScript</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>109</td>\n",
       "      <td>1b804afd</td>\n",
       "      <td>Angela Higgins</td>\n",
       "      <td>109</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>AWS, JavaScript, SQL</td>\n",
       "      <td>6</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>206</td>\n",
       "      <td>d182b6da</td>\n",
       "      <td>Loretta Potter</td>\n",
       "      <td>206</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>JavaScript, Node.js, React, TypeScript</td>\n",
       "      <td>11</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>76</td>\n",
       "      <td>b0c0da53</td>\n",
       "      <td>Wanda Santos</td>\n",
       "      <td>76</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Docker, GCP, Python</td>\n",
       "      <td>12</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>260</td>\n",
       "      <td>cf0ad7ab</td>\n",
       "      <td>Andrew Ryan</td>\n",
       "      <td>260</td>\n",
       "      <td>Head of UCD and Insights</td>\n",
       "      <td>6</td>\n",
       "      <td>CPD4E</td>\n",
       "      <td>C#, Kubernetes, Node.js, Oracle, Snowflake, Ty...</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>324</td>\n",
       "      <td>ae79dd13</td>\n",
       "      <td>Monique Andrews</td>\n",
       "      <td>324</td>\n",
       "      <td>Senior Data Platform Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Airflow, React, Spark</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>454</td>\n",
       "      <td>d61d2fdb</td>\n",
       "      <td>Gina Garner</td>\n",
       "      <td>454</td>\n",
       "      <td>Principal AWS Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>JavaScript, Oracle, Snowflake</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>198</td>\n",
       "      <td>674e76ae</td>\n",
       "      <td>Aaron Mitchell</td>\n",
       "      <td>198</td>\n",
       "      <td>Lead Data Platform Engineer</td>\n",
       "      <td>6</td>\n",
       "      <td>CPD4E</td>\n",
       "      <td>C#, Power BI, Python, TypeScript</td>\n",
       "      <td>12</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>456</td>\n",
       "      <td>34c38536</td>\n",
       "      <td>Tyler Strong</td>\n",
       "      <td>456</td>\n",
       "      <td>Principal MLOps Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>C#, JavaScript, SQL, Snowflake, TypeScript</td>\n",
       "      <td>13</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>269</td>\n",
       "      <td>5827dd9a</td>\n",
       "      <td>Gary Lawson</td>\n",
       "      <td>269</td>\n",
       "      <td>Principal Python Developer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>GCP, Power BI, React</td>\n",
       "      <td>14</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id cv_partner_user_id         user_name  cv_id  \\\n",
       "0       235           73c0e22b     Jasmine Brown    235   \n",
       "1       119           852ff95e    Pamela Sanchez    119   \n",
       "2       256           f35cc880      Jason Murphy    256   \n",
       "3       234           4fd5dcd0      Jesse Benson    234   \n",
       "4       231           130a3350    Chris Mitchell    231   \n",
       "5       398           249570fb      Joshua Tyler    398   \n",
       "6        25           f43ac997      Cynthia Diaz     25   \n",
       "7       467           0df60a11  Gregory Anderson    467   \n",
       "8       371           eb6d0b93   Elizabeth Hodge    371   \n",
       "9       155           0f3b546c    Laura Valencia    155   \n",
       "10      397           067fc535   Natasha Shields    397   \n",
       "11      109           1b804afd    Angela Higgins    109   \n",
       "12      206           d182b6da    Loretta Potter    206   \n",
       "13       76           b0c0da53      Wanda Santos     76   \n",
       "14      260           cf0ad7ab       Andrew Ryan    260   \n",
       "15      324           ae79dd13   Monique Andrews    324   \n",
       "16      454           d61d2fdb       Gina Garner    454   \n",
       "17      198           674e76ae    Aaron Mitchell    198   \n",
       "18      456           34c38536      Tyler Strong    456   \n",
       "19      269           5827dd9a       Gary Lawson    269   \n",
       "\n",
       "                         cv_title  sfia_level cpd_label  \\\n",
       "0         Principal Data Engineer           5     CPD3L   \n",
       "1              Senior AI Engineer           4     CPD3E   \n",
       "2   Principal Full-stack Engineer           5     CPD3L   \n",
       "3    Principal Solution Architect           5     CPD3L   \n",
       "4     Lead Data Platform Engineer           6     CPD4E   \n",
       "5      Senior Kubernetes Engineer           4     CPD3E   \n",
       "6       Lead Enterprise Architect           6     CPD4E   \n",
       "7       Senior Analytics Engineer           4     CPD3E   \n",
       "8       Senior Analytics Engineer           4     CPD3E   \n",
       "9     Principal Frontend Engineer           5     CPD3L   \n",
       "10     Principal Backend Engineer           5     CPD3L   \n",
       "11           Senior Data Engineer           4     CPD3E   \n",
       "12       Principal Data Scientist           5     CPD3L   \n",
       "13           Senior Data Engineer           4     CPD3E   \n",
       "14       Head of UCD and Insights           6     CPD4E   \n",
       "15  Senior Data Platform Engineer           4     CPD3E   \n",
       "16         Principal AWS Engineer           5     CPD3L   \n",
       "17    Lead Data Platform Engineer           6     CPD4E   \n",
       "18       Principal MLOps Engineer           5     CPD3L   \n",
       "19     Principal Python Developer           5     CPD3L   \n",
       "\n",
       "                                         technologies  max_years_experience  \\\n",
       "0                                     AWS, C#, Oracle                    11   \n",
       "1          .NET, Databricks, Power BI, Snowflake, dbt                    14   \n",
       "2                     .NET, Azure, Kafka, Python, SQL                    13   \n",
       "3         Azure, JavaScript, Power BI, SQL, Terraform                    11   \n",
       "4                  AWS, Azure, GCP, Kafka, TypeScript                    12   \n",
       "5                  .NET, Airflow, Azure, React, Spark                    11   \n",
       "6         JavaScript, Kafka, Oracle, Spark, Terraform                    14   \n",
       "7                     Kafka, Kubernetes, Node.js, SQL                    10   \n",
       "8                .NET, AWS, Databricks, Power BI, dbt                    14   \n",
       "9   AWS, JavaScript, Node.js, Python, React, Terra...                    14   \n",
       "10           Airflow, C#, Power BI, Spark, TypeScript                    14   \n",
       "11                               AWS, JavaScript, SQL                     6   \n",
       "12             JavaScript, Node.js, React, TypeScript                    11   \n",
       "13                                Docker, GCP, Python                    12   \n",
       "14  C#, Kubernetes, Node.js, Oracle, Snowflake, Ty...                    14   \n",
       "15                              Airflow, React, Spark                    15   \n",
       "16                      JavaScript, Oracle, Snowflake                    15   \n",
       "17                   C#, Power BI, Python, TypeScript                    12   \n",
       "18         C#, JavaScript, SQL, Snowflake, TypeScript                    13   \n",
       "19                               GCP, Power BI, React                    14   \n",
       "\n",
       "   clearance latest_availability_date  latest_percent_available  \n",
       "0         SC               2026-01-23                        90  \n",
       "1         SC               2026-01-23                        89  \n",
       "2         SC               2026-01-23                        86  \n",
       "3         SC               2026-01-23                        84  \n",
       "4         SC               2026-01-23                        83  \n",
       "5         SC               2026-01-23                        83  \n",
       "6         SC               2026-01-23                        80  \n",
       "7         SC               2026-01-23                        79  \n",
       "8         SC               2026-01-23                        79  \n",
       "9         SC               2026-01-23                        77  \n",
       "10        SC               2026-01-23                        76  \n",
       "11        SC               2026-01-23                        75  \n",
       "12        SC               2026-01-23                        73  \n",
       "13        SC               2026-01-23                        73  \n",
       "14        SC               2026-01-23                        72  \n",
       "15        SC               2026-01-23                        72  \n",
       "16        SC               2026-01-23                        71  \n",
       "17        SC               2026-01-23                        70  \n",
       "18        SC               2026-01-23                        70  \n",
       "19        SC               2026-01-23                        70  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_step(\"Example queries against cv_search_profile_mv\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    sc_available = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT *\n",
    "        FROM cv_search_profile_mv\n",
    "        WHERE\n",
    "            (clearance = 'SC' OR clearance IS NULL) AND\n",
    "            sfia_level >= 4 AND\n",
    "            latest_percent_available >= 50\n",
    "        ORDER BY latest_percent_available DESC, sfia_level DESC\n",
    "        LIMIT 20;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "    )\n",
    "\n",
    "print(\"\\nAvailable SC (or above) candidates:\")\n",
    "display(sc_available)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c43c5",
   "metadata": {},
   "source": [
    "# Step 7 — Explore Validations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d8e635",
   "metadata": {},
   "source": [
    "## 7.1 Pick a random user + CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ae51c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 7.1 — Pick one random user + CV ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cv_partner_user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>department</th>\n",
       "      <th>country</th>\n",
       "      <th>cv_id</th>\n",
       "      <th>cv_partner_cv_id</th>\n",
       "      <th>cv_title</th>\n",
       "      <th>sfia_level</th>\n",
       "      <th>cpd_level</th>\n",
       "      <th>cpd_band</th>\n",
       "      <th>cpd_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489</td>\n",
       "      <td>596dc408</td>\n",
       "      <td>Donald Shah</td>\n",
       "      <td>donald.shah@example.org</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>489</td>\n",
       "      <td>cv_596dc408</td>\n",
       "      <td>Associate Data Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>CPD1E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id cv_partner_user_id         name                    email  \\\n",
       "0      489           596dc408  Donald Shah  donald.shah@example.org   \n",
       "\n",
       "         department         country  cv_id cv_partner_cv_id  \\\n",
       "0  Data Engineering  United Kingdom    489      cv_596dc408   \n",
       "\n",
       "                  cv_title  sfia_level  cpd_level cpd_band cpd_label  \n",
       "0  Associate Data Engineer           2          1        E     CPD1E  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chosen user_id=489, cv_id=489\n"
     ]
    }
   ],
   "source": [
    "print_step(\"Step 7.1 — Pick one random user + CV\")\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    person_df = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            u.user_id,\n",
    "            u.cv_partner_user_id,\n",
    "            (u.name_multilang->>'int') AS name,\n",
    "            u.email,\n",
    "            u.department,\n",
    "            u.country,\n",
    "            c.cv_id,\n",
    "            c.cv_partner_cv_id,\n",
    "            (c.title_multilang->>'int') AS cv_title,\n",
    "            c.sfia_level,\n",
    "            c.cpd_level,\n",
    "            c.cpd_band,\n",
    "            c.cpd_label\n",
    "        FROM users u\n",
    "        JOIN cvs c ON c.user_id = u.user_id\n",
    "        ORDER BY random()\n",
    "        LIMIT 1;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "    )\n",
    "\n",
    "display(person_df)\n",
    "\n",
    "user_id = int(person_df.loc[0, \"user_id\"])\n",
    "cv_id = int(person_df.loc[0, \"cv_id\"])\n",
    "\n",
    "print(f\"\\nChosen user_id={user_id}, cv_id={cv_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8347d40c",
   "metadata": {},
   "source": [
    "## 7.2 Pull all related sections for that CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95506d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 7.2 — Load all sections for this CV ====================\n",
      "\n",
      "Technologies:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>technology</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>proficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Docker</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terraform</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbt</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  technology  years_experience  proficiency\n",
       "0     Docker                14            3\n",
       "1  Terraform                 8            5\n",
       "2        dbt                 5            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Languages:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>level</th>\n",
       "      <th>highlighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Native</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danish</td>\n",
       "      <td>Native</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norwegian</td>\n",
       "      <td>Professional</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    language         level  highlighted\n",
       "0    English        Native         True\n",
       "1     Danish        Native        False\n",
       "2  Norwegian  Professional        False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project experience:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_from</th>\n",
       "      <th>year_to</th>\n",
       "      <th>description</th>\n",
       "      <th>industry</th>\n",
       "      <th>project_type</th>\n",
       "      <th>percent_allocated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>2023</td>\n",
       "      <td>None</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Advisory</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>2017</td>\n",
       "      <td>None</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Implementation</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_from  year_to description industry    project_type  percent_allocated\n",
       "0       2021     2023        None   Energy        Advisory                 33\n",
       "1       2014     2017        None   Energy  Implementation                 21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Work experience:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_from</th>\n",
       "      <th>year_to</th>\n",
       "      <th>employer</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>2025</td>\n",
       "      <td>ConsultCo</td>\n",
       "      <td>Worked on data platforms, software delivery an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>Energia</td>\n",
       "      <td>Worked on data platforms, software delivery an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>2020</td>\n",
       "      <td>ConsultCo</td>\n",
       "      <td>Worked on data platforms, software delivery an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>2019</td>\n",
       "      <td>RetailCo</td>\n",
       "      <td>Worked on data platforms, software delivery an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_from  year_to   employer  \\\n",
       "0       2022     2025  ConsultCo   \n",
       "1       2022     2022    Energia   \n",
       "2       2018     2020  ConsultCo   \n",
       "3       2017     2019   RetailCo   \n",
       "\n",
       "                                         description  \n",
       "0  Worked on data platforms, software delivery an...  \n",
       "1  Worked on data platforms, software delivery an...  \n",
       "2  Worked on data platforms, software delivery an...  \n",
       "3  Worked on data platforms, software delivery an...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Education:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_from</th>\n",
       "      <th>year_to</th>\n",
       "      <th>place_of_study</th>\n",
       "      <th>degree</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>2024</td>\n",
       "      <td>KTH</td>\n",
       "      <td>MSc Data Science</td>\n",
       "      <td>Thesis on scalable data pipelines.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>2022</td>\n",
       "      <td>KTH</td>\n",
       "      <td>MSc Data Science</td>\n",
       "      <td>Thesis on scalable data pipelines.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_from  year_to place_of_study            degree  \\\n",
       "0       2022     2024            KTH  MSc Data Science   \n",
       "1       2021     2022            KTH  MSc Data Science   \n",
       "\n",
       "                          description  \n",
       "0  Thesis on scalable data pipelines.  \n",
       "1  Thesis on scalable data pipelines.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Courses:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>organiser</th>\n",
       "      <th>highlighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>Power BI</td>\n",
       "      <td>Udemy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>SQL Advanced</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>Databricks Lakehouse</td>\n",
       "      <td>Udemy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>Databricks Lakehouse</td>\n",
       "      <td>AWS</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Databricks Lakehouse</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                  name  organiser  highlighted\n",
       "0  2025              Power BI      Udemy        False\n",
       "1  2022          SQL Advanced   Coursera        False\n",
       "2  2021  Databricks Lakehouse      Udemy         True\n",
       "3  2021  Databricks Lakehouse        AWS         True\n",
       "4  2019  Databricks Lakehouse  Microsoft         True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Certifications:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>month_expire</th>\n",
       "      <th>year_expire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  month_expire  year_expire\n",
       "0  2022     10             2         2024\n",
       "1  2020      4             7         2020\n",
       "2  2018     12            12         2020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_from</th>\n",
       "      <th>year_to</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>highlighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>2017</td>\n",
       "      <td>Associate Data Engineer</td>\n",
       "      <td>Progression based on delivery impact.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_from  year_to                     name  \\\n",
       "0       2016     2017  Associate Data Engineer   \n",
       "\n",
       "                             description  highlighted  \n",
       "0  Progression based on delivery impact.         True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blogs / publications:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>highlighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Streaming 101</td>\n",
       "      <td>Conference talk / blog summary.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLOps Playbook</td>\n",
       "      <td>Conference talk / blog summary.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Modern .NET APIs</td>\n",
       "      <td>Conference talk / blog summary.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                      description  highlighted\n",
       "0     Streaming 101  Conference talk / blog summary.         True\n",
       "1    MLOps Playbook  Conference talk / blog summary.         True\n",
       "2  Modern .NET APIs  Conference talk / blog summary.        False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV roles:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>highlighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tech Lead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyst</td>\n",
       "      <td>High-level role on multiple projects.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manager</td>\n",
       "      <td>High-level role on multiple projects.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                            description  highlighted\n",
       "0  Tech Lead                                    NaN         True\n",
       "1    Analyst  High-level role on multiple projects.        False\n",
       "2    Manager  High-level role on multiple projects.        False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key qualifications:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>summary</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summary</td>\n",
       "      <td>Experienced in cloud, data engineering and ana...</td>\n",
       "      <td>Focus on Python, Azure/AWS, Databricks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            summary  \\\n",
       "0  Summary  Experienced in cloud, data engineering and ana...   \n",
       "\n",
       "                         short_description  \n",
       "0  Focus on Python, Azure/AWS, Databricks.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_step(\"Step 7.2 — Load all sections for this CV\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    techs = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          dt.name AS technology,\n",
    "          ct.years_experience,\n",
    "          ct.proficiency\n",
    "        FROM cv_technology ct\n",
    "        JOIN dim_technology dt ON dt.technology_id = ct.technology_id\n",
    "        WHERE ct.cv_id = %(cv_id)s\n",
    "        ORDER BY dt.name;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    langs = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          dl.name AS language,\n",
    "          cl.level,\n",
    "          cl.highlighted\n",
    "        FROM cv_language cl\n",
    "        JOIN dim_language dl ON dl.language_id = cl.language_id\n",
    "        WHERE cl.cv_id = %(cv_id)s\n",
    "        ORDER BY cl.highlighted DESC, dl.name;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    projects = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          pe.year_from, pe.year_to,\n",
    "          (pe.description_multilang->>'int') AS description,\n",
    "          di.name AS industry,\n",
    "          dpt.name AS project_type,\n",
    "          pe.percent_allocated\n",
    "        FROM project_experience pe\n",
    "        LEFT JOIN dim_industry di ON di.industry_id = pe.industry_id\n",
    "        LEFT JOIN dim_project_type dpt ON dpt.project_type_id = pe.project_type_id\n",
    "        WHERE pe.cv_id = %(cv_id)s\n",
    "        ORDER BY pe.year_from DESC, pe.month_from DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    work = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          year_from, year_to,\n",
    "          employer,\n",
    "          description\n",
    "        FROM work_experience\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY year_from DESC, month_from DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    edu = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          year_from, year_to,\n",
    "          place_of_study,\n",
    "          degree,\n",
    "          description\n",
    "        FROM education\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY year_from DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    courses = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          year,\n",
    "          name,\n",
    "          organiser,\n",
    "          highlighted\n",
    "        FROM course\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY year DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    certs = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          year,\n",
    "          month,\n",
    "          month_expire,\n",
    "          year_expire\n",
    "        FROM certification\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY year DESC, month DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    positions = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          year_from, year_to,\n",
    "          name,\n",
    "          description,\n",
    "          highlighted\n",
    "        FROM position\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY year_from DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    blogs = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          name,\n",
    "          description,\n",
    "          highlighted\n",
    "        FROM blog_publication\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY highlighted DESC, updated DESC NULLS LAST;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    roles = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          name,\n",
    "          description,\n",
    "          highlighted\n",
    "        FROM cv_role\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY highlighted DESC, name;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "    key_quals = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          label,\n",
    "          summary,\n",
    "          short_description\n",
    "        FROM key_qualification\n",
    "        WHERE cv_id = %(cv_id)s\n",
    "        ORDER BY label;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"cv_id\": cv_id},\n",
    "    )\n",
    "\n",
    "print(\"\\nTechnologies:\")\n",
    "display(techs.head())\n",
    "\n",
    "print(\"\\nLanguages:\")\n",
    "display(langs.head())\n",
    "\n",
    "print(\"\\nProject experience:\")\n",
    "display(projects.head())\n",
    "\n",
    "print(\"\\nWork experience:\")\n",
    "display(work.head())\n",
    "\n",
    "print(\"\\nEducation:\")\n",
    "display(edu.head())\n",
    "\n",
    "print(\"\\nCourses:\")\n",
    "display(courses.head())\n",
    "\n",
    "print(\"\\nCertifications:\")\n",
    "display(certs.head())\n",
    "\n",
    "print(\"\\nPositions:\")\n",
    "display(positions.head())\n",
    "\n",
    "print(\"\\nBlogs / publications:\")\n",
    "display(blogs.head())\n",
    "\n",
    "print(\"\\nCV roles:\")\n",
    "display(roles.head())\n",
    "\n",
    "print(\"\\nKey qualifications:\")\n",
    "display(key_quals.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572e634",
   "metadata": {},
   "source": [
    "## 7.3 Clearance + availability for that user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1e1bd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Step 7.3 — Clearance and availability for this user ====================\n",
      "\n",
      "Security clearance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clearance</th>\n",
       "      <th>valid_from</th>\n",
       "      <th>valid_to</th>\n",
       "      <th>verified_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SC</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>None</td>\n",
       "      <td>Security</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clearance  valid_from valid_to verified_by\n",
       "0        SC  2023-02-27     None    Security"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Upcoming availability (sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>percent_available</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>0</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>88</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>91</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>63</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-29</td>\n",
       "      <td>100</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>100</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>59</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-12-02</td>\n",
       "      <td>74</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-12-03</td>\n",
       "      <td>0</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>90</td>\n",
       "      <td>Fake generator</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  percent_available          source\n",
       "0  2025-11-25                  0  Fake generator\n",
       "1  2025-11-26                 88  Fake generator\n",
       "2  2025-11-27                 91  Fake generator\n",
       "3  2025-11-28                 63  Fake generator\n",
       "4  2025-11-29                100  Fake generator\n",
       "5  2025-11-30                100  Fake generator\n",
       "6  2025-12-01                 59  Fake generator\n",
       "7  2025-12-02                 74  Fake generator\n",
       "8  2025-12-03                  0  Fake generator\n",
       "9  2025-12-04                 90  Fake generator"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_step(\"Step 7.3 — Clearance and availability for this user\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    clearance = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          dc.name AS clearance,\n",
    "          uc.valid_from,\n",
    "          uc.valid_to,\n",
    "          uc.verified_by\n",
    "        FROM user_clearance uc\n",
    "        JOIN dim_clearance dc ON dc.clearance_id = uc.clearance_id\n",
    "        WHERE uc.user_id = %(user_id)s\n",
    "        ORDER BY uc.valid_from DESC;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"user_id\": user_id},\n",
    "    )\n",
    "\n",
    "    availability = pd.read_sql(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "          date,\n",
    "          percent_available,\n",
    "          source\n",
    "        FROM user_availability\n",
    "        WHERE user_id = %(user_id)s\n",
    "        ORDER BY date\n",
    "        LIMIT 30;\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params={\"user_id\": user_id},\n",
    "    )\n",
    "\n",
    "print(\"\\nSecurity clearance:\")\n",
    "display(clearance)\n",
    "\n",
    "print(\"\\nUpcoming availability (sample):\")\n",
    "display(availability.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c5ba883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Example table use ====================\n",
      "\n",
      "One-row-per-person profile table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cv_partner_user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>cv_id</th>\n",
       "      <th>cv_title</th>\n",
       "      <th>sfia_level</th>\n",
       "      <th>cpd_label</th>\n",
       "      <th>technologies</th>\n",
       "      <th>max_years_experience</th>\n",
       "      <th>clearance</th>\n",
       "      <th>latest_availability_date</th>\n",
       "      <th>latest_percent_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>f543201a</td>\n",
       "      <td>Danielle Johnson</td>\n",
       "      <td>1</td>\n",
       "      <td>Principal C# Developer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>.NET, Azure, Kubernetes, Python, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9cf199d1</td>\n",
       "      <td>Joshua Walker</td>\n",
       "      <td>2</td>\n",
       "      <td>Principal Data Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>C#, Kafka, Node.js, Snowflake, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90dbd3f5</td>\n",
       "      <td>Jill Rhodes</td>\n",
       "      <td>3</td>\n",
       "      <td>Senior C# Developer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>.NET, Node.js, React, Snowflake, TypeScript, dbt</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>34ecdd86</td>\n",
       "      <td>Patricia Miller</td>\n",
       "      <td>4</td>\n",
       "      <td>Principal Analytics Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>Airflow, C#, JavaScript, Kafka, Spark, Terraform</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>460e91df</td>\n",
       "      <td>Robert Johnson</td>\n",
       "      <td>5</td>\n",
       "      <td>Associate ML Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>Airflow, Node.js, Python, Spark</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>95832f08</td>\n",
       "      <td>Jeffery Wagner</td>\n",
       "      <td>6</td>\n",
       "      <td>Consultant Data Platform Engineer</td>\n",
       "      <td>3</td>\n",
       "      <td>CPD2L</td>\n",
       "      <td>Airflow, JavaScript, Power BI, dbt</td>\n",
       "      <td>15</td>\n",
       "      <td>SC</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>e999fc16</td>\n",
       "      <td>Anthony Gonzalez</td>\n",
       "      <td>7</td>\n",
       "      <td>Principal Azure Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>CPD3L</td>\n",
       "      <td>C#, Databricks, SQL, Snowflake, Terraform</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5ebb9296</td>\n",
       "      <td>Debra Gardner</td>\n",
       "      <td>8</td>\n",
       "      <td>Senior AI Engineer</td>\n",
       "      <td>4</td>\n",
       "      <td>CPD3E</td>\n",
       "      <td>Airflow, JavaScript, Oracle, Power BI, SQL, Te...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ef0cf63e</td>\n",
       "      <td>Jeffrey Lawrence</td>\n",
       "      <td>9</td>\n",
       "      <td>Associate Backend Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>AWS, Azure, C#, Oracle, Power BI, TypeScript</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>506472dd</td>\n",
       "      <td>Lisa Smith</td>\n",
       "      <td>10</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>2</td>\n",
       "      <td>CPD1E</td>\n",
       "      <td>.NET, Airflow, Azure, React, Snowflake</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id cv_partner_user_id              name  cv_id  \\\n",
       "0        1           f543201a  Danielle Johnson      1   \n",
       "1        2           9cf199d1     Joshua Walker      2   \n",
       "2        3           90dbd3f5       Jill Rhodes      3   \n",
       "3        4           34ecdd86   Patricia Miller      4   \n",
       "4        5           460e91df    Robert Johnson      5   \n",
       "5        6           95832f08    Jeffery Wagner      6   \n",
       "6        7           e999fc16  Anthony Gonzalez      7   \n",
       "7        8           5ebb9296     Debra Gardner      8   \n",
       "8        9           ef0cf63e  Jeffrey Lawrence      9   \n",
       "9       10           506472dd        Lisa Smith     10   \n",
       "\n",
       "                            cv_title  sfia_level cpd_label  \\\n",
       "0             Principal C# Developer           5     CPD3L   \n",
       "1            Principal Data Engineer           5     CPD3L   \n",
       "2                Senior C# Developer           4     CPD3E   \n",
       "3       Principal Analytics Engineer           5     CPD3L   \n",
       "4              Associate ML Engineer           2     CPD1E   \n",
       "5  Consultant Data Platform Engineer           3     CPD2L   \n",
       "6           Principal Azure Engineer           5     CPD3L   \n",
       "7                 Senior AI Engineer           4     CPD3E   \n",
       "8         Associate Backend Engineer           2     CPD1E   \n",
       "9           Associate Data Scientist           2     CPD1E   \n",
       "\n",
       "                                        technologies  max_years_experience  \\\n",
       "0               .NET, Azure, Kubernetes, Python, dbt                    15   \n",
       "1                 C#, Kafka, Node.js, Snowflake, dbt                    15   \n",
       "2   .NET, Node.js, React, Snowflake, TypeScript, dbt                     9   \n",
       "3   Airflow, C#, JavaScript, Kafka, Spark, Terraform                    15   \n",
       "4                    Airflow, Node.js, Python, Spark                    15   \n",
       "5                 Airflow, JavaScript, Power BI, dbt                    15   \n",
       "6          C#, Databricks, SQL, Snowflake, Terraform                    15   \n",
       "7  Airflow, JavaScript, Oracle, Power BI, SQL, Te...                    12   \n",
       "8       AWS, Azure, C#, Oracle, Power BI, TypeScript                    15   \n",
       "9             .NET, Airflow, Azure, React, Snowflake                    15   \n",
       "\n",
       "  clearance latest_availability_date  latest_percent_available  \n",
       "0      None               2026-01-23                       100  \n",
       "1      None               2026-01-23                       100  \n",
       "2      None               2026-01-23                       100  \n",
       "3        SC               2026-01-23                       100  \n",
       "4        SC               2026-01-23                       100  \n",
       "5        SC               2026-01-23                       100  \n",
       "6      None               2026-01-23                       100  \n",
       "7      None               2026-01-23                       100  \n",
       "8      None               2026-01-23                       100  \n",
       "9      None               2026-01-23                       100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_step(\"Example table use\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    basic = pd.read_sql(\"\"\"\n",
    "        SELECT\n",
    "            u.user_id,\n",
    "            u.cv_partner_user_id,\n",
    "            (u.name_multilang->>'int') AS name,\n",
    "            c.cv_id,\n",
    "            (c.title_multilang->>'int') AS cv_title,\n",
    "            c.sfia_level,\n",
    "            c.cpd_label,\n",
    "            dt.name AS technology,\n",
    "            ct.years_experience,\n",
    "            cr.name AS clearance,\n",
    "            ua.percent_available, \n",
    "            ua.date AS availability_date\n",
    "        FROM users u\n",
    "        JOIN cvs c\n",
    "            ON c.user_id = u.user_id\n",
    "        LEFT JOIN cv_technology ct  ON ct.cv_id = c.cv_id\n",
    "        LEFT JOIN dim_technology dt ON dt.technology_id = ct.technology_id\n",
    "        LEFT JOIN user_clearance uc ON uc.user_id = u.user_id\n",
    "        LEFT JOIN dim_clearance cr  ON cr.clearance_id = uc.clearance_id\n",
    "        LEFT JOIN user_availability ua ON ua.user_id = u.user_id\n",
    "\n",
    "    \"\"\", conn)\n",
    "\n",
    "basic_clean = (\n",
    "    basic.sort_values(\n",
    "        by=[\"user_id\", \"cv_id\", \"technology\", \"availability_date\", \"clearance\"],\n",
    "        ascending=[True, True, True, True, False]\n",
    "    )\n",
    "    .drop_duplicates(\n",
    "        subset=[\"user_id\", \"cv_id\", \"technology\", \"availability_date\"],\n",
    "        keep=\"first\"\n",
    "    )\n",
    ")\n",
    "\n",
    "profile = (\n",
    "    basic_clean\n",
    "    .groupby(\n",
    "        [\n",
    "            \"user_id\",\n",
    "            \"cv_partner_user_id\",\n",
    "            \"name\",\n",
    "            \"cv_id\",\n",
    "            \"cv_title\",\n",
    "            \"sfia_level\",\n",
    "            \"cpd_label\",\n",
    "        ],\n",
    "        dropna=False,\n",
    "    )\n",
    "    .agg(\n",
    "        technologies=(\"technology\", lambda s: \", \".join(sorted(set(s.dropna())))),\n",
    "        max_years_experience=(\"years_experience\", \"max\"),\n",
    "        clearance=(\"clearance\", lambda s: s.dropna().iloc[0] if s.dropna().any() else None),\n",
    "        latest_availability_date=(\"availability_date\", \"max\"),\n",
    "        latest_percent_available=(\"percent_available\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\nOne-row-per-person profile table:\")\n",
    "display(profile.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
